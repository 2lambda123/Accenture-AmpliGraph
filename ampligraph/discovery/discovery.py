import logging
import numpy as np

from ..evaluation import evaluate_performance, filter_unseen_entities

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)


def discover_facts(X, model, top_n=10, strategy='exhaustive',
                   max_candidates=.3, target_rel=None,
                   corruption_entities=None,
                   max_negatives=100,
                   seed=0):

    """ Discover new facts from an existing knowledge graph.


        Parameters
        ----------

        X : ndarray, shape [n, 3]
            The input knowledge graph used to train ``model``.
        model : EmbeddingModel
            The trained model that will be used to score candidate facts.
            ``model`` must have been previously trained on ``X``.
        top_n : int
            The cutoff position in ranking to consider a candidate triple
            as true positive.
        strategy: string
            The candidates generation strategy. Choose from 'exhaustive',
            'random_uniform'.
        max_candidates: int or float
            The maximum numbers of candidates generated by 'strategy'.
            Can be an absolute number or a percentage [0,1].
        target_rel : str
            Target relation to focus on. The function will discover facts only
            for that specific relation type.
            If None, the function attempts to discover new facts for all
            relation types in the graph.
        corruption_entities : ndarray, shape [n]
            A list of entities that will used in the evaluation step to
            generate negatives that will be ranked against
            candidate statements. If None, all entities will be used.
        max_negatives : int
            The maximum number of corrupted triples to generate during
            evaluation. The higher this value,
            the harder the ranking task.
        seed : int
            Seed to use for reproducible results.


        Returns
        -------
        X_pred : ndarray, shape [n, 3]
            A list of new facts predicted to be true.


        Examples
        --------
        >>> import numpy as np
        >>> from ampligraph.discovery import discover_facts

        >>> X = np.array([['a', 'y', 'b'],
        >>>               ['b', 'y', 'a'],
        >>>               ['a', 'y', 'c'],
        >>>               ['c', 'y', 'a'],
        >>>               ['a', 'y', 'd'],
        >>>               ['c', 'y', 'd'],
        >>>               ['b', 'y', 'c'],
        >>>               ['f', 'y', 'e']])
        >>>

                    #TODO

        >>> X_pred = discover_facts(X)
        >>> ([['a', 'y', 'e'],
        >>>  ['f', 'y', 'a'],
        >>>  ['c', 'y', 'e']])

    """

    if not model.is_fitted:
        msg = 'Model is not fitted.'
        logger.error(msg)
        raise ValueError(msg)

    if not model.is_fitted_on(X):
        msg = 'Model might not be fitted on this data.'
        logger.warning(msg)
        # raise ValueError(msg)

    if strategy not in ['exhaustive', 'random_uniform']:
        msg = '%s is not a valid strategy.' % strategy
        logger.error(msg)
        raise ValueError(msg)

    if target_rel is None:
        msg = 'No target relation specified. Using all relations to ' \
              'generate candidate statements.'
        logger.info(msg)
    else:
        if target_rel not in model.rel_to_idx.keys():
            msg = 'Target relation not found in model.'
            logger.error(msg)
            raise ValueError(msg)

    # rnd = np.random.RandomState(seed)

    # Remove unseen entities
    X_filtered = filter_unseen_entities(X, model)

    if target_rel is None:
        rel_list = [x for x in model.rel_to_idx.keys()]
    else:
        rel_list = [target_rel]

    discoveries = []

    # Iterate through relations
    for relation in rel_list:

        logger.debug('Generating candidates for relation: %s' % relation)
        candidate_generator = generate_candidates(X_filtered, strategy,
                                                  relation, max_candidates)

        for candidates in candidate_generator:

            logger.debug('Generated %d candidate statements.' %
                         len(candidates))

            # Get ranks of candidate statements
            ranks = evaluate_performance(candidates,
                                         model=model,
                                         filter_triples=X,
                                         use_default_protocol=True,
                                         verbose=True)

            # Select candidate statements within the top_n predicted ranks
            # standard protocol evaluates against corruptions on both sides,
            # we just average the ranks here
            num_ranks = len(ranks) // 2
            s_corruption_ranks = ranks[:num_ranks]
            o_corruption_ranks = ranks[num_ranks:]

            avg_ranks = np.mean([s_corruption_ranks, o_corruption_ranks],
                                axis=0)

            preds = np.array(avg_ranks) >= top_n

            discoveries.append(candidates[preds])

    logger.info('Discovered %d facts' % len(discoveries))

    return np.hstack(discoveries)


def generate_candidates(X, strategy, target_rel, max_candidates,
                        consolidate_sides=False):
    """ Generate candidate statements from an existing knowledge
        graph using a defined strategy.

        Parameters
        ----------

        strategy: string
            The candidates generation strategy. Choose from 'exhaustive',
            'random_uniform'.
            - 'exhaustive' strategy generates all possible candidates given
                the ```target_rel``` and ```consolidate_sides``` parameter.
            - 'random_uniform' generates N candidates (N <= max_candidates)
                based on a uniform random sampling of head and tail entities.
        max_candidates: int or float
            The maximum numbers of candidates generated by 'strategy'.
            Can be an absolute number or a percentage [0,1].
            This does not guarantee the number of candidates generated.
        target_rel : str
            Target relation to focus on. The function will discover facts
            only for that specific relation type.
            If None, the function attempts to discover new facts for all
            relation types in the graph.
        consolidate_sides: bool
            If True will generate candidate statements as a product of
            unique head and tail entities, otherwise will
            consider head and tail entitites separately. Default: False.
        seed : int
            Seed to use for reproducible results.

        Returns
        -------
        X_candidates : ndarray, shape [n, 3]
            A list of candidate statements.


        Examples
        --------
        >>> import numpy as np
        >>> from ampligraph.discovery import discover_facts

        >>> X = np.array([['a', 'y', 'b'],
        >>>               ['b', 'y', 'a'],
        >>>               ['a', 'y', 'c'],
        >>>               ['c', 'y', 'a'],
        >>>               ['a', 'y', 'd'],
        >>>               ['c', 'y', 'd'],
        >>>               ['b', 'y', 'c'],
        >>>               ['f', 'y', 'e']])

        >>> X_pred = discover_facts(X)
        >>> ([['a', 'y', 'e'],
        >>>  ['f', 'y', 'a'],
        >>>  ['c', 'y', 'e']])

    """

    if strategy not in ['random_uniform', 'exhaustive']:
        msg = '%s is not a valid candidate generation strategy.' % strategy
        raise ValueError(msg)

    if target_rel not in np.unique(X[:, 1]):
        # Not raising error as may be case where target_rel is
        # not in X
        msg = 'Target relation is not found in triples.'
        logger.warning(msg)

    if not isinstance(max_candidates, (float, int)):
        msg = 'Parameter max_candidates must be a float or int.'
        raise ValueError(msg)

    if max_candidates <= 0:
        msg = 'Parameter max_candidates must be a positive integer ' \
              'or float in range (0,1].'
        raise ValueError(msg)

    if isinstance(max_candidates, float):
        _max_candidates = int(max_candidates * len(X))
    elif isinstance(max_candidates, int):
        _max_candidates = max_candidates

    # Get entities linked with this relation
    if consolidate_sides:
        e_s = np.unique(np.concatenate((X[:, 0], X[:, 2])))
        e_o = e_s
    else:
        e_s = np.unique(X[:, 0])
        e_o = np.unique(X[:, 2])

    if strategy == 'exhaustive':

        logger.info('Generating candidates using exhaustive strategy.')

        # Exhaustive, generate all combinations of subject and object
        # entities for target_rel

        # lets not explode the memory here then ..
        for ent in e_s:
            X_candidates = np.array(
                np.meshgrid(ent, target_rel, e_o)).T.reshape(-1, 3)

            # Filter statements that are in X
            X_candidates = _setdiff2d(X_candidates, X)

            # NB: May want to consider filtering triples of form:
            #     <ent_id1, target_rel, ent_id1>, but
            # this seems less of a problem if considering a single
            # relationship at time, and with consolidate_sides=False

            yield X_candidates

    elif strategy == 'random_uniform':

        logger.info('Generating candidates using random_uniform strategy.')

        # Take sqrt of max_candidates so that:
        #   len(meshgrid result) == max_candidates
        sample_size = int(np.sqrt(_max_candidates))

        sample_e_s = np.random.choice(e_s, size=sample_size, replace=False)
        sample_e_o = np.random.choice(e_o, size=sample_size, replace=False)

        X_candidates = np.array(
            np.meshgrid(sample_e_s, target_rel, sample_e_o)).T.reshape(-1, 3)

        # Filter out statements that are in X
        X_candidates = _setdiff2d(X_candidates, X)

        yield X_candidates

    return


def _setdiff2d(A, B):
    """ Utility function equivalent to numpy.setdiff1d on 2d arrays.

    Parameters
    ----------

    A : ndarray, shape [n, m]

    B : ndarray, shape [n, m]

    Returns
    -------
    np.array, shape [k, m]
        Rows of A that are not in B.

    """

    if len(A.shape) != 2 or len(B.shape) != 2:
        raise RuntimeError('Input arrays must be 2-dimensional.')

    tmp = np.prod(np.swapaxes(A[:, :, None], 1, 2) == B, axis=2)
    return A[~ np.sum(np.cumsum(tmp, axis=0) * tmp == 1, axis=1).astype(bool)]
