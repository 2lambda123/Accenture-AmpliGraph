{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "import pandas as pd\n",
    "tf.config.set_soft_device_placement(False)\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "import numpy as np\n",
    "from ampligraph.datasets import load_fb15k_237, load_yago3_10\n",
    "from ampligraph.evaluation.protocol import create_mappings, to_idx\n",
    "\n",
    "from ampligraph.evaluation.metrics import mrr_score, hits_at_n_score, mr_score\n",
    "import time\n",
    "print(tf.__version__)\n",
    "assert(tf.__version__.startswith('2.3'))\n",
    "\n",
    "from ampligraph.datasets import load_fb15k_237, load_fb13, load_fb15k, load_wn11, load_wn18, load_wn18rr, load_yago3_10\n",
    "from ampligraph.latent_features import ScoringBasedEmbeddingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "def nll(scores_pos, scores_neg, eta):\n",
    "    scores_neg_reshaped = tf.reshape(scores_neg, [eta, tf.shape(scores_pos)[0]])\n",
    "    neg_exp = tf.exp(scores_neg_reshaped)\n",
    "    pos_exp = tf.exp(scores_pos)\n",
    "    softmax_score = pos_exp / (tf.reduce_sum(neg_exp, axis=0) + pos_exp)\n",
    "\n",
    "    loss = -tf.reduce_sum(tf.math.log(softmax_score))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/eval without partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "     29/Unknown - 1s 51ms/step - loss: 13395.2031\n",
      "Epoch 00001: loss improved from inf to 13395.20312, saving model to ./chkpt1\n",
      "29/29 [==============================] - 2s 52ms/step - loss: 13395.2031\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - ETA: 0s - loss: 12786.1338\n",
      "Epoch 00002: loss improved from 13395.20312 to 12786.13379, saving model to ./chkpt1\n",
      "29/29 [==============================] - 1s 40ms/step - loss: 12786.1338\n",
      "Epoch 3/10\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 12628.9590\n",
      "Epoch 00003: loss improved from 12786.13379 to 12509.62207, saving model to ./chkpt1\n",
      "29/29 [==============================] - 1s 40ms/step - loss: 12509.6221\n",
      "Epoch 4/10\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 12431.5869\n",
      "Epoch 00004: loss improved from 12509.62207 to 12343.49121, saving model to ./chkpt1\n",
      "29/29 [==============================] - 1s 40ms/step - loss: 12343.4912\n",
      "Epoch 5/10\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 12299.8682\n",
      "9 triples containing invalid keys skipped!\n",
      "177/177 [==============================] - 5s 26ms/step\n",
      "\n",
      "Epoch 00005: loss improved from 12343.49121 to 12230.34668, saving model to ./chkpt1\n",
      "29/29 [==============================] - 6s 222ms/step - loss: 12230.3467 - val_mrr: 0.0915 - val_mr: 470.8622 - val_hits@1: 0.0000e+00 - val_hits@10: 0.2515\n",
      "Epoch 6/10\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 12202.9531\n",
      "Epoch 00006: loss improved from 12230.34668 to 12145.55566, saving model to ./chkpt1\n",
      "29/29 [==============================] - 1s 40ms/step - loss: 12145.5557\n",
      "Epoch 7/10\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 12129.2334\n",
      "Epoch 00007: loss improved from 12145.55566 to 12080.31348, saving model to ./chkpt1\n",
      "29/29 [==============================] - 1s 40ms/step - loss: 12080.3135\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - ETA: 0s - loss: 12026.8916\n",
      "Epoch 00008: loss improved from 12080.31348 to 12026.89160, saving model to ./chkpt1\n",
      "29/29 [==============================] - 1s 40ms/step - loss: 12026.8916\n",
      "Epoch 9/10\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 12020.0488\n",
      "Epoch 00009: loss improved from 12026.89160 to 11982.40527, saving model to ./chkpt1\n",
      "29/29 [==============================] - 1s 41ms/step - loss: 11982.4053\n",
      "Epoch 10/10\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 11978.8486\n",
      "9 triples containing invalid keys skipped!\n",
      "177/177 [==============================] - 5s 26ms/step\n",
      "\n",
      "Epoch 00010: loss improved from 11982.40527 to 11945.12695, saving model to ./chkpt1\n",
      "29/29 [==============================] - 6s 200ms/step - loss: 11945.1270 - val_mrr: 0.0940 - val_mr: 452.6968 - val_hits@1: 0.0000e+00 - val_hits@10: 0.2608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdc6c09b7d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim = tf.optimizers.Adagrad(learning_rate=0.1)\n",
    "# optim = 'adam'\n",
    "\n",
    "# loss = nll\n",
    "# loss = 'self_adversarial'\n",
    "from ampligraph.latent_features.loss_functions import SelfAdversarialLoss\n",
    "loss = SelfAdversarialLoss({'margin': 0.1, 'alpha': 5})\n",
    "\n",
    "model = ScoringBasedEmbeddingModel(eta=50, \n",
    "                                     k=300,\n",
    "                                     scoring_type='TransE')\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=optim, loss=loss)\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint('./chkpt1', monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "model.fit('/home/spai/code/ampligraph_projects/dataset/fb15k-237/train.txt',\n",
    "             batch_size=10000,\n",
    "             epochs=10,\n",
    "             validation_freq=5,\n",
    "             validation_batch_size=100,\n",
    "             validation_data = '/home/spai/code/ampligraph_projects/dataset/fb15k-237/valid.txt',\n",
    "         callbacks=[checkpoint])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "28 triples containing invalid keys skipped!\n",
      "\n",
      "9 triples containing invalid keys skipped!\n",
      "\n",
      "28 triples containing invalid keys skipped!\n",
      "206/206 [==============================] - 92s 446ms/step\n",
      "Time taken: 99.60667252540588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(329.3209218123104,\n",
       " 0.2040090857039047,\n",
       " 0.12819258244446619,\n",
       " 0.3548047754183384)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "ranks = model.evaluate('/home/spai/code/ampligraph_projects/dataset/fb15k-237/test.txt', \n",
    "                       batch_size=100,\n",
    "                       corrupt_side='s,o',\n",
    "         use_filter={'train':'/home/spai/code/ampligraph_projects/dataset/fb15k-237/train.txt',\n",
    "                  'valid':'/home/spai/code/ampligraph_projects/dataset/fb15k-237/valid.txt',\n",
    "                  'test':'/home/spai/code/ampligraph_projects/dataset/fb15k-237/test.txt'})\n",
    "end = time.time()\n",
    "print('Time taken:', end-start)\n",
    "mr_score(ranks), mrr_score(ranks), hits_at_n_score(ranks, 1), hits_at_n_score(ranks, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Checkpoint and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "28 triples containing invalid keys skipped!\n",
      "\n",
      "9 triples containing invalid keys skipped!\n",
      "\n",
      "28 triples containing invalid keys skipped!\n",
      "206/206 [==============================] - 92s 444ms/step\n",
      "Time taken: 99.79198861122131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(329.3209218123104,\n",
       " 0.2040090857039047,\n",
       " 0.12819258244446619,\n",
       " 0.3548047754183384)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "loaded_model = ScoringBasedEmbeddingModel(eta=50, \n",
    "                                     k=300, \n",
    "                                     scoring_type='TransE')\n",
    "loaded_model.load_weights('./chkpt1')\n",
    "ranks = loaded_model.evaluate('/home/spai/code/ampligraph_projects/dataset/fb15k-237/test.txt', \n",
    "                       batch_size=100,\n",
    "                       corrupt_side='s,o',\n",
    "         use_filter={'train':'/home/spai/code/ampligraph_projects/dataset/fb15k-237/train.txt',\n",
    "                  'valid':'/home/spai/code/ampligraph_projects/dataset/fb15k-237/valid.txt',\n",
    "                  'test':'/home/spai/code/ampligraph_projects/dataset/fb15k-237/test.txt'})\n",
    "end = time.time()\n",
    "print('Time taken:', end-start)\n",
    "mr_score(ranks), mrr_score(ranks), hits_at_n_score(ranks, 1), hits_at_n_score(ranks, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training/eval with partition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with RandomEdges partitioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_split: memory before: 0.0Bytes, after: 13.058MB, consumed: 13.058MB; exec time: 33.213s\n"
     ]
    }
   ],
   "source": [
    "from ampligraph.datasets import DummyBackend, SQLiteAdapter\n",
    "from ampligraph.datasets import GraphDataLoader\n",
    "from ampligraph.datasets.graph_partitioner import PARTITION_ALGO_REGISTRY\n",
    "dataset_loader = GraphDataLoader('/home/spai/code/ampligraph_projects/dataset/fb15k-237/train.txt', \n",
    "                                 backend=SQLiteAdapter,\n",
    "                                    batch_size=1000, \n",
    "                                    dataset_type='train', \n",
    "                                    epochs=10,\n",
    "                                    use_indexer=True)\n",
    "\n",
    "# Choose the partitioner \n",
    "partitioner = PARTITION_ALGO_REGISTRY.get('RandomEdges')(dataset_loader, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tf.optimizers.Adam(learning_rate=0.001, amsgrad=True)\n",
    "\n",
    "partitioned_model = ScoringBasedEmbeddingModel(eta=5, \n",
    "                                     k=300, \n",
    "                                     scoring_type='TransE')\n",
    "partitioned_model.compile(optimizer=optim, loss=nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "    274/Unknown - 12s 44ms/step - loss: 1579.7837\n",
      "Epoch 00001: loss improved from inf to 1579.78369, saving model to ./chkpt1\n",
      "274/274 [==============================] - 14s 52ms/step - loss: 1579.7837\n",
      "Epoch 2/10\n",
      "269/274 [============================>.] - ETA: 0s - loss: 1407.4520\n",
      "Epoch 00002: loss improved from 1579.78369 to 1403.83862, saving model to ./chkpt1\n",
      "274/274 [==============================] - 14s 50ms/step - loss: 1403.8386\n",
      "Epoch 3/10\n",
      "273/274 [============================>.] - ETA: 0s - loss: 1248.8979\n",
      "Epoch 00003: loss improved from 1403.83862 to 1248.08704, saving model to ./chkpt1\n",
      "274/274 [==============================] - 14s 51ms/step - loss: 1248.0870\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - ETA: 0s - loss: 1118.7273\n",
      "Epoch 00004: loss improved from 1248.08704 to 1118.72729, saving model to ./chkpt1\n",
      "274/274 [==============================] - 14s 52ms/step - loss: 1118.7273\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - ETA: 0s - loss: 1014.0121\n",
      "Epoch 00005: loss improved from 1118.72729 to 1014.01208, saving model to ./chkpt1\n",
      "274/274 [==============================] - 14s 51ms/step - loss: 1014.0121\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - ETA: 0s - loss: 929.1785\n",
      "Epoch 00006: loss improved from 1014.01208 to 929.17847, saving model to ./chkpt1\n",
      "274/274 [==============================] - 14s 51ms/step - loss: 929.1785\n",
      "Epoch 7/10\n",
      "270/274 [============================>.] - ETA: 0s - loss: 860.3193\n",
      "Epoch 00007: loss improved from 929.17847 to 859.32758, saving model to ./chkpt1\n",
      "274/274 [==============================] - 14s 51ms/step - loss: 859.3276\n",
      "Epoch 8/10\n",
      "269/274 [============================>.] - ETA: 0s - loss: 802.1810\n",
      "Epoch 00008: loss improved from 859.32758 to 801.14594, saving model to ./chkpt1\n",
      "274/274 [==============================] - 14s 51ms/step - loss: 801.1459\n",
      "Epoch 9/10\n",
      "273/274 [============================>.] - ETA: 0s - loss: 752.0069\n",
      "Epoch 00009: loss improved from 801.14594 to 751.79913, saving model to ./chkpt1\n",
      "274/274 [==============================] - 14s 52ms/step - loss: 751.7991\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - ETA: 0s - loss: 709.6334\n",
      "Epoch 00010: loss improved from 751.79913 to 709.63336, saving model to ./chkpt1\n",
      "274/274 [==============================] - 14s 51ms/step - loss: 709.6334\n",
      "180.3483395576477\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "partitioned_model.fit(partitioner,\n",
    "                     batch_size=1000, use_partitioning=True,\n",
    "                     epochs=10)\n",
    "print((time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "28 triples containing invalid keys skipped!\n",
      "52/52 [==============================] - 129s 2s/step\n",
      "Time taken: 132.15588426589966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(504.75254901960784, 0.09983318770378669, 0.0, 0.27379901960784314)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset_loader_test = GraphDataLoader('/home/spai/code/ampligraph_projects/dataset/fb15k-237/test.txt', \n",
    "                                        backend=SQLiteAdapter,\n",
    "                                        batch_size=400, \n",
    "                                        dataset_type='test', \n",
    "                                        epochs=1,\n",
    "                                        use_indexer=partitioned_model.data_handler.get_mapper())\n",
    "\n",
    "start = time.time()\n",
    "ranks = partitioned_model.evaluate(dataset_loader_test, \n",
    "                                   batch_size=400)\n",
    "end = time.time()\n",
    "print('Time taken:', end-start)\n",
    "\n",
    "mr_score(ranks), mrr_score(ranks), hits_at_n_score(ranks, 1), hits_at_n_score(ranks, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioned_model.save_weights('./best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_part_model = ScoringBasedEmbeddingModel(eta=5, \n",
    "                                     k=300, \n",
    "                                     scoring_type='TransE')\n",
    "\n",
    "loaded_part_model.load_weights('./best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "28 triples containing invalid keys skipped!\n",
      "52/52 [==============================] - 133s 3s/step\n",
      "Time taken: 135.7653512954712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(504.75254901960784, 0.09983318770378669, 0.0, 0.27379901960784314)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset_loader_test = GraphDataLoader('/home/spai/code/ampligraph_projects/dataset/fb15k-237/test.txt', \n",
    "                                        backend=SQLiteAdapter,\n",
    "                                        batch_size=400, \n",
    "                                        dataset_type='test', \n",
    "                                        epochs=1,\n",
    "                                        use_indexer=loaded_part_model.data_indexer)\n",
    "\n",
    "start = time.time()\n",
    "ranks = loaded_part_model.evaluate(dataset_loader_test, \n",
    "                                   batch_size=400)\n",
    "end = time.time()\n",
    "print('Time taken:', end-start)\n",
    "\n",
    "mr_score(ranks), mrr_score(ranks), hits_at_n_score(ranks, 1), hits_at_n_score(ranks, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training/eval with partition (default Partitioning Approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.datasets import DummyBackend, SQLiteAdapter\n",
    "from ampligraph.datasets import GraphDataLoader\n",
    "from ampligraph.datasets.graph_partitioner import PARTITION_ALGO_REGISTRY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_split: memory before: 896.0Bytes, after: 12.904MB, consumed: 12.903MB; exec time: 146.49s\n",
      "Epoch 1/10\n",
      "    277/Unknown - 5s 20ms/step - loss: 1689.7427\n",
      "Epoch 00001: loss improved from inf to 1689.05029, saving model to ./chkpt1\n",
      "279/279 [==============================] - 6s 20ms/step - loss: 1689.0503\n",
      "Epoch 2/10\n",
      "277/279 [============================>.] - ETA: 0s - loss: 1590.5535\n",
      "Epoch 00002: loss improved from 1689.05029 to 1590.34705, saving model to ./chkpt1\n",
      "279/279 [==============================] - 5s 17ms/step - loss: 1590.3470\n",
      "Epoch 3/10\n",
      "277/279 [============================>.] - ETA: 0s - loss: 1481.9143\n",
      "Epoch 00003: loss improved from 1590.34705 to 1481.84058, saving model to ./chkpt1\n",
      "279/279 [==============================] - 5s 18ms/step - loss: 1481.8406\n",
      "Epoch 4/10\n",
      "277/279 [============================>.] - ETA: 0s - loss: 1380.2938\n",
      "Epoch 00004: loss improved from 1481.84058 to 1380.22937, saving model to ./chkpt1\n",
      "279/279 [==============================] - 5s 18ms/step - loss: 1380.2294\n",
      "Epoch 5/10\n",
      "277/279 [============================>.] - ETA: 0s - loss: 1290.5410\n",
      "Epoch 00005: loss improved from 1380.22937 to 1290.48267, saving model to ./chkpt1\n",
      "279/279 [==============================] - 5s 19ms/step - loss: 1290.4827\n",
      "Epoch 6/10\n",
      "277/279 [============================>.] - ETA: 0s - loss: 1212.3057\n",
      "Epoch 00006: loss improved from 1290.48267 to 1212.24597, saving model to ./chkpt1\n",
      "279/279 [==============================] - 5s 18ms/step - loss: 1212.2460\n",
      "Epoch 7/10\n",
      "277/279 [============================>.] - ETA: 0s - loss: 1144.1609\n",
      "Epoch 00007: loss improved from 1212.24597 to 1144.09448, saving model to ./chkpt1\n",
      "279/279 [==============================] - 5s 18ms/step - loss: 1144.0945\n",
      "Epoch 8/10\n",
      "277/279 [============================>.] - ETA: 0s - loss: 1084.6311\n",
      "Epoch 00008: loss improved from 1144.09448 to 1084.55872, saving model to ./chkpt1\n",
      "279/279 [==============================] - 5s 18ms/step - loss: 1084.5587\n",
      "Epoch 9/10\n",
      "277/279 [============================>.] - ETA: 0s - loss: 1032.5002\n",
      "Epoch 00009: loss improved from 1084.55872 to 1032.42200, saving model to ./chkpt1\n",
      "279/279 [==============================] - 5s 18ms/step - loss: 1032.4220\n",
      "Epoch 10/10\n",
      "277/279 [============================>.] - ETA: 0s - loss: 986.4651\n",
      "Epoch 00010: loss improved from 1032.42200 to 986.38654, saving model to ./chkpt1\n",
      "279/279 [==============================] - 5s 17ms/step - loss: 986.3865\n",
      "205.86038613319397\n"
     ]
    }
   ],
   "source": [
    "optim = tf.optimizers.Adam(learning_rate=0.001, amsgrad=True)\n",
    "\n",
    "partitioned_model = ScoringBasedEmbeddingModel(eta=5, \n",
    "                                     k=300, \n",
    "                                     scoring_type='TransE')\n",
    "partitioned_model.compile(optimizer=optim, loss=nll)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "partitioned_model.fit('/home/spai/code/ampligraph_projects/dataset/fb15k-237/train.txt',\n",
    "                     batch_size=1000, use_partitioning=True,\n",
    "                     epochs=10)\n",
    "print((time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "28 triples containing invalid keys skipped!\n",
      "53/53 [==============================] - 169s 3s/step\n",
      "Time taken: 173.1760048866272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(703.0901996281436, 0.0938227619140394, 0.0, 0.2562383794891868)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "start = time.time()\n",
    "ranks = partitioned_model.evaluate('/home/spai/code/ampligraph_projects/dataset/fb15k-237/test.txt', \n",
    "                                   batch_size=400)\n",
    "end = time.time()\n",
    "print('Time taken:', end-start)\n",
    "\n",
    "mr_score(ranks), mrr_score(ranks), hits_at_n_score(ranks, 1), hits_at_n_score(ranks, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtered evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "28 triples containing invalid keys skipped!\n",
      "\n",
      "9 triples containing invalid keys skipped!\n",
      "\n",
      "28 triples containing invalid keys skipped!\n",
      "104/104 [==============================] - 1097s 11s/step\n",
      "Time taken: 1193.5984427928925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(577.7298659360016,\n",
       " 0.21288052721907064,\n",
       " 0.14925628730795576,\n",
       " 0.33736177708190623)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "ranks = partitioned_model.evaluate('/home/spai/code/ampligraph_projects/dataset/fb15k-237/test.txt', \n",
    "                       batch_size=200,\n",
    "                       corrupt_side='s,o',\n",
    "                        use_filter={'train':'/home/spai/code/ampligraph_projects/dataset/fb15k-237/train.txt',\n",
    "                              'valid':'/home/spai/code/ampligraph_projects/dataset/fb15k-237/valid.txt',\n",
    "                              'test':'/home/spai/code/ampligraph_projects/dataset/fb15k-237/test.txt'})\n",
    "end = time.time()\n",
    "print('Time taken:', end-start)\n",
    "mr_score(ranks), mrr_score(ranks), hits_at_n_score(ranks, 1), hits_at_n_score(ranks, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_nightly",
   "language": "python",
   "name": "tf_nightly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
