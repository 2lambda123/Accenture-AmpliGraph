{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "import pandas as pd\n",
    "tf.config.set_soft_device_placement(False)\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "import numpy as np\n",
    "from ampligraph.datasets import load_fb15k_237, load_yago3_10\n",
    "from ampligraph.evaluation.protocol import create_mappings, to_idx\n",
    "\n",
    "from ampligraph.evaluation.metrics import mrr_score, hits_at_n_score, mr_score\n",
    "import time\n",
    "print(tf.__version__)\n",
    "assert(tf.__version__.startswith('2.3'))\n",
    "\n",
    "from ampligraph.datasets import load_fb15k_237, load_fb13, load_fb15k, load_wn11, load_wn18, load_wn18rr, load_yago3_10\n",
    "from ampligraph.latent_features import ScoringBasedEmbeddingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "def nll(scores_pred, eta):\n",
    "    scores_neg = scores_pred[1]\n",
    "    scores_pos = scores_pred[0]\n",
    "\n",
    "    scores_neg_reshaped = tf.reshape(scores_neg, [eta, tf.shape(scores_pos)[0]])\n",
    "    neg_exp = tf.exp(scores_neg_reshaped)\n",
    "    pos_exp = tf.exp(scores_pos)\n",
    "    softmax_score = pos_exp / (tf.reduce_sum(neg_exp, axis=0) + pos_exp)\n",
    "\n",
    "    loss = -tf.reduce_sum(tf.math.log(softmax_score))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/eval without partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 17501.9082\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - ETA: 0s - loss: 16930.3594\n",
      "9 triples containing invalid keys skipped!\n",
      "176/176 [==============================] - 49s 279ms/step\n",
      "28/28 [==============================] - 51s 2s/step - loss: 16930.3594 - val_mrr: 0.0965 - val_mr: 1162.6060 - val_hits@1: 0.0035 - val_hits@10: 0.2564\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 16181.6035\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - ETA: 0s - loss: 15331.6602\n",
      "9 triples containing invalid keys skipped!\n",
      "176/176 [==============================] - 16s 89ms/step\n",
      "28/28 [==============================] - 17s 617ms/step - loss: 15331.6602 - val_mrr: 0.0984 - val_mr: 881.6503 - val_hits@1: 0.0033 - val_hits@10: 0.2622\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 14492.6719\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - ETA: 0s - loss: 13709.9258\n",
      "9 triples containing invalid keys skipped!\n",
      "176/176 [==============================] - 16s 89ms/step\n",
      "28/28 [==============================] - 17s 617ms/step - loss: 13709.9258 - val_mrr: 0.0955 - val_mr: 766.0714 - val_hits@1: 0.0034 - val_hits@10: 0.2521\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 12999.6055\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - ETA: 0s - loss: 12359.8516\n",
      "9 triples containing invalid keys skipped!\n",
      "176/176 [==============================] - 16s 92ms/step\n",
      "28/28 [==============================] - 18s 638ms/step - loss: 12359.8516 - val_mrr: 0.0932 - val_mr: 692.4733 - val_hits@1: 0.0033 - val_hits@10: 0.2450\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 11784.2783\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - ETA: 0s - loss: 11267.2197\n",
      "9 triples containing invalid keys skipped!\n",
      "176/176 [==============================] - 16s 91ms/step\n",
      "28/28 [==============================] - 18s 629ms/step - loss: 11267.2197 - val_mrr: 0.0928 - val_mr: 638.3956 - val_hits@1: 0.0034 - val_hits@10: 0.2477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f00f0375b90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ScoringBasedEmbeddingModel(eta=5, \n",
    "                                     k=300, \n",
    "                                     max_ent_size=14505, \n",
    "                                     max_rel_size=237,\n",
    "                                     scoring_type='TransE')\n",
    "\n",
    "model.compile(optimizer='adam', loss=nll)\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint('./chkpt1', monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "model.fit('/home/spai/code/ampligraph_projects/dataset/fb15k-237/train.txt',\n",
    "          batch_size=10000,\n",
    "          validation_batch_size=100,\n",
    "          validation_freq=2,\n",
    "          epochs=10,\n",
    "          validation_data = '/home/spai/code/ampligraph_projects/dataset/fb15k-237/valid.txt')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "28 triples containing invalid keys skipped!\n",
      "52/52 [==============================] - 41s 793ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(647.0359068627452, 0.08983463806823218)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "ranks = model.evaluate('/home/spai/code/ampligraph_projects/dataset/fb15k-237/test.txt', batch_size=400)\n",
    "end = time.time()\n",
    "mr_score(ranks), mrr_score(ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training/eval with partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_split: memory before: 0.0Bytes, after: 13.016MB, consumed: 13.016MB; exec time: 210.76s\n"
     ]
    }
   ],
   "source": [
    "from ampligraph.datasets import DummyBackend, SQLiteAdapter\n",
    "from ampligraph.datasets import GraphDataLoader\n",
    "from ampligraph.datasets.graph_partitioner import PARTITION_ALGO_REGISTRY\n",
    "dataset_loader = GraphDataLoader('/home/spai/code/ampligraph_projects/dataset/fb15k-237/train.txt', \n",
    "                                 backend=SQLiteAdapter,\n",
    "                                    batch_size=1000, \n",
    "                                    dataset_type='train', \n",
    "                                    epochs=10,\n",
    "                                    use_indexer=True)\n",
    "\n",
    "\n",
    "partitioner = PARTITION_ALGO_REGISTRY.get('Bucket')(dataset_loader, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "    277/Unknown - 11s 39ms/step - loss: 1674.0751\n",
      "Epoch 00001: loss improved from inf to 1674.07507, saving model to ./chkpt1\n",
      "277/277 [==============================] - 12s 42ms/step - loss: 1674.0751\n",
      "Epoch 2/10\n",
      "274/277 [============================>.] - ETA: 0s - loss: 1551.6996\n",
      "Epoch 00002: loss improved from 1674.07507 to 1549.06494, saving model to ./chkpt1\n",
      "277/277 [==============================] - 9s 33ms/step - loss: 1549.0649\n",
      "Epoch 3/10\n",
      "274/277 [============================>.] - ETA: 0s - loss: 1434.5685\n",
      "Epoch 00003: loss improved from 1549.06494 to 1432.87756, saving model to ./chkpt1\n",
      "277/277 [==============================] - 10s 35ms/step - loss: 1432.8776\n",
      "Epoch 4/10\n",
      "274/277 [============================>.] - ETA: 0s - loss: 1332.1746\n",
      "Epoch 00004: loss improved from 1432.87756 to 1330.95544, saving model to ./chkpt1\n",
      "277/277 [==============================] - 10s 35ms/step - loss: 1330.9554\n",
      "Epoch 5/10\n",
      "274/277 [============================>.] - ETA: 0s - loss: 1244.5736\n",
      "Epoch 00005: loss improved from 1330.95544 to 1243.64014, saving model to ./chkpt1\n",
      "277/277 [==============================] - 9s 34ms/step - loss: 1243.6401\n",
      "Epoch 6/10\n",
      "274/277 [============================>.] - ETA: 0s - loss: 1169.8523\n",
      "Epoch 00006: loss improved from 1243.64014 to 1169.10303, saving model to ./chkpt1\n",
      "277/277 [==============================] - 10s 35ms/step - loss: 1169.1030\n",
      "Epoch 7/10\n",
      "274/277 [============================>.] - ETA: 0s - loss: 1105.3882\n",
      "Epoch 00007: loss improved from 1169.10303 to 1104.74536, saving model to ./chkpt1\n",
      "277/277 [==============================] - 10s 36ms/step - loss: 1104.7454\n",
      "Epoch 8/10\n",
      "274/277 [============================>.] - ETA: 0s - loss: 1049.2833\n",
      "Epoch 00008: loss improved from 1104.74536 to 1048.74609, saving model to ./chkpt1\n",
      "277/277 [==============================] - 10s 35ms/step - loss: 1048.7461\n",
      "Epoch 9/10\n",
      "274/277 [============================>.] - ETA: 0s - loss: 1000.0872\n",
      "Epoch 00009: loss improved from 1048.74609 to 999.59906, saving model to ./chkpt1\n",
      "277/277 [==============================] - 10s 35ms/step - loss: 999.5991\n",
      "Epoch 10/10\n",
      "274/277 [============================>.] - ETA: 0s - loss: 956.6229\n",
      "Epoch 00010: loss improved from 999.59906 to 956.20343, saving model to ./chkpt1\n",
      "277/277 [==============================] - 9s 34ms/step - loss: 956.2034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efe8c0c9f10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ScoringBasedEmbeddingModel(eta=5, \n",
    "                                     k=300, \n",
    "                                     max_ent_size=9437, \n",
    "                                     max_rel_size=237,\n",
    "                                     scoring_type='TransE')\n",
    "\n",
    "model.compile(optimizer='adam', loss=nll)\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint('./chkpt1', monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "model.fit(partitioner,\n",
    "         batch_size=1000, use_partitioning=True,\n",
    "         epochs=10, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "28 triples containing invalid keys skipped!\n",
      "21/21 [==============================] - 167s 8s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1269.91475, 0.08386363417991036)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "ranks = model.evaluate('/home/spai/code/ampligraph_projects/dataset/fb15k-237/test.txt', \n",
    "                       batch_size=1000)\n",
    "end = time.time()\n",
    "mr_score(ranks), mrr_score(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_nightly",
   "language": "python",
   "name": "tf_nightly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
