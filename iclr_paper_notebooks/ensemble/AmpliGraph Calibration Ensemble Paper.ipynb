{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import gc\n",
    "\n",
    "import ampligraph.datasets\n",
    "from ampligraph.datasets import load_wn18, load_wn18rr, load_fb15k, load_fb15k_237, load_yago3_10\n",
    "from ampligraph.latent_features import ComplEx, DistMult, TransE, HolE\n",
    "from ampligraph.evaluation import evaluate_performance, mr_score, mrr_score, hits_at_n_score, generate_corruptions_for_eval\n",
    "from ampligraph.latent_features import *\n",
    "from ampligraph.datasets.numpy_adapter import NumpyDatasetAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"AmpliGraph/experiments/config.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import check_random_state\n",
    "import abc\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from ampligraph.latent_features.loss_functions import LOSS_REGISTRY\n",
    "from ampligraph.latent_features.regularizers import REGULARIZER_REGISTRY\n",
    "from ampligraph.latent_features.optimizers import OPTIMIZER_REGISTRY, SGDOptimizer\n",
    "from ampligraph.latent_features.initializers import INITIALIZER_REGISTRY, DEFAULT_XAVIER_IS_UNIFORM\n",
    "from ampligraph.evaluation import generate_corruptions_for_fit, to_idx, generate_corruptions_for_eval, \\\n",
    "    hits_at_n_score, mrr_score\n",
    "from ampligraph.datasets import AmpligraphDatasetAdapter, NumpyDatasetAdapter\n",
    "from functools import partial\n",
    "from ampligraph.latent_features import constants as constants\n",
    "from ampligraph.latent_features.constants import *\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "class Ensemble(object):\n",
    "    def __init__(self, mode, models, epochs, batches_count, eta, \n",
    "                 loss, loss_params={}, \n",
    "                 embedding_model_params={},\n",
    "                 optimizer='adam', optimizer_params={}, \n",
    "                 verbose=True):\n",
    "        self.eval_dataset_handle = None\n",
    "        self.mode = mode\n",
    "        self.models = models\n",
    "        self.ent_to_idx = models[0].ent_to_idx\n",
    "        self.rel_to_idx = models[0].rel_to_idx\n",
    "        assert all(e.ent_to_idx == self.ent_to_idx for e in models)\n",
    "        assert all(e.rel_to_idx == self.rel_to_idx for e in models)\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.is_filtered = False\n",
    "        self.is_fitted = True\n",
    "        self.seed = 0\n",
    "        \n",
    "        self.batches_count = batches_count\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        self.embedding_model_params = embedding_model_params\n",
    "        self.loss_params = loss_params\n",
    "\n",
    "        try:\n",
    "            self.loss = LOSS_REGISTRY[loss](self.eta, self.loss_params, verbose=verbose)\n",
    "        except KeyError:\n",
    "            msg = 'Unsupported loss function: {}'.format(loss)\n",
    "            logger.error(msg)\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        self.optimizer_params = optimizer_params\n",
    "\n",
    "        try:\n",
    "            self.optimizer = OPTIMIZER_REGISTRY[optimizer](self.optimizer_params, \n",
    "                                                           self.batches_count, \n",
    "                                                            verbose)\n",
    "        except KeyError:\n",
    "            msg = 'Unsupported optimizer: {}'.format(optimizer)\n",
    "            logger.error(msg)\n",
    "            raise ValueError(msg)\n",
    "        \n",
    "        self.tf_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "        self.tf_config.gpu_options.allow_growth = True\n",
    "        self.sess_train = None\n",
    "        self.sess_predict = None\n",
    "\n",
    "    def _save_trained_params(self):\n",
    "        self.trained_model_params = self.sess_train.run(self.ensemble)\n",
    "\n",
    "    def _load_model_from_trained_params(self):\n",
    "        self.ensemble = tf.constant(self.trained_model_params)\n",
    "        \n",
    "    def _initialize_parameters(self):\n",
    "        self.ensemble = tf.get_variable('ensemble', #shape=[len(self.models)],\n",
    "                                        initializer=np.ones(len(self.models), dtype=np.float32))#tf.contrib.layers.xavier_initializer(uniform=False, seed=self.seed))\n",
    "          \n",
    "    def _lookup_embeddings(self, i, x):\n",
    "        e_s = tf.nn.embedding_lookup(self.ent_emb[i], x[:, 0])\n",
    "        e_p = tf.nn.embedding_lookup(self.rel_emb[i], x[:, 1], name='embedding_lookup_predicate')\n",
    "        e_o = tf.nn.embedding_lookup(self.ent_emb[i], x[:, 2])\n",
    "        return e_s, e_p, e_o\n",
    "    \n",
    "    def set_filter_for_eval(self):\n",
    "        \"\"\"Configures to use filter\n",
    "        \"\"\"\n",
    "        self.is_filtered = True\n",
    "\n",
    "    def configure_evaluation_protocol(self, config=None):\n",
    "        if config is None:\n",
    "            config = {'corruption_entities': DEFAULT_CORRUPTION_ENTITIES,\n",
    "                      'corrupt_side': DEFAULT_CORRUPT_SIDE_EVAL,\n",
    "                      'default_protocol': DEFAULT_PROTOCOL_EVAL}\n",
    "        self.eval_config = config\n",
    "        if self.eval_config['default_protocol']:\n",
    "            self.eval_config['corrupt_side'] = 's+o'\n",
    "\n",
    "    def test_retrieve(self, mode):\n",
    "        if self.is_filtered:\n",
    "            test_generator = partial(self.eval_dataset_handle.get_next_batch_with_filter,\n",
    "                                     batch_size=1, dataset_type=mode)\n",
    "        else:\n",
    "            test_generator = partial(self.eval_dataset_handle.get_next_eval_batch, batch_size=1, dataset_type=mode)\n",
    "            \n",
    "        batch_iterator = iter(test_generator())\n",
    "        indices_obj = np.empty(shape=(0, 1), dtype=np.int32)\n",
    "        indices_sub = np.empty(shape=(0, 1), dtype=np.int32)\n",
    "        for i in range(self.eval_dataset_handle.get_size(mode)):\n",
    "            if self.is_filtered:\n",
    "                out, indices_obj, indices_sub = next(batch_iterator)\n",
    "            else:\n",
    "                out = next(batch_iterator)\n",
    "  \n",
    "            yield out, indices_obj, indices_sub\n",
    "            \n",
    "            \n",
    "    def _initialize_eval_graph(self, mode=\"test\"):\n",
    "        \"\"\"Initialize the evaluation graph. \n",
    "        \n",
    "        Use prime number based filtering strategy (refer set_filter_for_eval()), if the filter is set\n",
    "        \"\"\"\n",
    "\n",
    "        # Use a data generator which returns a test triple along with the subjects and objects indices for filtering\n",
    "        # The last two data are used if the graph is large. They are the embeddings of the entities that must be \n",
    "        # loaded on the GPU before scoring and the indices of those embeddings. \n",
    "        dataset = tf.data.Dataset.from_generator(partial(self.test_retrieve, mode=mode),\n",
    "                                                 output_types=(tf.int32, tf.int32, tf.int32),\n",
    "                                                 output_shapes=((1, 3), (None, 1), (None, 1))) \n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.prefetch(1)\n",
    "        dataset_iter = dataset.make_one_shot_iterator()\n",
    "        self.X_test_tf, indices_obj, indices_sub = dataset_iter.get_next()\n",
    "\n",
    "        use_default_protocol = self.eval_config.get('default_protocol', DEFAULT_PROTOCOL_EVAL)\n",
    "        corrupt_side = self.eval_config.get('corrupt_side', DEFAULT_CORRUPT_SIDE_EVAL)\n",
    "        # Dependencies that need to be run before scoring\n",
    "        test_dependency = []\n",
    "        # For large graphs\n",
    "\n",
    "        # Rather than generating corruptions in batches do it at once on the GPU for small or medium sized graphs\n",
    "        all_entities_np = np.arange(len(self.ent_to_idx))\n",
    "\n",
    "        corruption_entities = self.eval_config.get('corruption_entities', DEFAULT_CORRUPTION_ENTITIES)\n",
    "\n",
    "        if corruption_entities == 'all':\n",
    "            corruption_entities = all_entities_np\n",
    "        elif isinstance(corruption_entities, np.ndarray):\n",
    "            corruption_entities = corruption_entities\n",
    "        else:\n",
    "            msg = 'Invalid type for corruption entities.'\n",
    "            logger.error(msg)\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        # Entities that must be used while generating corruptions\n",
    "        self.corruption_entities_tf = tf.constant(corruption_entities, dtype=tf.int32)\n",
    "\n",
    "        corrupt_side = self.eval_config.get('corrupt_side', DEFAULT_CORRUPT_SIDE_EVAL)\n",
    "        # Generate corruptions\n",
    "        self.out_corr = generate_corruptions_for_eval(self.X_test_tf,\n",
    "                                                      self.corruption_entities_tf,\n",
    "                                                      corrupt_side)\n",
    "\n",
    "        scores_predict = []\n",
    "        score_positive = []\n",
    "        \n",
    "        if self.mode == 'calibration':\n",
    "            for i, m in enumerate(self.models):\n",
    "                w = tf.Variable(m.calibration_parameters[0], dtype=tf.float32, trainable=False)\n",
    "                b = tf.Variable(m.calibration_parameters[1], dtype=tf.float32, trainable=False)\n",
    "                # Compute scores for negatives\n",
    "                e_s, e_p, e_o = self._lookup_embeddings(i, self.out_corr)\n",
    "                scores_predict.append(tf.sigmoid(-(w*m._fn(e_s, e_p, e_o)+b)))\n",
    "                # Compute scores for positive\n",
    "                e_s, e_p, e_o = self._lookup_embeddings(i, self.X_test_tf)\n",
    "                score_positive.append(tf.sigmoid(-(w*m._fn(e_s, e_p, e_o)+b)))\n",
    "\n",
    "            dummy = tf.ones(shape=tf.shape(tf.reshape(tf.exp(self.ensemble), (-1, 1))))\n",
    "            scores_predict = tf.squeeze(tf.matmul(tf.stack(scores_predict, axis=1), dummy))\n",
    "            score_positive = tf.squeeze(tf.matmul(tf.stack(score_positive, axis=1), dummy))\n",
    "        elif self.mode == 'expit':\n",
    "            for i, m in enumerate(self.models):\n",
    "                # Compute scores for negatives\n",
    "                e_s, e_p, e_o = self._lookup_embeddings(i, self.out_corr)\n",
    "                scores_predict.append(tf.sigmoid(m._fn(e_s, e_p, e_o)))\n",
    "                # Compute scores for positive\n",
    "                e_s, e_p, e_o = self._lookup_embeddings(i, self.X_test_tf)\n",
    "                score_positive.append(tf.sigmoid(m._fn(e_s, e_p, e_o)))\n",
    "\n",
    "            dummy = tf.ones(shape=tf.shape(tf.reshape(tf.exp(self.ensemble), (-1, 1))))\n",
    "            scores_predict = tf.squeeze(tf.matmul(tf.stack(scores_predict, axis=1), dummy))\n",
    "            score_positive = tf.squeeze(tf.matmul(tf.stack(score_positive, axis=1), dummy))\n",
    "        elif self.mode == 'mean':\n",
    "            for i, m in enumerate(self.models):\n",
    "                # Compute scores for negatives\n",
    "                e_s, e_p, e_o = self._lookup_embeddings(i, self.out_corr)\n",
    "                scores_predict.append(m._fn(e_s, e_p, e_o))\n",
    "                # Compute scores for positive\n",
    "                e_s, e_p, e_o = self._lookup_embeddings(i, self.X_test_tf)\n",
    "                score_positive.append(m._fn(e_s, e_p, e_o))\n",
    "                \n",
    "            dummy = tf.ones(shape=tf.shape(tf.reshape(tf.exp(self.ensemble), (-1, 1))))\n",
    "            scores_predict = tf.squeeze(tf.matmul(tf.stack(scores_predict, axis=1), dummy))\n",
    "            score_positive = tf.squeeze(tf.matmul(tf.stack(score_positive, axis=1), dummy))\n",
    "        elif self.mode == 'linear':\n",
    "            for i, m in enumerate(self.models):\n",
    "                # Compute scores for negatives\n",
    "                e_s, e_p, e_o = self._lookup_embeddings(i, self.out_corr)\n",
    "                scores_predict.append(m._fn(e_s, e_p, e_o))\n",
    "                # Compute scores for positive\n",
    "                e_s, e_p, e_o = self._lookup_embeddings(i, self.X_test_tf)\n",
    "                score_positive.append(m._fn(e_s, e_p, e_o))\n",
    "                \n",
    "            dummy = tf.reshape(tf.exp(self.ensemble), (-1, 1))\n",
    "            scores_predict = tf.squeeze(tf.matmul(tf.stack(scores_predict, axis=1), dummy))\n",
    "            score_positive = tf.squeeze(tf.matmul(tf.stack(score_positive, axis=1), dummy))\n",
    "        else:\n",
    "            raise ValueError(\"Unknown mode: {}\".format(self.mode))\n",
    "            \n",
    "        use_default_protocol = self.eval_config.get('default_protocol', DEFAULT_PROTOCOL_EVAL)\n",
    "\n",
    "        if use_default_protocol:\n",
    "            obj_corruption_scores = tf.slice(scores_predict,\n",
    "                                             [0],\n",
    "                                             [tf.shape(scores_predict)[0] // 2])\n",
    "\n",
    "            subj_corruption_scores = tf.slice(scores_predict,\n",
    "                                              [tf.shape(scores_predict)[0] // 2],\n",
    "                                              [tf.shape(scores_predict)[0] // 2])\n",
    "\n",
    "        # this is to remove the positives from corruptions - while ranking with filter\n",
    "        positives_among_obj_corruptions_ranked_higher = tf.constant(0, dtype=tf.int32)\n",
    "        positives_among_sub_corruptions_ranked_higher = tf.constant(0, dtype=tf.int32)\n",
    "        \n",
    "        if self.is_filtered:\n",
    "            # If a list of specified entities were used for corruption generation\n",
    "            if isinstance(self.eval_config.get('corruption_entities',\n",
    "                                               DEFAULT_CORRUPTION_ENTITIES), np.ndarray):\n",
    "                corruption_entities = self.eval_config.get('corruption_entities',\n",
    "                                                           DEFAULT_CORRUPTION_ENTITIES).astype(np.int32)\n",
    "                if corruption_entities.ndim == 1:\n",
    "                    corruption_entities = np.expand_dims(corruption_entities, 1)\n",
    "                # If the specified key is not present then it would return the length of corruption_entities\n",
    "                corruption_mapping = tf.contrib.lookup.MutableDenseHashTable(key_dtype=tf.int32,\n",
    "                                                                             value_dtype=tf.int32,\n",
    "                                                                             default_value=len(corruption_entities),\n",
    "                                                                             empty_key=-2,\n",
    "                                                                             deleted_key=-1)\n",
    "\n",
    "                insert_lookup_op = corruption_mapping.insert(corruption_entities, \n",
    "                                                             tf.reshape(tf.range(tf.shape(corruption_entities)[0],\n",
    "                                                                                 dtype=tf.int32), (-1, 1)))\n",
    "\n",
    "                with tf.control_dependencies([insert_lookup_op]):\n",
    "                    # remap the indices of objects to the smaller set of corruptions\n",
    "                    indices_obj = corruption_mapping.lookup(indices_obj)\n",
    "                    # mask out the invalid indices (i.e. the entities that were not in corruption list\n",
    "                    indices_obj = tf.boolean_mask(indices_obj, indices_obj < len(corruption_entities))\n",
    "                    # remap the indices of subject to the smaller set of corruptions\n",
    "                    indices_sub = corruption_mapping.lookup(indices_sub)\n",
    "                    # mask out the invalid indices (i.e. the entities that were not in corruption list\n",
    "                    indices_sub = tf.boolean_mask(indices_sub, indices_sub < len(corruption_entities))\n",
    "\n",
    "            # get the scores of positives present in corruptions\n",
    "            if use_default_protocol:\n",
    "                scores_pos_obj = tf.gather(obj_corruption_scores, indices_obj) \n",
    "                scores_pos_sub = tf.gather(subj_corruption_scores, indices_sub)\n",
    "            else:\n",
    "                scores_pos_obj = tf.gather(scores_predict, indices_obj) \n",
    "                if corrupt_side == 's+o':\n",
    "                    scores_pos_sub = tf.gather(scores_predict, indices_sub + len(corruption_entities))\n",
    "                else:\n",
    "                    scores_pos_sub = tf.gather(scores_predict, indices_sub)\n",
    "            # compute the ranks of the positives present in the corruptions and \n",
    "            # see how many are ranked higher than the test triple\n",
    "            if corrupt_side == 's+o' or corrupt_side == 'o':\n",
    "                positives_among_obj_corruptions_ranked_higher = tf.reduce_sum(\n",
    "                    tf.cast(scores_pos_obj >= score_positive, tf.int32)) \n",
    "            if corrupt_side == 's+o' or corrupt_side == 's':\n",
    "                positives_among_sub_corruptions_ranked_higher = tf.reduce_sum(\n",
    "                    tf.cast(scores_pos_sub >= score_positive, tf.int32)) \n",
    "                \n",
    "        # compute the rank of the test triple and subtract the positives(from corruptions) that are ranked higher\n",
    "        if use_default_protocol:       \n",
    "            self.rank = tf.stack([tf.reduce_sum(tf.cast(\n",
    "                subj_corruption_scores >= score_positive, \n",
    "                tf.int32)) + 1 - positives_among_sub_corruptions_ranked_higher,\n",
    "                tf.reduce_sum(tf.cast(obj_corruption_scores >= score_positive,\n",
    "                                      tf.int32)) + 1 - positives_among_obj_corruptions_ranked_higher], 0)\n",
    "        else:\n",
    "            self.rank = tf.reduce_sum(tf.cast(\n",
    "                scores_predict >= score_positive, \n",
    "                tf.int32)) + 1 - positives_among_sub_corruptions_ranked_higher - \\\n",
    "                positives_among_obj_corruptions_ranked_higher\n",
    "\n",
    "        \n",
    "    def get_ranks(self, dataset_handle):\n",
    "        if not self.is_fitted:\n",
    "            msg = 'Model has not been fitted.'\n",
    "            logger.error(msg)\n",
    "            raise RuntimeError(msg)\n",
    "        \n",
    "        self.eval_dataset_handle = dataset_handle\n",
    "\n",
    "        # build tf graph for predictions\n",
    "        if self.sess_predict is None:\n",
    "            tf.reset_default_graph()\n",
    "            self.rnd = check_random_state(self.seed)\n",
    "            tf.random.set_random_seed(self.seed)\n",
    "\n",
    "            self.ent_emb = [tf.Variable(m.trained_model_params[0], dtype=tf.float32) for m in self.models]\n",
    "            self.rel_emb = [tf.Variable(m.trained_model_params[1], dtype=tf.float32) for m in self.models]\n",
    "      \n",
    "            self._load_model_from_trained_params()\n",
    "            # build the eval graph\n",
    "            self._initialize_eval_graph()\n",
    "\n",
    "            sess = tf.Session()\n",
    "            sess.run(tf.tables_initializer())\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            self.sess_predict = sess\n",
    "\n",
    "        ranks = []\n",
    "                                                   \n",
    "        for i in tqdm(range(self.eval_dataset_handle.get_size('test'))):\n",
    "            rank = self.sess_predict.run(self.rank)\n",
    "            if self.eval_config.get('default_protocol', DEFAULT_PROTOCOL_EVAL): \n",
    "                ranks.append(list(rank))\n",
    "            else:\n",
    "                ranks.append(rank)\n",
    "        return ranks\n",
    "\n",
    "    def predict(self, X, from_idx=False):\n",
    "        if not self.is_fitted:\n",
    "            msg = 'Model has not been fitted.'\n",
    "            logger.error(msg)\n",
    "            raise RuntimeError(msg)\n",
    "        # adapt the data with numpy adapter for internal use\n",
    "        dataset_handle = NumpyDatasetAdapter()\n",
    "        dataset_handle.use_mappings(self.rel_to_idx, self.ent_to_idx)\n",
    "        dataset_handle.set_data(X, \"test\", mapped_status=from_idx)\n",
    "        \n",
    "        self.eval_dataset_handle = dataset_handle\n",
    "        \n",
    "        # build tf graph for predictions\n",
    "        if self.sess_predict is None:\n",
    "            tf.reset_default_graph()\n",
    "            self.rnd = check_random_state(self.seed)\n",
    "            tf.random.set_random_seed(self.seed)\n",
    "\n",
    "            self.ent_emb = [tf.Variable(m.trained_model_params[0], dtype=tf.float32) for m in self.models]\n",
    "            self.rel_emb = [tf.Variable(m.trained_model_params[1], dtype=tf.float32) for m in self.models]\n",
    "      \n",
    "            self._load_model_from_trained_params()\n",
    "            # build the eval graph\n",
    "            self._initialize_eval_graph()\n",
    "\n",
    "            sess = tf.Session()\n",
    "            sess.run(tf.tables_initializer())\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            self.sess_predict = sess\n",
    "\n",
    "        scores = []\n",
    "                                                   \n",
    "        for i in tqdm(range(self.eval_dataset_handle.get_size('test'))):\n",
    "            score = self.sess_predict.run([score_positive])\n",
    "            if self.eval_config.get('default_protocol', DEFAULT_PROTOCOL_EVAL): \n",
    "                scores.extend(list(score)) \n",
    "            else:\n",
    "                scores.append(score)\n",
    "\n",
    "        return scores\n",
    "    \n",
    "    \n",
    "    def end_evaluation(self):\n",
    "        \"\"\"End the evaluation and close the Tensorflow session.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.is_filtered and self.eval_dataset_handle is not None:\n",
    "            self.eval_dataset_handle.cleanup()\n",
    "            self.eval_dataset_handle = None\n",
    "            \n",
    "        if self.sess_predict is not None:\n",
    "            self.sess_predict.close()\n",
    "            \n",
    "        self.sess_predict = None\n",
    "        self.is_filtered = False\n",
    "        \n",
    "        self.eval_config = {}\n",
    "        \n",
    "\n",
    "    def _get_model_loss(self, dataset_iterator):\n",
    "        # get the train triples of the batch, unique entities and the corresponding embeddings\n",
    "        # the latter 2 variables are passed only for large graphs. \n",
    "        x_pos_tf = dataset_iterator.get_next()\n",
    "\n",
    "        entities_size = 0\n",
    "        entities_list = None\n",
    "\n",
    "        x_pos = x_pos_tf\n",
    "\n",
    "        scores_pos = []\n",
    "        for i, m in enumerate(self.models):\n",
    "            e_s, e_p, e_o = self._lookup_embeddings(i, x_pos)\n",
    "            scores_pos.append(tf.squeeze(m._fn(e_s, e_p, e_o)))\n",
    "        \n",
    "        scores_pos = tf.squeeze(tf.matmul(tf.stop_gradient(tf.stack(scores_pos, axis=1)), \n",
    "                                          tf.reshape(tf.exp(self.ensemble), (-1, 1))))\n",
    "                    \n",
    "        if self.loss.get_state('require_same_size_pos_neg'):\n",
    "            logger.debug('Requires the same size of postive and negative')\n",
    "            scores_pos = tf.reshape(tf.tile(scores_pos, [self.eta]), [tf.shape(scores_pos)[0] * self.eta])\n",
    "\n",
    "        # look up embeddings from input training triples\n",
    "        negative_corruption_entities = self.embedding_model_params.get('negative_corruption_entities',\n",
    "                                                                       DEFAULT_CORRUPTION_ENTITIES)\n",
    "\n",
    "        if negative_corruption_entities == 'all':\n",
    "            logger.debug('Using all entities for generation of corruptions during training')\n",
    "            entities_size = tf.shape(self.ent_emb)[0]\n",
    "        elif negative_corruption_entities == 'batch':\n",
    "            # default is batch (entities_size=0 and entities_list=None)\n",
    "            logger.debug('Using batch entities for generation of corruptions during training')\n",
    "        elif isinstance(negative_corruption_entities, list):\n",
    "            logger.debug('Using the supplied entities for generation of corruptions during training')\n",
    "            entities_list = tf.squeeze(tf.constant(np.asarray([idx for uri, idx in self.ent_to_idx.items()\n",
    "                                                               if uri in negative_corruption_entities]),\n",
    "                                                   dtype=tf.int32))\n",
    "        elif isinstance(negative_corruption_entities, int):\n",
    "            logger.debug('Using first {} entities for generation of corruptions during \\\n",
    "                         training'.format(negative_corruption_entities))\n",
    "            entities_size = negative_corruption_entities\n",
    "\n",
    "        loss = 0\n",
    "        corruption_sides = self.embedding_model_params.get('corrupt_sides', DEFAULT_CORRUPT_SIDE_TRAIN)\n",
    "        if not isinstance(corruption_sides, list):\n",
    "            corruption_sides = [corruption_sides]\n",
    "\n",
    "        for side in corruption_sides:\n",
    "            # Generate the corruptions\n",
    "            x_neg_tf = generate_corruptions_for_fit(x_pos_tf, \n",
    "                                                    entities_list=entities_list, \n",
    "                                                    eta=self.eta, \n",
    "                                                    corrupt_side=side, \n",
    "                                                    entities_size=entities_size, \n",
    "                                                    rnd=self.seed)\n",
    "\n",
    "\n",
    "            scores_neg = []\n",
    "            for i, m in enumerate(self.models):\n",
    "                e_s, e_p, e_o = self._lookup_embeddings(i,x_neg_tf)\n",
    "                scores_neg.append(m._fn(e_s, e_p, e_o))\n",
    "            scores_neg = tf.squeeze(tf.matmul(tf.stop_gradient(tf.stack(scores_neg, axis=1)),\n",
    "                                              tf.reshape(tf.exp(self.ensemble), (-1, 1))))\n",
    "\n",
    "            # Apply the loss function\n",
    "            loss += self.loss.apply(scores_pos, scores_neg)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _training_data_generator(self):\n",
    "        batch_iterator = iter(self.train_dataset_handle.get_next_train_batch(self.batch_size, \"train\"))\n",
    "        for i in range(self.batches_count):\n",
    "            out = next(batch_iterator)\n",
    "            yield out\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.train_dataset_handle = None\n",
    "        # try-except block is mainly to handle clean up in case of exception or manual stop in jupyter notebook\n",
    "        try:\n",
    "            if isinstance(X, np.ndarray):\n",
    "                # Adapt the numpy data in the internal format - to generalize\n",
    "                self.train_dataset_handle = NumpyDatasetAdapter()\n",
    "                self.train_dataset_handle.set_data(X, \"train\")\n",
    "            elif isinstance(X, AmpligraphDatasetAdapter):\n",
    "                self.train_dataset_handle = X\n",
    "            else:\n",
    "                msg = 'Invalid type for input X. Expected ndarray/AmpligraphDataset object, got {}'.format(type(X))\n",
    "                logger.error(msg)\n",
    "                raise ValueError(msg)\n",
    "\n",
    "            self.train_dataset_handle.map_data()\n",
    "\n",
    "            tf.reset_default_graph()\n",
    "            self.rnd = check_random_state(self.seed)\n",
    "            tf.random.set_random_seed(self.seed)\n",
    "\n",
    "            self.ent_emb = [tf.Variable(m.trained_model_params[0], dtype=tf.float32) for m in self.models]\n",
    "            self.rel_emb = [tf.Variable(m.trained_model_params[1], dtype=tf.float32) for m in self.models]\n",
    "      \n",
    "            self.sess_train = tf.Session(config=self.tf_config)\n",
    "\n",
    "            batch_size = int(np.ceil(self.train_dataset_handle.get_size(\"train\") / self.batches_count))\n",
    "\n",
    "            self.batch_size = batch_size\n",
    "\n",
    "            dataset = tf.data.Dataset.from_generator(self._training_data_generator, \n",
    "                                                     output_types=tf.int32,\n",
    "                                                     output_shapes=(None, 3))\n",
    "\n",
    "            dataset = dataset.repeat().prefetch(1)\n",
    "\n",
    "            dataset_iterator = dataset.make_one_shot_iterator()\n",
    "            # init tf graph/dataflow for training\n",
    "            # init variables (model parameters to be learned - i.e. the embeddings)\n",
    "            self._initialize_parameters()\n",
    "\n",
    "            if self.loss.get_state('require_same_size_pos_neg'):\n",
    "                batch_size = batch_size * self.eta\n",
    "\n",
    "            loss = self._get_model_loss(dataset_iterator)\n",
    "\n",
    "            train = self.optimizer.minimize(loss)\n",
    "\n",
    "            self.sess_train.run(tf.tables_initializer())\n",
    "            self.sess_train.run(tf.global_variables_initializer())\n",
    "\n",
    "            epoch_iterator_with_progress = tqdm(range(1, self.epochs + 1), disable=(not self.verbose), unit='epoch')\n",
    "\n",
    "            for epoch in epoch_iterator_with_progress:\n",
    "                losses = []\n",
    "                for batch in range(1, self.batches_count + 1):\n",
    "                    feed_dict = {}\n",
    "                    self.optimizer.update_feed_dict(feed_dict, batch, epoch)\n",
    "                    loss_batch, _ = self.sess_train.run([loss, train], feed_dict=feed_dict)\n",
    "\n",
    "                    if np.isnan(loss_batch) or np.isinf(loss_batch):\n",
    "                        msg = 'Loss is {}. Please change the hyperparameters.'.format(loss_batch)\n",
    "                        logger.error(msg)\n",
    "                        raise ValueError(msg)\n",
    "\n",
    "                    losses.append(loss_batch)\n",
    "\n",
    "                if self.verbose:\n",
    "                    msg = 'Average Loss: {:10f}'.format(sum(losses) / (batch_size * self.batches_count))\n",
    "\n",
    "                    logger.debug(msg)\n",
    "                    epoch_iterator_with_progress.set_description(msg)\n",
    "            \n",
    "            self._save_trained_params()\n",
    "            self._end_training()\n",
    "        except BaseException as e:\n",
    "            self._end_training()\n",
    "            raise e\n",
    "        \n",
    "    def _end_training(self):\n",
    "        \"\"\"Performs clean up tasks after training.\n",
    "        \"\"\"\n",
    "        # Reset this variable as it is reused during evaluation phase\n",
    "        if self.is_filtered and self.eval_dataset_handle is not None:\n",
    "            # cleanup the evaluation data (deletion of tables\n",
    "            self.eval_dataset_handle.cleanup()\n",
    "            self.eval_dataset_handle = None\n",
    "            \n",
    "        if self.train_dataset_handle is not None:\n",
    "            self.train_dataset_handle.cleanup()\n",
    "            self.train_dataset_handle = None\n",
    "            \n",
    "        self.is_filtered = False\n",
    "        self.eval_config = {}\n",
    "\n",
    "        # close the tf session\n",
    "        if self.sess_train is not None:\n",
    "            self.sess_train.close()\n",
    "\n",
    "        # set is_fitted to true to indicate that the model fitting is completed\n",
    "        self.is_fitted = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_experiment(dataset):    \n",
    "    X = getattr(ampligraph.datasets, config['load_function_map'][dataset.upper()])()\n",
    "    \n",
    "    filter_triples = np.concatenate((X['train'], X['valid'], X['test']))\n",
    "    \n",
    "    model_loss_combs = list(product([ComplEx, DistMult, TransE, HolE], \n",
    "                                    [\"pairwise\", \"nll\", \"multiclass_nll\", \"self_adversarial\"]))\n",
    "    \n",
    "    results = {'model_metrics': []}\n",
    "    models = []\n",
    "    \n",
    "    for m, l in tqdm_notebook(model_loss_combs):\n",
    "        model_name = m.__name__\n",
    "        pickle_name = \"./calibration_ensemble/{}_{}_{}.pkl\".format(dataset, model_name.lower(), l)\n",
    "        c = config['hyperparams'][dataset.upper()][model_name.upper()]\n",
    "\n",
    "        try:\n",
    "            model = restore_model(pickle_name)\n",
    "            print(\"Restored model {}\".format(pickle_name))\n",
    "        except:\n",
    "            print(\"Training model {}\".format(pickle_name))\n",
    "            model = m(batches_count=c['batches_count'], seed=0, epochs=1000, \n",
    "                      k=300 if m in (DistMult, TransE) else 150, \n",
    "                      eta=c['eta'], optimizer=c['optimizer'], optimizer_params={'lr': c['optimizer_params']['lr']},\n",
    "                      regularizer=c.get('regularizer'), \n",
    "                      regularizer_params={'p':c['regularizer_params']['p'], 'lambda':c['regularizer_params']['lambda']} if 'regularizer' in c and 'regularizer_params' in c else {}, \n",
    "                      loss=l, verbose=False)\n",
    "            try:\n",
    "                print(\"Fitting\")\n",
    "                model.fit(X['train'])\n",
    "                print(\"Calibrating\")\n",
    "                model.calibrate(X['valid'], positive_base_rate=0.5)\n",
    "                save_model(model, pickle_name)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "#         ranks = evaluate_performance(X['test'], \n",
    "#                              model=model, \n",
    "#                              filter_triples=filter_triples,\n",
    "#                              use_default_protocol=True, \n",
    "#                              verbose=False)\n",
    "#         results['model_metrics'].append([model_name, l, mrr_score(ranks), hits_at_n_score(ranks, n=10), mr_score(ranks)])\n",
    "#         print(results['model_metrics'][-1])        \n",
    "        models.append(model)\n",
    "        \n",
    "#     with open('./calibration_ensemble/{}_model_metrics.json'.format(dataset), 'w') as f:\n",
    "#         json.dump(results['model_metrics'], f)\n",
    "        \n",
    "    results = {}\n",
    "    for mode in ['calibration', 'mean', 'expit']:\n",
    "        try:\n",
    "            ens = Ensemble(mode=mode, models=models,\n",
    "                           epochs=1, \n",
    "                           batches_count=1, eta=1,\n",
    "                           loss='pairwise', optimizer='adam')\n",
    "        \n",
    "            ens.fit(X['valid'])\n",
    "\n",
    "            ranks = evaluate_performance(X['test'], \n",
    "                                         model=ens, \n",
    "                                         filter_triples=filter_triples,\n",
    "                                         use_default_protocol=True, \n",
    "                                         verbose=False)\n",
    "        \n",
    "            results[mode] = [mrr_score(ranks), hits_at_n_score(ranks, n=10), mr_score(ranks)]\n",
    "            print(mode, results[mode])\n",
    "        except Exception as e:\n",
    "            results[mode] = [\"exception\", \"exception\"]\n",
    "            print(\"Exception: {}\".format(str(e)))\n",
    "            \n",
    "    with open('./calibration_ensemble/{}_results.json'.format(dataset), 'w') as f:\n",
    "        json.dump(results, f)\n",
    "\n",
    "    return models, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WN18', 'FB15K', 'FB15K-237', 'WN18RR', 'YAGO310']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = list(config['load_function_map'].keys())\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d0c88bc9a74739a66406e367909474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model ./calibration_ensemble/FB15K-237_complex_pairwise.pkl\n",
      "Restored model ./calibration_ensemble/FB15K-237_complex_nll.pkl\n",
      "Restored model ./calibration_ensemble/FB15K-237_complex_multiclass_nll.pkl\n",
      "Restored model ./calibration_ensemble/FB15K-237_complex_self_adversarial.pkl\n",
      "Restored model ./calibration_ensemble/FB15K-237_distmult_pairwise.pkl\n",
      "Restored model ./calibration_ensemble/FB15K-237_distmult_nll.pkl\n",
      "Restored model ./calibration_ensemble/FB15K-237_distmult_multiclass_nll.pkl\n",
      "Restored model ./calibration_ensemble/FB15K-237_distmult_self_adversarial.pkl\n",
      "Restored model ./calibration_ensemble/FB15K-237_transe_pairwise.pkl\n",
      "Restored model ./calibration_ensemble/FB15K-237_transe_nll.pkl\n",
      "Restored model ./calibration_ensemble/FB15K-237_transe_multiclass_nll.pkl\n",
      "Restored model ./calibration_ensemble/FB15K-237_transe_self_adversarial.pkl\n",
      "Restored model ./calibration_ensemble/FB15K-237_hole_pairwise.pkl\n",
      "Restored model ./calibration_ensemble/FB15K-237_hole_nll.pkl\n",
      "Restored model ./calibration_ensemble/FB15K-237_hole_multiclass_nll.pkl\n",
      "Restored model ./calibration_ensemble/FB15K-237_hole_self_adversarial.pkl\n",
      "\n",
      "WARNING:tensorflow:From /home/ptabacof/.conda/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING - From /home/ptabacof/.conda/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ptabacof/.conda/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "WARNING - From /home/ptabacof/.conda/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "WARNING:tensorflow:From /home/ptabacof/.conda/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING - From /home/ptabacof/.conda/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss:  16.148472: 100%|██████████| 1/1 [00:01<00:00,  1.27s/epoch]\n",
      "100%|██████████| 20438/20438 [09:40<00:00, 38.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calibration [0.30994084986300474, 0.49226930228006655, 173.28207260984442]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss:  16.148472: 100%|██████████| 1/1 [00:00<00:00,  1.76epoch/s]\n",
      "100%|██████████| 20438/20438 [08:47<00:00, 38.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean [0.3162208948932377, 0.49867893140228986, 172.99207358841375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss:  16.148472: 100%|██████████| 1/1 [00:01<00:00,  1.18s/epoch]\n",
      "100%|██████████| 20438/20438 [09:36<00:00, 35.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expit [0.2762770332507093, 0.4652118602602994, 196.76529014580683]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a166fdc15af24991bb5e75b5bcce9a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model ./calibration_ensemble/WN18RR_complex_pairwise.pkl\n",
      "Restored model ./calibration_ensemble/WN18RR_complex_nll.pkl\n",
      "Restored model ./calibration_ensemble/WN18RR_complex_multiclass_nll.pkl\n",
      "Restored model ./calibration_ensemble/WN18RR_complex_self_adversarial.pkl\n",
      "Restored model ./calibration_ensemble/WN18RR_distmult_pairwise.pkl\n",
      "Restored model ./calibration_ensemble/WN18RR_distmult_nll.pkl\n",
      "Restored model ./calibration_ensemble/WN18RR_distmult_multiclass_nll.pkl\n",
      "Restored model ./calibration_ensemble/WN18RR_distmult_self_adversarial.pkl\n",
      "Restored model ./calibration_ensemble/WN18RR_transe_pairwise.pkl\n",
      "Restored model ./calibration_ensemble/WN18RR_transe_nll.pkl\n",
      "Restored model ./calibration_ensemble/WN18RR_transe_multiclass_nll.pkl\n",
      "Restored model ./calibration_ensemble/WN18RR_transe_self_adversarial.pkl\n",
      "Restored model ./calibration_ensemble/WN18RR_hole_pairwise.pkl\n",
      "Restored model ./calibration_ensemble/WN18RR_hole_nll.pkl\n",
      "Restored model ./calibration_ensemble/WN18RR_hole_multiclass_nll.pkl\n",
      "Restored model ./calibration_ensemble/WN18RR_hole_self_adversarial.pkl\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss:   8.735569: 100%|██████████| 1/1 [00:03<00:00,  3.19s/epoch]\n",
      "100%|██████████| 2924/2924 [02:43<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calibration [0.4950741010374487, 0.5714774281805746, 2329.877222982216]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss:   8.735569: 100%|██████████| 1/1 [00:02<00:00,  2.10s/epoch]\n",
      "100%|██████████| 2924/2924 [03:03<00:00, 15.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean [0.4837868888733338, 0.5528385772913816, 4218.939466484268]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss:   8.735569: 100%|██████████| 1/1 [00:03<00:00,  3.82s/epoch]\n",
      "100%|██████████| 2924/2924 [03:18<00:00, 14.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expit [0.49104252907088924, 0.5745554035567716, 3427.872777017784]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for d in ['FB15K-237', 'WN18RR']:\n",
    "    _, r = ensemble_experiment(d)\n",
    "    results.append(r)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
