{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.calibration import calibration_curve, _SigmoidCalibration, _sigmoid_calibration\n",
    "from ampligraph.evaluation import evaluate_performance, mr_score, mrr_score, hits_at_n_score, generate_corruptions_for_eval\n",
    "from sklearn.metrics import brier_score_loss, log_loss, accuracy_score\n",
    "from scipy.special import expit\n",
    "\n",
    "from ampligraph.datasets import load_fb13\n",
    "from ampligraph.latent_features.models import TransE, ComplEx, DistMult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_corruptions import generate_corruptions, calibration_loss, pos_iso\n",
    "import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_fb13()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_pos = X['valid'][X['valid_labels']]\n",
    "X_valid_neg = X['valid'][~X['valid_labels']]\n",
    "\n",
    "X_test_pos = X['test'][X['test_labels']]\n",
    "X_test_neg = X['test'][~X['test_labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING - From /home/ptabacof/.conda/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING - From /home/ptabacof/.conda/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "WARNING - From /home/ptabacof/.conda/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING - From /home/ptabacof/.conda/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "pos [-1.0954863, -4.334414]\n",
      "pos neg [-1.6125523, -5.5522327]\n",
      "WARNING - From /home/ptabacof/AmpliGraph-Lab/ampligraph/evaluation/protocol.py:352: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.random.categorical instead.\n",
      "pos sc -1.0922488047710615 -4.463725882491225\n",
      "pos neg sc -1.6125365361080692 -5.55218235696441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_pred_true = y_true[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:202: RuntimeWarning: invalid value encountered in true_divide\n",
      "  bin_centroid = y_prob[i_start:i_end].sum() / delta_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"eta\": 1,\n",
      "  \"brier_score_scores\": 0.43010238901625863,\n",
      "  \"log_loss_scores\": 1.4585676094150124,\n",
      "  \"brier_score_probas_pos\": 0.18092034908458868,\n",
      "  \"log_loss_probas_pos\": 0.5370831285028451,\n",
      "  \"brier_score_probas_pos_neg\": 0.16231437634363932,\n",
      "  \"log_loss_probas_pos_neg\": 0.4898351556862251,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.16163469243894837,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.4870209616450951,\n",
      "  \"brier_score_probas_pos_iso\": 0.19254436721470428,\n",
      "  \"log_loss_probas_pos_iso\": 0.5615592260268177,\n",
      "  \"brier_score_probas_pos_sc\": 0.1888307926375534,\n",
      "  \"log_loss_probas_pos_sc\": 0.5547230007177081,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.16231436288453022,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.4898344686036387,\n",
      "  \"ece_scores\": 0.4505600300990328,\n",
      "  \"ece_probas_pos\": 0.11753036279451701,\n",
      "  \"ece_probas_pos_neg\": 0.022471213650185028,\n",
      "  \"ece_probas_pos_neg_iso\": 0.006846981749344497,\n",
      "  \"ece_probas_pos_iso\": 0.14747494657805427,\n",
      "  \"ece_probas_pos_sc\": 0.14281984797082461,\n",
      "  \"ece_probas_pos_neg_sc\": 0.022466555355778763,\n",
      "  \"metrics_mrr\": 0.24865094467268592,\n",
      "  \"metrics_hits@10\": 0.34079130324864115,\n",
      "  \"metrics_mr\": 3735.0251337799687,\n",
      "  \"accuracy_per_relation\": 0.7618826900387662,\n",
      "  \"accuracy_uncalib\": 0.4999789314006405,\n",
      "  \"accuracy_pos\": 0.7273091184898028,\n",
      "  \"accuracy_pos_neg\": 0.7517697623461992,\n",
      "  \"accuracy_pos_neg_iso\": 0.75217006573403,\n",
      "  \"accuracy_pos_iso\": 0.6988875779538176,\n",
      "  \"accuracy_pos_sc\": 0.7094218776335749,\n",
      "  \"accuracy_pos_neg_sc\": 0.7517697623461992\n",
      "}\n",
      "pos [-1.395171, -5.4161263]\n",
      "pos neg [-2.5620983, -9.133718]\n",
      "pos sc -1.4435048492380242 -5.727503384824264\n",
      "pos neg sc -2.561859670625622 -9.13299182796796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_pred_true = y_true[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:202: RuntimeWarning: invalid value encountered in true_divide\n",
      "  bin_centroid = y_prob[i_start:i_end].sum() / delta_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"eta\": 5,\n",
      "  \"brier_score_scores\": 0.443506634446674,\n",
      "  \"log_loss_scores\": 1.5242958195201615,\n",
      "  \"brier_score_probas_pos\": 0.15201329069370087,\n",
      "  \"log_loss_probas_pos\": 0.46958473983798893,\n",
      "  \"brier_score_probas_pos_neg\": 0.13323192493161676,\n",
      "  \"log_loss_probas_pos_neg\": 0.4147222181775302,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.13336567042720532,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.414814903200108,\n",
      "  \"brier_score_probas_pos_iso\": 0.15402736004113057,\n",
      "  \"log_loss_probas_pos_iso\": 0.47264937646660315,\n",
      "  \"brier_score_probas_pos_sc\": 0.15669793228792864,\n",
      "  \"log_loss_probas_pos_sc\": 0.4788816849985962,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.13323195928451906,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.4147226660593127,\n",
      "  \"ece_scores\": 0.4607009358054849,\n",
      "  \"ece_probas_pos\": 0.10586315002647154,\n",
      "  \"ece_probas_pos_neg\": 0.01521211576244792,\n",
      "  \"ece_probas_pos_neg_iso\": 0.009829387764596275,\n",
      "  \"ece_probas_pos_iso\": 0.1015516201573718,\n",
      "  \"ece_probas_pos_sc\": 0.12048983355090251,\n",
      "  \"ece_probas_pos_neg_sc\": 0.015258438332864261,\n",
      "  \"metrics_mrr\": 0.28441391683898115,\n",
      "  \"metrics_hits@10\": 0.3803986011039481,\n",
      "  \"metrics_mr\": 3464.913179960393,\n",
      "  \"accuracy_per_relation\": 0.8051575931232091,\n",
      "  \"accuracy_uncalib\": 0.4999789314006405,\n",
      "  \"accuracy_pos\": 0.7878602730490477,\n",
      "  \"accuracy_pos_neg\": 0.8065902578796562,\n",
      "  \"accuracy_pos_neg_iso\": 0.8077068936457105,\n",
      "  \"accuracy_pos_iso\": 0.7728594303050733,\n",
      "  \"accuracy_pos_sc\": 0.7748188100455081,\n",
      "  \"accuracy_pos_neg_sc\": 0.8065902578796562\n",
      "}\n",
      "pos [-1.426191, -5.516561]\n",
      "pos neg [-2.6914856, -9.618854]\n",
      "pos sc -1.491246857846647 -5.886320225849361\n",
      "pos neg sc -2.6910871435152 -9.617647282395174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_pred_true = y_true[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:202: RuntimeWarning: invalid value encountered in true_divide\n",
      "  bin_centroid = y_prob[i_start:i_end].sum() / delta_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"eta\": 10,\n",
      "  \"brier_score_scores\": 0.4449743486881438,\n",
      "  \"log_loss_scores\": 1.531114754635349,\n",
      "  \"brier_score_probas_pos\": 0.1475938140653438,\n",
      "  \"log_loss_probas_pos\": 0.45924728665003317,\n",
      "  \"brier_score_probas_pos_neg\": 0.12908166102148239,\n",
      "  \"log_loss_probas_pos_neg\": 0.4036669537004763,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.12916904811544647,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.4034930553150096,\n",
      "  \"brier_score_probas_pos_iso\": 0.1479903422470931,\n",
      "  \"log_loss_probas_pos_iso\": 0.4588063197774797,\n",
      "  \"brier_score_probas_pos_sc\": 0.15136495022635757,\n",
      "  \"log_loss_probas_pos_sc\": 0.4661357943041857,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.12908177443247576,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.4036677602275994,\n",
      "  \"ece_scores\": 0.46178920431159587,\n",
      "  \"ece_probas_pos\": 0.10781627132943644,\n",
      "  \"ece_probas_pos_neg\": 0.011184428768135447,\n",
      "  \"ece_probas_pos_neg_iso\": 0.007725199472405761,\n",
      "  \"ece_probas_pos_iso\": 0.09503221551516096,\n",
      "  \"ece_probas_pos_sc\": 0.11747048686754953,\n",
      "  \"ece_probas_pos_neg_sc\": 0.0111215735143774,\n",
      "  \"metrics_mrr\": 0.29085314507136517,\n",
      "  \"metrics_hits@10\": 0.38707706568912487,\n",
      "  \"metrics_mr\": 3458.398790713353,\n",
      "  \"accuracy_per_relation\": 0.8119206135176134,\n",
      "  \"accuracy_uncalib\": 0.4999789314006405,\n",
      "  \"accuracy_pos\": 0.7961613011966965,\n",
      "  \"accuracy_pos_neg\": 0.8144909826394742,\n",
      "  \"accuracy_pos_neg_iso\": 0.8146173942356312,\n",
      "  \"accuracy_pos_iso\": 0.7894193494016518,\n",
      "  \"accuracy_pos_sc\": 0.7847631889431991,\n",
      "  \"accuracy_pos_neg_sc\": 0.8144909826394742\n",
      "}\n",
      "pos [-1.4403313, -5.5580726]\n",
      "pos neg [-2.754491, -9.854868]\n",
      "pos sc -1.5130581178886044 -5.954451594028602\n",
      "pos neg sc -2.7543940439074124 -9.854533811695852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_pred_true = y_true[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:202: RuntimeWarning: invalid value encountered in true_divide\n",
      "  bin_centroid = y_prob[i_start:i_end].sum() / delta_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"eta\": 20,\n",
      "  \"brier_score_scores\": 0.44563209528380743,\n",
      "  \"log_loss_scores\": 1.5335787178428342,\n",
      "  \"brier_score_probas_pos\": 0.145080650046291,\n",
      "  \"log_loss_probas_pos\": 0.45329740366389204,\n",
      "  \"brier_score_probas_pos_neg\": 0.12679760281621352,\n",
      "  \"log_loss_probas_pos_neg\": 0.39731446391077135,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.1269213223747452,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.3974572730331737,\n",
      "  \"brier_score_probas_pos_iso\": 0.14499401537487708,\n",
      "  \"log_loss_probas_pos_iso\": 0.4516454916188764,\n",
      "  \"brier_score_probas_pos_sc\": 0.14838202571507067,\n",
      "  \"log_loss_probas_pos_sc\": 0.45892898971826107,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.1267976473010799,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.39731445180523806,\n",
      "  \"ece_scores\": 0.46229651736586247,\n",
      "  \"ece_probas_pos\": 0.10859998988799816,\n",
      "  \"ece_probas_pos_neg\": 0.01023814466416322,\n",
      "  \"ece_probas_pos_neg_iso\": 0.010035126857443198,\n",
      "  \"ece_probas_pos_iso\": 0.09186436106985635,\n",
      "  \"ece_probas_pos_sc\": 0.11575681281804782,\n",
      "  \"ece_probas_pos_neg_sc\": 0.01023889955172283,\n",
      "  \"metrics_mrr\": 0.2946411316998378,\n",
      "  \"metrics_hits@10\": 0.39234399359541566,\n",
      "  \"metrics_mr\": 3448.5908018371047,\n",
      "  \"accuracy_per_relation\": 0.8159868531939997,\n",
      "  \"accuracy_uncalib\": 0.4999789314006405,\n",
      "  \"accuracy_pos\": 0.8001643350750042,\n",
      "  \"accuracy_pos_neg\": 0.8184729479184224,\n",
      "  \"accuracy_pos_neg_iso\": 0.8192524860947245,\n",
      "  \"accuracy_pos_iso\": 0.795487106017192,\n",
      "  \"accuracy_pos_sc\": 0.7888926344176639,\n",
      "  \"accuracy_pos_neg_sc\": 0.8184729479184224\n",
      "}\n",
      "pos [-1.4541494, -5.601229]\n",
      "pos neg [-2.8150074, -10.087865]\n",
      "pos sc -1.5382287946007438 -6.03771168144908\n",
      "pos neg sc -2.814367355512736 -10.085924323039388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_pred_true = y_true[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:202: RuntimeWarning: invalid value encountered in true_divide\n",
      "  bin_centroid = y_prob[i_start:i_end].sum() / delta_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"eta\": 50,\n",
      "  \"brier_score_scores\": 0.4460858275793543,\n",
      "  \"log_loss_scores\": 1.5355540995823067,\n",
      "  \"brier_score_probas_pos\": 0.1423449120778154,\n",
      "  \"log_loss_probas_pos\": 0.4470435699097237,\n",
      "  \"brier_score_probas_pos_neg\": 0.12420871922158815,\n",
      "  \"log_loss_probas_pos_neg\": 0.3905511126419684,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.12449517218918156,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.3907800792653795,\n",
      "  \"brier_score_probas_pos_iso\": 0.14112705903950606,\n",
      "  \"log_loss_probas_pos_iso\": 0.44249453902423647,\n",
      "  \"brier_score_probas_pos_sc\": 0.14506060867547288,\n",
      "  \"log_loss_probas_pos_sc\": 0.4511349851482815,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.12420893648666705,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.3905526241946029,\n",
      "  \"ece_scores\": 0.462700612193795,\n",
      "  \"ece_probas_pos\": 0.10918192700312589,\n",
      "  \"ece_probas_pos_neg\": 0.010066107154073353,\n",
      "  \"ece_probas_pos_neg_iso\": 0.009674655720074725,\n",
      "  \"ece_probas_pos_iso\": 0.09115698174483002,\n",
      "  \"ece_probas_pos_sc\": 0.11234289175428418,\n",
      "  \"ece_probas_pos_neg_sc\": 0.010051002122480317,\n",
      "  \"metrics_mrr\": 0.29761047774963423,\n",
      "  \"metrics_hits@10\": 0.39459823873930816,\n",
      "  \"metrics_mr\": 3453.600492984452,\n",
      "  \"accuracy_per_relation\": 0.8207272880498905,\n",
      "  \"accuracy_uncalib\": 0.4999789314006405,\n",
      "  \"accuracy_pos\": 0.8065270520815776,\n",
      "  \"accuracy_pos_neg\": 0.8231501769762346,\n",
      "  \"accuracy_pos_neg_iso\": 0.8205376706556549,\n",
      "  \"accuracy_pos_iso\": 0.8061056800943873,\n",
      "  \"accuracy_pos_sc\": 0.7964773301870892,\n",
      "  \"accuracy_pos_neg_sc\": 0.8231923141749536\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for eta in [1, 5, 10, 20, 50, 100]:\n",
    "    model = TransE(batches_count=64, seed=0, epochs=500, k=100, eta=eta,\n",
    "                   optimizer='adam', optimizer_params={'lr':0.0001},\n",
    "                   loss='self_adversarial', verbose=False)\n",
    "\n",
    "    model.fit(X['train'])\n",
    "    \n",
    "    scores = model.predict(X['test'])\n",
    "\n",
    "    model.calibrate(X_valid_pos, batches_count=10, epochs=1000, positive_base_rate=0.5)\n",
    "    print(\"pos\", model.calibration_parameters)\n",
    "    probas1 = model.predict_proba(X['test'])\n",
    "\n",
    "    model.calibrate(X_valid_pos, X_valid_neg)\n",
    "    print(\"pos neg\", model.calibration_parameters)\n",
    "    probas2 = model.predict_proba(X['test'])\n",
    "    \n",
    "    val_scores = model.predict(X['valid'])\n",
    "    ir = IsotonicRegression(out_of_bounds='clip')\n",
    "    ir.fit(np.squeeze(val_scores).astype(float), (X['valid_labels']).astype(float))\n",
    "    probas3 = ir.predict(np.squeeze(scores).astype(float))\n",
    "    \n",
    "    model.generate_corruptions = types.MethodType(generate_corruptions, model)\n",
    "    corruptions = model.generate_corruptions(X_valid_pos, batches_count=10, epochs=1000)\n",
    "    val_pos_scores = np.squeeze(model.predict(X_valid_pos))\n",
    "    iso_pos = pos_iso(IsotonicRegression(out_of_bounds='clip'), val_pos_scores, corruptions, positive_base_rate=0.5)\n",
    "    probas4 = iso_pos.predict(np.squeeze(scores).astype(float))\n",
    "\n",
    "    sc_pos = pos_iso(_SigmoidCalibration(), val_pos_scores, corruptions, positive_base_rate=0.5)\n",
    "    print(\"pos sc\", sc_pos.a_, sc_pos.b_)\n",
    "    probas5 = sc_pos.predict(np.squeeze(scores).astype(float))\n",
    "    \n",
    "    val_neg_scores = np.squeeze(model.predict(X_valid_neg))\n",
    "    sc_pos_neg = pos_iso(_SigmoidCalibration(), val_pos_scores, val_neg_scores, positive_base_rate=0.5)\n",
    "    print(\"pos neg sc\", sc_pos_neg.a_, sc_pos_neg.b_)\n",
    "    probas6 = sc_pos_neg.predict(np.squeeze(scores).astype(float))\n",
    "    \n",
    "    thresholds = {r: np.median(np.sort(val_scores[X['valid'][:, 1] == r])) for r in np.unique(X['valid'][:, 1])}\n",
    "    thresholds_test = np.vectorize(thresholds.get)(X['test'][:, 1])\n",
    "    per_relation_acc = accuracy_score(X['test_labels'], scores > thresholds_test)\n",
    "\n",
    "    acc_uncalib = accuracy_score(X['test_labels'], expit(scores) > 0.5)\n",
    "    \n",
    "    acc1 = accuracy_score(X['test_labels'], probas1 > 0.5)\n",
    "    acc2 = accuracy_score(X['test_labels'], probas2 > 0.5)\n",
    "    acc3 = accuracy_score(X['test_labels'], probas3 > 0.5)\n",
    "    acc4 = accuracy_score(X['test_labels'], probas4 > 0.5)\n",
    "    acc5 = accuracy_score(X['test_labels'], probas5 > 0.5)\n",
    "    acc6 = accuracy_score(X['test_labels'], probas6 > 0.5)\n",
    "    \n",
    "    filter_triples = np.concatenate((X['train'], X_valid_pos, X_test_pos))\n",
    "    ranks = evaluate_performance(X_test_pos, \n",
    "                                 model=model, \n",
    "                                 filter_triples=filter_triples,\n",
    "                                 use_default_protocol=True, \n",
    "                                 verbose=False)\n",
    "\n",
    "    results.append({\n",
    "        'eta': eta,\n",
    "        'brier_score_scores': brier_score_loss(X['test_labels'], expit(scores)),\n",
    "        'log_loss_scores': log_loss(X['test_labels'], expit(scores), eps=1e-7),\n",
    "        'brier_score_probas_pos': brier_score_loss(X['test_labels'], probas1),\n",
    "        'log_loss_probas_pos': log_loss(X['test_labels'], probas1, eps=1e-7),\n",
    "        'brier_score_probas_pos_neg': brier_score_loss(X['test_labels'], probas2),\n",
    "        'log_loss_probas_pos_neg': log_loss(X['test_labels'], probas2, eps=1e-7),\n",
    "        'brier_score_probas_pos_neg_iso': brier_score_loss(X['test_labels'], probas3),\n",
    "        'log_loss_probas_pos_neg_iso': log_loss(X['test_labels'], probas3, eps=1e-7),\n",
    "        'brier_score_probas_pos_iso': brier_score_loss(X['test_labels'], probas4),\n",
    "        'log_loss_probas_pos_iso': log_loss(X['test_labels'], probas4, eps=1e-7),\n",
    "        'brier_score_probas_pos_sc': brier_score_loss(X['test_labels'], probas5),\n",
    "        'log_loss_probas_pos_sc': log_loss(X['test_labels'], probas5, eps=1e-7),\n",
    "        'brier_score_probas_pos_neg_sc': brier_score_loss(X['test_labels'], probas6),\n",
    "        'log_loss_probas_pos_neg_sc': log_loss(X['test_labels'], probas6, eps=1e-7),\n",
    "        'ece_scores': calibration_loss(X['test_labels'], expit(scores)),\n",
    "        'ece_probas_pos': calibration_loss(X['test_labels'], probas1),\n",
    "        'ece_probas_pos_neg': calibration_loss(X['test_labels'], probas2),\n",
    "        'ece_probas_pos_neg_iso': calibration_loss(X['test_labels'], probas3),\n",
    "        'ece_probas_pos_iso': calibration_loss(X['test_labels'], probas4),\n",
    "        'ece_probas_pos_sc': calibration_loss(X['test_labels'], probas5),\n",
    "        'ece_probas_pos_neg_sc': calibration_loss(X['test_labels'], probas6),\n",
    "        'metrics_mrr': mrr_score(ranks), \n",
    "        'metrics_hits@10': hits_at_n_score(ranks, n=10),\n",
    "        'metrics_mr': mr_score(ranks),\n",
    "        'accuracy_per_relation': per_relation_acc,\n",
    "        'accuracy_uncalib': acc_uncalib,\n",
    "        'accuracy_pos': acc1,\n",
    "        'accuracy_pos_neg': acc2,\n",
    "        'accuracy_pos_neg_iso': acc3,\n",
    "        'accuracy_pos_iso': acc4,\n",
    "        'accuracy_pos_sc': acc5,\n",
    "        'accuracy_pos_neg_sc': acc6\n",
    "    })\n",
    "        \n",
    "    print(json.dumps(results[-1], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_results = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(eta_results)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"fb13_eta.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.rcParams.update({'font.size': 20, 'axes.titlesize': 18})\n",
    "plt.plot(df.eta, df.brier_score_probas_pos_neg, lw=3, label=\"Platt scaling\")\n",
    "plt.plot(df.eta, df.brier_score_probas_pos_neg_iso, lw=3, label=\"Isotonic\")\n",
    "plt.plot(df.eta, df.brier_score_scores, lw=3, label=\"Uncalibrated scores\")\n",
    "plt.plot(df.eta, df.metrics_mrr, lw=3, label=\"MRR\")\n",
    "plt.xlabel(\"Eta\")\n",
    "plt.ylabel(\"Brier score\")\n",
    "plt.legend()\n",
    "plt.title(\"FB13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for k in [10, 25, 50, 100, 200, 500]:\n",
    "    model = TransE(batches_count=64, seed=0, epochs=500, k=k, eta=20,\n",
    "                   optimizer='adam', optimizer_params={'lr':0.0001},\n",
    "                   loss='self_adversarial', verbose=False)\n",
    "\n",
    "    model.fit(X['train'])\n",
    "    \n",
    "    scores = model.predict(X['test'])\n",
    "\n",
    "    model.calibrate(X_valid_pos, batches_count=10, epochs=1000, positive_base_rate=0.5)\n",
    "    print(\"pos\", model.calibration_parameters)\n",
    "    probas1 = model.predict_proba(X['test'])\n",
    "\n",
    "    model.calibrate(X_valid_pos, X_valid_neg)\n",
    "    print(\"pos neg\", model.calibration_parameters)\n",
    "    probas2 = model.predict_proba(X['test'])\n",
    "    \n",
    "    val_scores = model.predict(X['valid'])\n",
    "    ir = IsotonicRegression(out_of_bounds='clip')\n",
    "    ir.fit(np.squeeze(val_scores).astype(float), (X['valid_labels']).astype(float))\n",
    "    probas3 = ir.predict(np.squeeze(scores).astype(float))\n",
    "    \n",
    "    model.generate_corruptions = types.MethodType(generate_corruptions, model)\n",
    "    corruptions = model.generate_corruptions(X_valid_pos, batches_count=10, epochs=1000)\n",
    "    val_pos_scores = np.squeeze(model.predict(X_valid_pos))\n",
    "    iso_pos = pos_iso(IsotonicRegression(out_of_bounds='clip'), val_pos_scores, corruptions, positive_base_rate=0.5)\n",
    "    probas4 = iso_pos.predict(np.squeeze(scores).astype(float))\n",
    "\n",
    "    sc_pos = pos_iso(_SigmoidCalibration(), val_pos_scores, corruptions, positive_base_rate=0.5)\n",
    "    print(\"pos sc\", sc_pos.a_, sc_pos.b_)\n",
    "    probas5 = sc_pos.predict(np.squeeze(scores).astype(float))\n",
    "    \n",
    "    val_neg_scores = np.squeeze(model.predict(X_valid_neg))\n",
    "    sc_pos_neg = pos_iso(_SigmoidCalibration(), val_pos_scores, val_neg_scores, positive_base_rate=0.5)\n",
    "    print(\"pos neg sc\", sc_pos_neg.a_, sc_pos_neg.b_)\n",
    "    probas6 = sc_pos_neg.predict(np.squeeze(scores).astype(float))\n",
    "    \n",
    "    thresholds = {r: np.median(np.sort(val_scores[X['valid'][:, 1] == r])) for r in np.unique(X['valid'][:, 1])}\n",
    "    thresholds_test = np.vectorize(thresholds.get)(X['test'][:, 1])\n",
    "    per_relation_acc = accuracy_score(X['test_labels'], scores > thresholds_test)\n",
    "\n",
    "    acc_uncalib = accuracy_score(X['test_labels'], expit(scores) > 0.5)\n",
    "    \n",
    "    acc1 = accuracy_score(X['test_labels'], probas1 > 0.5)\n",
    "    acc2 = accuracy_score(X['test_labels'], probas2 > 0.5)\n",
    "    acc3 = accuracy_score(X['test_labels'], probas3 > 0.5)\n",
    "    acc4 = accuracy_score(X['test_labels'], probas4 > 0.5)\n",
    "    acc5 = accuracy_score(X['test_labels'], probas5 > 0.5)\n",
    "    acc6 = accuracy_score(X['test_labels'], probas6 > 0.5)\n",
    "    \n",
    "    filter_triples = np.concatenate((X['train'], X_valid_pos, X_test_pos))\n",
    "    ranks = evaluate_performance(X_test_pos, \n",
    "                                 model=model, \n",
    "                                 filter_triples=filter_triples,\n",
    "                                 use_default_protocol=True, \n",
    "                                 verbose=False)\n",
    "\n",
    "    results.append({\n",
    "        'k': k,\n",
    "        'brier_score_scores': brier_score_loss(X['test_labels'], expit(scores)),\n",
    "        'log_loss_scores': log_loss(X['test_labels'], expit(scores), eps=1e-7),\n",
    "        'brier_score_probas_pos': brier_score_loss(X['test_labels'], probas1),\n",
    "        'log_loss_probas_pos': log_loss(X['test_labels'], probas1, eps=1e-7),\n",
    "        'brier_score_probas_pos_neg': brier_score_loss(X['test_labels'], probas2),\n",
    "        'log_loss_probas_pos_neg': log_loss(X['test_labels'], probas2, eps=1e-7),\n",
    "        'brier_score_probas_pos_neg_iso': brier_score_loss(X['test_labels'], probas3),\n",
    "        'log_loss_probas_pos_neg_iso': log_loss(X['test_labels'], probas3, eps=1e-7),\n",
    "        'brier_score_probas_pos_iso': brier_score_loss(X['test_labels'], probas4),\n",
    "        'log_loss_probas_pos_iso': log_loss(X['test_labels'], probas4, eps=1e-7),\n",
    "        'brier_score_probas_pos_sc': brier_score_loss(X['test_labels'], probas5),\n",
    "        'log_loss_probas_pos_sc': log_loss(X['test_labels'], probas5, eps=1e-7),\n",
    "        'brier_score_probas_pos_neg_sc': brier_score_loss(X['test_labels'], probas6),\n",
    "        'log_loss_probas_pos_neg_sc': log_loss(X['test_labels'], probas6, eps=1e-7),\n",
    "        'ece_scores': calibration_loss(X['test_labels'], expit(scores)),\n",
    "        'ece_probas_pos': calibration_loss(X['test_labels'], probas1),\n",
    "        'ece_probas_pos_neg': calibration_loss(X['test_labels'], probas2),\n",
    "        'ece_probas_pos_neg_iso': calibration_loss(X['test_labels'], probas3),\n",
    "        'ece_probas_pos_iso': calibration_loss(X['test_labels'], probas4),\n",
    "        'ece_probas_pos_sc': calibration_loss(X['test_labels'], probas5),\n",
    "        'ece_probas_pos_neg_sc': calibration_loss(X['test_labels'], probas6),\n",
    "        'metrics_mrr': mrr_score(ranks), \n",
    "        'metrics_hits@10': hits_at_n_score(ranks, n=10),\n",
    "        'metrics_mr': mr_score(ranks),\n",
    "        'accuracy_per_relation': per_relation_acc,\n",
    "        'accuracy_uncalib': acc_uncalib,\n",
    "        'accuracy_pos': acc1,\n",
    "        'accuracy_pos_neg': acc2,\n",
    "        'accuracy_pos_neg_iso': acc3,\n",
    "        'accuracy_pos_iso': acc4,\n",
    "        'accuracy_pos_sc': acc5,\n",
    "        'accuracy_pos_neg_sc': acc6\n",
    "    })\n",
    "        \n",
    "    print(json.dumps(results[-1], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_results = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(k_results)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"fb13_k.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.rcParams.update({'font.size': 20, 'axes.titlesize': 18})\n",
    "plt.plot(df.k, df.brier_score_probas_pos_neg, lw=3, label=\"Platt scaling\")\n",
    "plt.plot(df.k, df.brier_score_probas_pos_neg_iso, lw=3, label=\"Isotonic\")\n",
    "plt.plot(df.k, df.brier_score_scores, lw=3, label=\"Uncalibrated scores\")\n",
    "plt.plot(df.k, df.metrics_mrr, lw=3, label=\"MRR\")\n",
    "plt.xlabel(\"Embedding size\")\n",
    "plt.ylabel(\"Brier score\")\n",
    "plt.legend()\n",
    "plt.title(\"FB13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
