{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.calibration import calibration_curve, _SigmoidCalibration\n",
    "from ampligraph.evaluation import evaluate_performance, mr_score, mrr_score, hits_at_n_score, generate_corruptions_for_eval\n",
    "from sklearn.metrics import brier_score_loss, log_loss, accuracy_score\n",
    "from scipy.special import expit\n",
    "\n",
    "from ampligraph.datasets import load_fb13\n",
    "from ampligraph.latent_features.models import TransE, ComplEx, DistMult\n",
    "import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_corruptions import generate_corruptions, calibration_loss, pos_iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_fb13()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_pos = X['valid'][X['valid_labels']]\n",
    "X_valid_neg = X['valid'][~X['valid_labels']]\n",
    "\n",
    "X_test_pos = X['test'][X['test_labels']]\n",
    "X_test_neg = X['test'][~X['test_labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING - From /home/ptabacof/.conda/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING - From /home/ptabacof/.conda/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "WARNING - From /home/ptabacof/.conda/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING - From /home/ptabacof/.conda/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "pos [-1.4296955, -5.5330477]\n",
      "pos neg [-2.745783, -9.865425]\n",
      "WARNING - From /home/ptabacof/AmpliGraph-Lab/ampligraph/evaluation/protocol.py:352: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.random.categorical instead.\n",
      "pos sc -1.5014799113967103 -5.925346708263222\n",
      "pos neg sc -2.745765486884588 -9.86536315025429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_pred_true = y_true[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:202: RuntimeWarning: invalid value encountered in true_divide\n",
      "  bin_centroid = y_prob[i_start:i_end].sum() / delta_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model\": \"TransE\",\n",
      "  \"loss\": \"self_adversarial\",\n",
      "  \"brier_score_scores\": 0.44554974123999214,\n",
      "  \"log_loss_scores\": 1.533803733208319,\n",
      "  \"brier_score_probas_pos\": 0.1423859988388692,\n",
      "  \"log_loss_probas_pos\": 0.4469818503702879,\n",
      "  \"brier_score_probas_pos_neg\": 0.12434945745450178,\n",
      "  \"log_loss_probas_pos_neg\": 0.3907171836879325,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.124352102967138,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.3907786528156528,\n",
      "  \"brier_score_probas_pos_iso\": 0.14135220360648737,\n",
      "  \"log_loss_probas_pos_iso\": 0.44296393211287666,\n",
      "  \"brier_score_probas_pos_sc\": 0.1454120464243028,\n",
      "  \"log_loss_probas_pos_sc\": 0.4519962641419201,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.12434946643338107,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.39071610098006654,\n",
      "  \"ece_scores\": 0.4624879393653124,\n",
      "  \"ece_probas_pos\": 0.10791181316468958,\n",
      "  \"ece_probas_pos_neg\": 0.010122691080057063,\n",
      "  \"ece_probas_pos_neg_iso\": 0.007116593848850285,\n",
      "  \"ece_probas_pos_iso\": 0.08716301897226798,\n",
      "  \"ece_probas_pos_sc\": 0.11343212230529601,\n",
      "  \"ece_probas_pos_neg_sc\": 0.010122785882700708,\n",
      "  \"metrics_mrr\": 0.2968011787339366,\n",
      "  \"metrics_hits@10\": 0.39411368137192937,\n",
      "  \"metrics_mr\": 3429.35014536721,\n",
      "  \"accuracy_per_relation\": 0.8207694252486095,\n",
      "  \"accuracy_uncalib\": 0.4999789314006405,\n",
      "  \"accuracy_pos\": 0.8065691892802966,\n",
      "  \"accuracy_pos_neg\": 0.82291842238328,\n",
      "  \"accuracy_pos_neg_iso\": 0.8236136861621439,\n",
      "  \"accuracy_pos_iso\": 0.8073065902578797,\n",
      "  \"accuracy_pos_sc\": 0.7944126074498568,\n",
      "  \"accuracy_pos_neg_sc\": 0.82291842238328\n",
      "}\n",
      "pos [-0.4988469, -5.555953]\n",
      "pos neg [-0.5039308, -5.5194077]\n",
      "pos sc -0.6216321714797556 -7.006033193216443\n",
      "pos neg sc -0.5038928668802306 -5.51909871679269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_pred_true = y_true[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:202: RuntimeWarning: invalid value encountered in true_divide\n",
      "  bin_centroid = y_prob[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_pred_true = y_true[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:202: RuntimeWarning: invalid value encountered in true_divide\n",
      "  bin_centroid = y_prob[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_pred_true = y_true[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:202: RuntimeWarning: invalid value encountered in true_divide\n",
      "  bin_centroid = y_prob[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_pred_true = y_true[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:202: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  bin_centroid = y_prob[i_start:i_end].sum() / delta_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model\": \"TransE\",\n",
      "  \"loss\": \"pairwise\",\n",
      "  \"brier_score_scores\": 0.4999600556860562,\n",
      "  \"log_loss_scores\": 5.233593539454379,\n",
      "  \"brier_score_probas_pos\": 0.22494239533363558,\n",
      "  \"log_loss_probas_pos\": 0.6373193005651496,\n",
      "  \"brier_score_probas_pos_neg\": 0.22469787795731397,\n",
      "  \"log_loss_probas_pos_neg\": 0.6362553057238051,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.20299433345446838,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.5820868916678338,\n",
      "  \"brier_score_probas_pos_iso\": 0.20803145528953107,\n",
      "  \"log_loss_probas_pos_iso\": 0.5936251368204077,\n",
      "  \"brier_score_probas_pos_sc\": 0.2284992373799987,\n",
      "  \"log_loss_probas_pos_sc\": 0.6437693785737651,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.22469730589396622,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.6362553495353314,\n",
      "  \"ece_scores\": 0.4999776426222399,\n",
      "  \"ece_probas_pos\": 0.10634056276933913,\n",
      "  \"ece_probas_pos_neg\": 0.156289998909715,\n",
      "  \"ece_probas_pos_neg_iso\": 0.006800646281727416,\n",
      "  \"ece_probas_pos_iso\": 0.06314431733619326,\n",
      "  \"ece_probas_pos_sc\": 0.15140079312673113,\n",
      "  \"ece_probas_pos_neg_sc\": 0.15616548681659517,\n",
      "  \"metrics_mrr\": 0.2824132607477101,\n",
      "  \"metrics_hits@10\": 0.3740993553280243,\n",
      "  \"metrics_mr\": 7631.636560906754,\n",
      "  \"accuracy_per_relation\": 0.8045255351424238,\n",
      "  \"accuracy_uncalib\": 0.4999789314006405,\n",
      "  \"accuracy_pos\": 0.6002865329512894,\n",
      "  \"accuracy_pos_neg\": 0.5544623293443451,\n",
      "  \"accuracy_pos_neg_iso\": 0.6422341142760829,\n",
      "  \"accuracy_pos_iso\": 0.6400219113433339,\n",
      "  \"accuracy_pos_sc\": 0.6101887746502612,\n",
      "  \"accuracy_pos_neg_sc\": 0.5545466037417832\n",
      "}\n",
      "pos [-2.6439717, -1.5976642]\n",
      "pos neg [-3.2466576, -1.0627198]\n",
      "pos sc -2.178800331525417 -1.5689309819426753\n",
      "pos neg sc -3.245747818348099 -1.0623698035715803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_pred_true = y_true[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:202: RuntimeWarning: invalid value encountered in true_divide\n",
      "  bin_centroid = y_prob[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_pred_true = y_true[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:202: RuntimeWarning: invalid value encountered in true_divide\n",
      "  bin_centroid = y_prob[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_pred_true = y_true[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:202: RuntimeWarning: invalid value encountered in true_divide\n",
      "  bin_centroid = y_prob[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_pred_true = y_true[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:202: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  bin_centroid = y_prob[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_pred_true = y_true[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:202: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  bin_centroid = y_prob[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg_pred_true = y_true[i_start:i_end].sum() / delta_count\n",
      "/home/ptabacof/AmpliGraph-Lab/iclr_paper_notebooks/generate_corruptions.py:202: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  bin_centroid = y_prob[i_start:i_end].sum() / delta_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model\": \"TransE\",\n",
      "  \"loss\": \"nll\",\n",
      "  \"brier_score_scores\": 0.2356852277835587,\n",
      "  \"log_loss_scores\": 0.6634528751939001,\n",
      "  \"brier_score_probas_pos\": 0.23940801192799221,\n",
      "  \"log_loss_probas_pos\": 0.6758681786576761,\n",
      "  \"brier_score_probas_pos_neg\": 0.2092276480664465,\n",
      "  \"log_loss_probas_pos_neg\": 0.6140861720148587,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.20295373284390997,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.5926602140869712,\n",
      "  \"brier_score_probas_pos_iso\": 0.24326005536628312,\n",
      "  \"log_loss_probas_pos_iso\": 0.6837006758597755,\n",
      "  \"brier_score_probas_pos_sc\": 0.25280592963927584,\n",
      "  \"log_loss_probas_pos_sc\": 0.703133247862919,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.2092300032913679,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.6140878475953448,\n",
      "  \"ece_scores\": 0.14380922404706692,\n",
      "  \"ece_probas_pos\": 0.15978150862617116,\n",
      "  \"ece_probas_pos_neg\": 0.04320384164935883,\n",
      "  \"ece_probas_pos_neg_iso\": 0.009459265670122305,\n",
      "  \"ece_probas_pos_iso\": 0.17844937728238,\n",
      "  \"ece_probas_pos_sc\": 0.18691165281188388,\n",
      "  \"ece_probas_pos_neg_sc\": 0.043234981535856594,\n",
      "  \"metrics_mrr\": 0.20026026055771154,\n",
      "  \"metrics_hits@10\": 0.27164707369485525,\n",
      "  \"metrics_mr\": 6794.890174019298,\n",
      "  \"accuracy_per_relation\": 0.6612801280970841,\n",
      "  \"accuracy_uncalib\": 0.4999789314006405,\n",
      "  \"accuracy_pos\": 0.5907213888420698,\n",
      "  \"accuracy_pos_neg\": 0.6775872240013484,\n",
      "  \"accuracy_pos_neg_iso\": 0.6779032529917411,\n",
      "  \"accuracy_pos_iso\": 0.6264958705545255,\n",
      "  \"accuracy_pos_sc\": 0.55208157761672,\n",
      "  \"accuracy_pos_neg_sc\": 0.6776082926007079\n",
      "}\n",
      "pos [-0.35568318, -7.0330143]\n"
     ]
    }
   ],
   "source": [
    "losses =  ['self_adversarial', 'pairwise', 'nll', 'multiclass_nll']\n",
    "models = [TransE, DistMult, ComplEx]\n",
    "\n",
    "results = []\n",
    "\n",
    "for m, l in itertools.product(models, losses):\n",
    "    model = m(batches_count=32, seed=0, epochs=1000, k=100, eta=20,\n",
    "               optimizer='adam', optimizer_params={'lr':0.0001},\n",
    "               loss=l, verbose=False)\n",
    "    \n",
    "    try:\n",
    "        model.fit(X['train'])\n",
    "\n",
    "        scores = model.predict(X['test'])\n",
    "\n",
    "        model.calibrate(X_valid_pos, batches_count=10, epochs=1000, positive_base_rate=0.5)\n",
    "        print(\"pos\", model.calibration_parameters)\n",
    "        probas1 = model.predict_proba(X['test'])\n",
    "\n",
    "        model.calibrate(X_valid_pos, X_valid_neg)\n",
    "        print(\"pos neg\", model.calibration_parameters)\n",
    "        probas2 = model.predict_proba(X['test'])\n",
    "\n",
    "        val_scores = model.predict(X['valid'])\n",
    "        ir = IsotonicRegression(out_of_bounds='clip')\n",
    "        ir.fit(np.squeeze(val_scores).astype(float), (X['valid_labels']).astype(float))\n",
    "        probas3 = ir.predict(np.squeeze(scores).astype(float))\n",
    "\n",
    "        model.generate_corruptions = types.MethodType(generate_corruptions, model)\n",
    "        corruptions = model.generate_corruptions(X_valid_pos, batches_count=10, epochs=1000)\n",
    "        val_pos_scores = np.squeeze(model.predict(X_valid_pos))\n",
    "        iso_pos = pos_iso(IsotonicRegression(out_of_bounds='clip'), val_pos_scores, corruptions, positive_base_rate=0.5)\n",
    "        probas4 = iso_pos.predict(np.squeeze(scores).astype(float))\n",
    "\n",
    "        sc_pos = pos_iso(_SigmoidCalibration(), val_pos_scores, corruptions, positive_base_rate=0.5)\n",
    "        print(\"pos sc\", sc_pos.a_, sc_pos.b_)\n",
    "        probas5 = sc_pos.predict(np.squeeze(scores).astype(float))\n",
    "\n",
    "        val_neg_scores = np.squeeze(model.predict(X_valid_neg))\n",
    "        sc_pos_neg = pos_iso(_SigmoidCalibration(), val_pos_scores, val_neg_scores, positive_base_rate=0.5)\n",
    "        print(\"pos neg sc\", sc_pos_neg.a_, sc_pos_neg.b_)\n",
    "        probas6 = sc_pos_neg.predict(np.squeeze(scores).astype(float))\n",
    "\n",
    "        thresholds = {r: np.median(np.sort(val_scores[X['valid'][:, 1] == r])) for r in np.unique(X['valid'][:, 1])}\n",
    "        thresholds_test = np.vectorize(thresholds.get)(X['test'][:, 1])\n",
    "        per_relation_acc = accuracy_score(X['test_labels'], scores > thresholds_test)\n",
    "        \n",
    "        acc_uncalib = accuracy_score(X['test_labels'], expit(scores) > 0.5)\n",
    "\n",
    "        acc1 = accuracy_score(X['test_labels'], probas1 > 0.5)\n",
    "        acc2 = accuracy_score(X['test_labels'], probas2 > 0.5)\n",
    "        acc3 = accuracy_score(X['test_labels'], probas3 > 0.5)\n",
    "        acc4 = accuracy_score(X['test_labels'], probas4 > 0.5)\n",
    "        acc5 = accuracy_score(X['test_labels'], probas5 > 0.5)\n",
    "        acc6 = accuracy_score(X['test_labels'], probas6 > 0.5)\n",
    "        \n",
    "        filter_triples = np.concatenate((X['train'], X_valid_pos, X_test_pos))\n",
    "        ranks = evaluate_performance(X_test_pos, \n",
    "                                     model=model, \n",
    "                                     filter_triples=filter_triples,\n",
    "                                     use_default_protocol=True, \n",
    "                                     verbose=False)\n",
    "    except Exception as e:\n",
    "        print(\"Exception: {}\".format(e))\n",
    "        continue\n",
    "        \n",
    "    results.append({\n",
    "        'model': m.__name__,\n",
    "        'loss': l,\n",
    "        'brier_score_scores': brier_score_loss(X['test_labels'], expit(scores)),\n",
    "        'log_loss_scores': log_loss(X['test_labels'], expit(scores), eps=1e-7),\n",
    "        'brier_score_probas_pos': brier_score_loss(X['test_labels'], probas1),\n",
    "        'log_loss_probas_pos': log_loss(X['test_labels'], probas1, eps=1e-7),\n",
    "        'brier_score_probas_pos_neg': brier_score_loss(X['test_labels'], probas2),\n",
    "        'log_loss_probas_pos_neg': log_loss(X['test_labels'], probas2, eps=1e-7),\n",
    "        'brier_score_probas_pos_neg_iso': brier_score_loss(X['test_labels'], probas3),\n",
    "        'log_loss_probas_pos_neg_iso': log_loss(X['test_labels'], probas3, eps=1e-7),\n",
    "        'brier_score_probas_pos_iso': brier_score_loss(X['test_labels'], probas4),\n",
    "        'log_loss_probas_pos_iso': log_loss(X['test_labels'], probas4, eps=1e-7),\n",
    "        'brier_score_probas_pos_sc': brier_score_loss(X['test_labels'], probas5),\n",
    "        'log_loss_probas_pos_sc': log_loss(X['test_labels'], probas5, eps=1e-7),\n",
    "        'brier_score_probas_pos_neg_sc': brier_score_loss(X['test_labels'], probas6),\n",
    "        'log_loss_probas_pos_neg_sc': log_loss(X['test_labels'], probas6, eps=1e-7),\n",
    "        'ece_scores': calibration_loss(X['test_labels'], expit(scores)),\n",
    "        'ece_probas_pos': calibration_loss(X['test_labels'], probas1),\n",
    "        'ece_probas_pos_neg': calibration_loss(X['test_labels'], probas2),\n",
    "        'ece_probas_pos_neg_iso': calibration_loss(X['test_labels'], probas3),\n",
    "        'ece_probas_pos_iso': calibration_loss(X['test_labels'], probas4),\n",
    "        'ece_probas_pos_sc': calibration_loss(X['test_labels'], probas5),\n",
    "        'ece_probas_pos_neg_sc': calibration_loss(X['test_labels'], probas6),\n",
    "        'metrics_mrr': mrr_score(ranks), \n",
    "        'metrics_hits@10': hits_at_n_score(ranks, n=10),\n",
    "        'metrics_mr': mr_score(ranks),\n",
    "        'accuracy_per_relation': per_relation_acc,\n",
    "        'accuracy_uncalib': acc_uncalib,\n",
    "        'accuracy_pos': acc1,\n",
    "        'accuracy_pos_neg': acc2,\n",
    "        'accuracy_pos_neg_iso': acc3,\n",
    "        'accuracy_pos_iso': acc4,\n",
    "        'accuracy_pos_sc': acc5,\n",
    "        'accuracy_pos_neg_sc': acc6\n",
    "    })\n",
    "        \n",
    "    print(json.dumps(results[-1], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_min(s):\n",
    "    is_min = s == s.min()\n",
    "    return ['font-weight: bold' if v else '' for v in is_min]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results).set_index(['model', 'loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = df[(c for c in df.columns if c.startswith('brier'))]\n",
    "bs.columns = [c[len(\"brier_score_\"):] for c in bs.columns]\n",
    "bs.style.apply(highlight_min, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = df[(c for c in df.columns if c.startswith('log_loss'))]\n",
    "ll.columns = [c[len(\"log_loss_\"):] for c in ll.columns]\n",
    "ll.style.apply(highlight_min, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((bs.reset_index()\n",
    " .query(\"loss == 'self_adversarial' \")\n",
    " [['model', 'scores', 'probas_pos_neg', 'probas_pos_neg_iso', 'probas_pos', 'probas_pos_iso']]\n",
    " .reset_index(drop=True)\n",
    " .round(3)\n",
    " .to_latex()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ll.reset_index()\n",
    " .query(\"loss == 'self_adversarial' \")\n",
    " [['model', 'scores', 'probas_pos_neg', 'probas_pos_neg_iso', 'probas_pos', 'probas_pos_iso']]\n",
    " .reset_index(drop=True)\n",
    "  .round(3)\n",
    " .to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((acc*100).reset_index()\n",
    " .query(\"loss == 'self_adversarial' \")\n",
    " [['model', 'pos_neg', 'pos_neg_iso', 'pos', 'pos_iso',  'uncalib', 'per_relation']]\n",
    " .reset_index(drop=True)\n",
    "  .round(1)\n",
    " .to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = df[(c for c in df.columns if c.startswith('metrics'))]\n",
    "metrics.columns = [c[len(\"metrics_\"):] for c in metrics.columns]\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s):\n",
    "    is_min = s == s.max()\n",
    "    return ['font-weight: bold' if v else '' for v in is_min]\n",
    "\n",
    "acc = df[(c for c in df.columns if c.startswith('accuracy'))]\n",
    "acc.columns = [c[len(\"accuracy_\"):] for c in acc.columns]\n",
    "acc.style.apply(highlight_max, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(method='spearman').reset_index().query(\"index.str.startswith('accuracy')\")[['index', 'log_loss_probas_pos_neg', 'log_loss_probas_pos_neg_iso', 'log_loss_probas_pos', 'log_loss_probas_pos_iso']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(method='spearman').reset_index().query(\"index.str.startswith('accuracy')\")[['index', 'brier_score_probas_pos_neg', 'brier_score_probas_pos_neg_iso', 'brier_score_probas_pos', 'brier_score_probas_pos_iso']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(X['valid'][:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
