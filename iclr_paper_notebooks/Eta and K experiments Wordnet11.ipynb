{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.calibration import calibration_curve, _SigmoidCalibration, _sigmoid_calibration\n",
    "from ampligraph.evaluation import evaluate_performance, mr_score, mrr_score, hits_at_n_score, generate_corruptions_for_eval\n",
    "from sklearn.metrics import brier_score_loss, log_loss, accuracy_score\n",
    "from scipy.special import expit\n",
    "\n",
    "from ampligraph.datasets import load_wn11\n",
    "from ampligraph.latent_features.models import TransE, ComplEx, DistMult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_wn11()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_pos = X['valid'][X['valid_labels']]\n",
    "X_valid_neg = X['valid'][X['valid_labels']]\n",
    "\n",
    "X_test_pos = X['test'][X['test_labels']]\n",
    "X_test_neg = X['test'][X['test_labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "from functools import partial\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import check_random_state\n",
    "from tqdm import tqdm\n",
    "from ampligraph.datasets import AmpligraphDatasetAdapter, NumpyDatasetAdapter\n",
    "from ampligraph.evaluation import generate_corruptions_for_fit, to_idx, generate_corruptions_for_eval, \\\n",
    "    hits_at_n_score, mrr_score\n",
    "\n",
    "\n",
    "def generate_corruptions(self, X_pos, batches_count, epochs):\n",
    "    try:\n",
    "        tf.reset_default_graph()\n",
    "        self.rnd = check_random_state(self.seed)\n",
    "        tf.random.set_random_seed(self.seed)\n",
    "\n",
    "        self._load_model_from_trained_params()\n",
    "\n",
    "        dataset_handle = NumpyDatasetAdapter()\n",
    "        dataset_handle.use_mappings(self.rel_to_idx, self.ent_to_idx)\n",
    "\n",
    "        dataset_handle.set_data(X_pos, \"pos\")\n",
    "\n",
    "        gen_fn = partial(dataset_handle.get_next_batch, batches_count=batches_count, dataset_type=\"pos\")\n",
    "        dataset = tf.data.Dataset.from_generator(gen_fn,\n",
    "                                                 output_types=tf.int32,\n",
    "                                                 output_shapes=(None, 3))\n",
    "        dataset = dataset.repeat().prefetch(1)\n",
    "        dataset_iter = tf.data.make_one_shot_iterator(dataset)\n",
    "\n",
    "        x_pos_tf = dataset_iter.get_next()\n",
    "\n",
    "        e_s, e_p, e_o = self._lookup_embeddings(x_pos_tf)\n",
    "        scores_pos = self._fn(e_s, e_p, e_o)\n",
    "\n",
    "        x_neg_tf = generate_corruptions_for_fit(x_pos_tf,\n",
    "                                                entities_list=None,\n",
    "                                                eta=1,\n",
    "                                                corrupt_side='s+o',\n",
    "                                                entities_size=0,\n",
    "                                                rnd=self.seed)\n",
    "\n",
    "        e_s_neg, e_p_neg, e_o_neg = self._lookup_embeddings(x_neg_tf)\n",
    "        scores = self._fn(e_s_neg, e_p_neg, e_o_neg)\n",
    "\n",
    "        epoch_iterator_with_progress = tqdm(range(1, epochs + 1), disable=(not self.verbose), unit='epoch')\n",
    "\n",
    "        scores_list = []\n",
    "        with tf.Session(config=self.tf_config) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for _ in epoch_iterator_with_progress:\n",
    "                losses = []\n",
    "                for batch in range(batches_count):\n",
    "                    scores_list.append(sess.run(scores))\n",
    "\n",
    "        dataset_handle.cleanup()\n",
    "        return np.concatenate(scores_list)\n",
    "    \n",
    "    except Exception as e:\n",
    "        dataset_handle.cleanup()\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_iso(cal_model, pos_scores, neg_scores, positive_base_rate):\n",
    "    weigths_pos = len(neg_scores) / len(pos_scores)\n",
    "    weights_neg = (1.0 - positive_base_rate) / positive_base_rate\n",
    "    weights = np.concatenate((np.full(pos_scores.shape, weigths_pos),\n",
    "                              np.full(neg_scores.shape, weights_neg))).astype(float)\n",
    "    target =  np.concatenate((np.ones(pos_scores.shape), np.zeros(neg_scores.shape))).astype(float)\n",
    "    x = np.concatenate((pos_scores, neg_scores)).astype(float)\n",
    "    \n",
    "    cal_model.fit(x, target, sample_weight=weights)\n",
    "    return cal_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos [-0.89165145, -5.142675]\n",
      "pos neg [0.0, 0.0]\n",
      "pos sc -0.8603107272325426 -4.895681828295831\n",
      "pos neg sc 0.0 0.0\n",
      "{\n",
      "  \"eta\": 1,\n",
      "  \"brier_score_scores\": 0.41343093971872774,\n",
      "  \"log_loss_scores\": 1.779857533688991,\n",
      "  \"brier_score_probas_pos\": 0.09540378202326559,\n",
      "  \"log_loss_probas_pos\": 0.33894811057758867,\n",
      "  \"brier_score_probas_pos_neg\": 0.25,\n",
      "  \"log_loss_probas_pos_neg\": 0.6931471824645996,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.09002995339996255,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.3070340655845408,\n",
      "  \"brier_score_probas_pos_iso\": 0.09012063435396776,\n",
      "  \"log_loss_probas_pos_iso\": 0.3083721391041788,\n",
      "  \"brier_score_probas_pos_sc\": 0.095743202245781,\n",
      "  \"log_loss_probas_pos_sc\": 0.3402299216938159,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.25,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.6931471805599453,\n",
      "  \"metrics_mrr\": 0.1730298391465115,\n",
      "  \"metrics_hits@10\": 0.2974448794560066,\n",
      "  \"metrics_mr\": 2557.2818359777457,\n",
      "  \"accuracy_per_relation\": 0.8732873236577692,\n",
      "  \"accuracy_uncalib\": 0.5074596569572719,\n",
      "  \"accuracy_pos\": 0.8827260732771745,\n",
      "  \"accuracy_pos_neg\": 0.5074596569572719,\n",
      "  \"accuracy_pos_neg_iso\": 0.8838932304881761,\n",
      "  \"accuracy_pos_iso\": 0.8838424845224805,\n",
      "  \"accuracy_pos_sc\": 0.8839947224195677,\n",
      "  \"accuracy_pos_neg_sc\": 0.5074596569572719\n",
      "}\n",
      "pos [-1.1260498, -6.6169887]\n",
      "pos neg [0.0, 0.0]\n",
      "pos sc -1.1901255206885764 -6.971087298790129\n",
      "pos neg sc 0.0 0.0\n",
      "{\n",
      "  \"eta\": 5,\n",
      "  \"brier_score_scores\": 0.43699580182355074,\n",
      "  \"log_loss_scores\": 1.9263225656813943,\n",
      "  \"brier_score_probas_pos\": 0.0928175764841796,\n",
      "  \"log_loss_probas_pos\": 0.314831150876862,\n",
      "  \"brier_score_probas_pos_neg\": 0.25,\n",
      "  \"log_loss_probas_pos_neg\": 0.6931471824645996,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.08919067183397894,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.2996443951092593,\n",
      "  \"brier_score_probas_pos_iso\": 0.08932255482003924,\n",
      "  \"log_loss_probas_pos_iso\": 0.30093377538946225,\n",
      "  \"brier_score_probas_pos_sc\": 0.09197386629414231,\n",
      "  \"log_loss_probas_pos_sc\": 0.3125359724659912,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.25,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.6931471805599453,\n",
      "  \"metrics_mrr\": 0.15825282048874292,\n",
      "  \"metrics_hits@10\": 0.3025963321656707,\n",
      "  \"metrics_mr\": 2478.5579023284567,\n",
      "  \"accuracy_per_relation\": 0.8780066984674718,\n",
      "  \"accuracy_uncalib\": 0.5074596569572719,\n",
      "  \"accuracy_pos\": 0.8848066578706992,\n",
      "  \"accuracy_pos_neg\": 0.5074596569572719,\n",
      "  \"accuracy_pos_neg_iso\": 0.8834872627626104,\n",
      "  \"accuracy_pos_iso\": 0.8839439764538719,\n",
      "  \"accuracy_pos_sc\": 0.8849588957677864,\n",
      "  \"accuracy_pos_neg_sc\": 0.5074596569572719\n",
      "}\n",
      "pos [-1.1638818, -6.7997527]\n",
      "pos neg [0.0, 0.0]\n",
      "pos sc -1.2562460610886774 -7.327019448423238\n",
      "pos neg sc 0.0 0.0\n",
      "{\n",
      "  \"eta\": 10,\n",
      "  \"brier_score_scores\": 0.44288972620580214,\n",
      "  \"log_loss_scores\": 1.9627826902973162,\n",
      "  \"brier_score_probas_pos\": 0.09452725119964298,\n",
      "  \"log_loss_probas_pos\": 0.31901229678503784,\n",
      "  \"brier_score_probas_pos_neg\": 0.25,\n",
      "  \"log_loss_probas_pos_neg\": 0.6931471824645996,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.09045355172602294,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.3030175159803663,\n",
      "  \"brier_score_probas_pos_iso\": 0.09062425194459992,\n",
      "  \"log_loss_probas_pos_iso\": 0.3042374268648993,\n",
      "  \"brier_score_probas_pos_sc\": 0.0933914239174088,\n",
      "  \"log_loss_probas_pos_sc\": 0.31574640043666113,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.25,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.6931471805599453,\n",
      "  \"metrics_mrr\": 0.15655321917006945,\n",
      "  \"metrics_hits@10\": 0.30336905007212034,\n",
      "  \"metrics_mr\": 2501.722233669895,\n",
      "  \"accuracy_per_relation\": 0.8764843194966,\n",
      "  \"accuracy_uncalib\": 0.5074596569572719,\n",
      "  \"accuracy_pos\": 0.883740992591089,\n",
      "  \"accuracy_pos_neg\": 0.5074596569572719,\n",
      "  \"accuracy_pos_neg_iso\": 0.8831320410027402,\n",
      "  \"accuracy_pos_iso\": 0.8832335329341318,\n",
      "  \"accuracy_pos_sc\": 0.8838932304881761,\n",
      "  \"accuracy_pos_neg_sc\": 0.5074596569572719\n",
      "}\n",
      "pos [-1.1893537, -6.8957243]\n",
      "pos neg [0.0, 0.0]\n",
      "pos sc -1.3033177753103278 -7.550681144382195\n",
      "pos neg sc 0.0 0.0\n",
      "{\n",
      "  \"eta\": 20,\n",
      "  \"brier_score_scores\": 0.4464697619889876,\n",
      "  \"log_loss_scores\": 1.9813387355672207,\n",
      "  \"brier_score_probas_pos\": 0.0960493286035683,\n",
      "  \"log_loss_probas_pos\": 0.32289430283591825,\n",
      "  \"brier_score_probas_pos_neg\": 0.25,\n",
      "  \"log_loss_probas_pos_neg\": 0.6931471824645996,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.09178954065002219,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.306306798566133,\n",
      "  \"brier_score_probas_pos_iso\": 0.09194003986733601,\n",
      "  \"log_loss_probas_pos_iso\": 0.30754382573448785,\n",
      "  \"brier_score_probas_pos_sc\": 0.09471047591111889,\n",
      "  \"log_loss_probas_pos_sc\": 0.31894491790285634,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.25,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.6931471805599453,\n",
      "  \"metrics_mrr\": 0.15589600212297305,\n",
      "  \"metrics_hits@10\": 0.3058417473727591,\n",
      "  \"metrics_mr\": 2520.4262827117245,\n",
      "  \"accuracy_per_relation\": 0.8743529889373794,\n",
      "  \"accuracy_uncalib\": 0.5074596569572719,\n",
      "  \"accuracy_pos\": 0.8826753273114787,\n",
      "  \"accuracy_pos_neg\": 0.5074596569572719,\n",
      "  \"accuracy_pos_neg_iso\": 0.8826753273114787,\n",
      "  \"accuracy_pos_iso\": 0.8826753273114787,\n",
      "  \"accuracy_pos_sc\": 0.8827260732771745,\n",
      "  \"accuracy_pos_neg_sc\": 0.5074596569572719\n",
      "}\n",
      "pos [-1.2100093, -6.96151]\n",
      "pos neg [0.0, 0.0]\n",
      "pos sc -1.3361779790417976 -7.682512016263989\n",
      "pos neg sc 0.0 0.0\n",
      "{\n",
      "  \"eta\": 50,\n",
      "  \"brier_score_scores\": 0.44887219650170773,\n",
      "  \"log_loss_scores\": 1.9905056551461842,\n",
      "  \"brier_score_probas_pos\": 0.09730887100099073,\n",
      "  \"log_loss_probas_pos\": 0.325996146064111,\n",
      "  \"brier_score_probas_pos_neg\": 0.25,\n",
      "  \"log_loss_probas_pos_neg\": 0.6931471824645996,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.09292595919602632,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.30977762317568597,\n",
      "  \"brier_score_probas_pos_iso\": 0.09334440944107618,\n",
      "  \"log_loss_probas_pos_iso\": 0.3107474610178105,\n",
      "  \"brier_score_probas_pos_sc\": 0.09586833868402769,\n",
      "  \"log_loss_probas_pos_sc\": 0.3216681802779934,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.25,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.6931471805599453,\n",
      "  \"metrics_mrr\": 0.15461477382376312,\n",
      "  \"metrics_hits@10\": 0.3079538429837214,\n",
      "  \"metrics_mr\": 2536.1518133113536,\n",
      "  \"accuracy_per_relation\": 0.8728306099665076,\n",
      "  \"accuracy_uncalib\": 0.5074596569572719,\n",
      "  \"accuracy_pos\": 0.8806454886836497,\n",
      "  \"accuracy_pos_neg\": 0.5074596569572719,\n",
      "  \"accuracy_pos_neg_iso\": 0.8799857911296052,\n",
      "  \"accuracy_pos_iso\": 0.879478331472648,\n",
      "  \"accuracy_pos_sc\": 0.8806454886836497,\n",
      "  \"accuracy_pos_neg_sc\": 0.5074596569572719\n",
      "}\n",
      "pos [-1.218014, -6.982495]\n",
      "pos neg [0.0, 0.0]\n",
      "pos sc -1.3520323658059314 -7.747374939090774\n",
      "pos neg sc 0.0 0.0\n",
      "{\n",
      "  \"eta\": 100,\n",
      "  \"brier_score_scores\": 0.44965400461678695,\n",
      "  \"log_loss_scores\": 1.991206011944463,\n",
      "  \"brier_score_probas_pos\": 0.09765029012635787,\n",
      "  \"log_loss_probas_pos\": 0.3267459300198764,\n",
      "  \"brier_score_probas_pos_neg\": 0.25,\n",
      "  \"log_loss_probas_pos_neg\": 0.6931471824645996,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.0933258999337367,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.31103466927679235,\n",
      "  \"brier_score_probas_pos_iso\": 0.0935820985006523,\n",
      "  \"log_loss_probas_pos_iso\": 0.31119318729355194,\n",
      "  \"brier_score_probas_pos_sc\": 0.09613802681966983,\n",
      "  \"log_loss_probas_pos_sc\": 0.32213032110682666,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.25,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.6931471805599453,\n",
      "  \"metrics_mrr\": 0.15483389162246403,\n",
      "  \"metrics_hits@10\": 0.3104265402843602,\n",
      "  \"metrics_mr\": 2528.083556562951,\n",
      "  \"accuracy_per_relation\": 0.8715619608241145,\n",
      "  \"accuracy_uncalib\": 0.5074596569572719,\n",
      "  \"accuracy_pos\": 0.8802902669237795,\n",
      "  \"accuracy_pos_neg\": 0.5074596569572719,\n",
      "  \"accuracy_pos_neg_iso\": 0.879833553232518,\n",
      "  \"accuracy_pos_iso\": 0.8799350451639095,\n",
      "  \"accuracy_pos_sc\": 0.8802902669237795,\n",
      "  \"accuracy_pos_neg_sc\": 0.5074596569572719\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for eta in [1, 5, 10, 20, 50, 100]:\n",
    "    model = TransE(batches_count=64, seed=0, epochs=500, k=100, eta=eta,\n",
    "                   optimizer='adam', optimizer_params={'lr':0.0001},\n",
    "                   loss='self_adversarial', verbose=False)\n",
    "\n",
    "    model.fit(X['train'])\n",
    "    \n",
    "    scores = model.predict(X['test'])\n",
    "\n",
    "    model.calibrate(X_valid_pos, batches_count=10, epochs=1000, positive_base_rate=0.5)\n",
    "    print(\"pos\", model.calibration_parameters)\n",
    "    probas1 = model.predict_proba(X['test'])\n",
    "\n",
    "    model.calibrate(X_valid_pos, X_valid_neg)\n",
    "    print(\"pos neg\", model.calibration_parameters)\n",
    "    probas2 = model.predict_proba(X['test'])\n",
    "    \n",
    "    val_scores = model.predict(X['valid'])\n",
    "    ir = IsotonicRegression(out_of_bounds='clip')\n",
    "    ir.fit(np.squeeze(val_scores).astype(float), (X['valid_labels']).astype(float))\n",
    "    probas3 = ir.predict(np.squeeze(scores).astype(float))\n",
    "    \n",
    "    model.generate_corruptions = types.MethodType(generate_corruptions, model)\n",
    "    corruptions = model.generate_corruptions(X_valid_pos, batches_count=10, epochs=1000)\n",
    "    val_pos_scores = np.squeeze(model.predict(X_valid_pos))\n",
    "    iso_pos = pos_iso(IsotonicRegression(out_of_bounds='clip'), val_pos_scores, corruptions, positive_base_rate=0.5)\n",
    "    probas4 = iso_pos.predict(np.squeeze(scores).astype(float))\n",
    "\n",
    "    sc_pos = pos_iso(_SigmoidCalibration(), val_pos_scores, corruptions, positive_base_rate=0.5)\n",
    "    print(\"pos sc\", sc_pos.a_, sc_pos.b_)\n",
    "    probas5 = sc_pos.predict(np.squeeze(scores).astype(float))\n",
    "    \n",
    "    val_neg_scores = np.squeeze(model.predict(X_valid_neg))\n",
    "    sc_pos_neg = pos_iso(_SigmoidCalibration(), val_pos_scores, val_neg_scores, positive_base_rate=0.5)\n",
    "    print(\"pos neg sc\", sc_pos_neg.a_, sc_pos_neg.b_)\n",
    "    probas6 = sc_pos_neg.predict(np.squeeze(scores).astype(float))\n",
    "    \n",
    "    thresholds = {r: np.median(np.sort(val_scores[X['valid'][:, 1] == r])) for r in np.unique(X['valid'][:, 1])}\n",
    "    thresholds_test = np.vectorize(thresholds.get)(X['test'][:, 1])\n",
    "    per_relation_acc = accuracy_score(X['test_labels'], scores > thresholds_test)\n",
    "\n",
    "    acc_uncalib = accuracy_score(X['test_labels'], expit(scores) > 0.5)\n",
    "    \n",
    "    acc1 = accuracy_score(X['test_labels'], probas1 > 0.5)\n",
    "    acc2 = accuracy_score(X['test_labels'], probas2 > 0.5)\n",
    "    acc3 = accuracy_score(X['test_labels'], probas3 > 0.5)\n",
    "    acc4 = accuracy_score(X['test_labels'], probas4 > 0.5)\n",
    "    acc5 = accuracy_score(X['test_labels'], probas5 > 0.5)\n",
    "    acc6 = accuracy_score(X['test_labels'], probas6 > 0.5)\n",
    "    \n",
    "    filter_triples = np.concatenate((X['train'], X_valid_pos, X_test_pos))\n",
    "    ranks = evaluate_performance(X_test_pos, \n",
    "                                 model=model, \n",
    "                                 filter_triples=filter_triples,\n",
    "                                 use_default_protocol=True, \n",
    "                                 verbose=False)\n",
    "\n",
    "    results.append({\n",
    "        'eta': eta,\n",
    "        'brier_score_scores': brier_score_loss(X['test_labels'], expit(scores)),\n",
    "        'log_loss_scores': log_loss(X['test_labels'], expit(scores), eps=1e-7),\n",
    "        'brier_score_probas_pos': brier_score_loss(X['test_labels'], probas1),\n",
    "        'log_loss_probas_pos': log_loss(X['test_labels'], probas1, eps=1e-7),\n",
    "        'brier_score_probas_pos_neg': brier_score_loss(X['test_labels'], probas2),\n",
    "        'log_loss_probas_pos_neg': log_loss(X['test_labels'], probas2, eps=1e-7),\n",
    "        'brier_score_probas_pos_neg_iso': brier_score_loss(X['test_labels'], probas3),\n",
    "        'log_loss_probas_pos_neg_iso': log_loss(X['test_labels'], probas3, eps=1e-7),\n",
    "        'brier_score_probas_pos_iso': brier_score_loss(X['test_labels'], probas4),\n",
    "        'log_loss_probas_pos_iso': log_loss(X['test_labels'], probas4, eps=1e-7),\n",
    "        'brier_score_probas_pos_sc': brier_score_loss(X['test_labels'], probas5),\n",
    "        'log_loss_probas_pos_sc': log_loss(X['test_labels'], probas5, eps=1e-7),\n",
    "        'brier_score_probas_pos_neg_sc': brier_score_loss(X['test_labels'], probas6),\n",
    "        'log_loss_probas_pos_neg_sc': log_loss(X['test_labels'], probas6, eps=1e-7),\n",
    "        'metrics_mrr': mrr_score(ranks), \n",
    "        'metrics_hits@10': hits_at_n_score(ranks, n=10),\n",
    "        'metrics_mr': mr_score(ranks),\n",
    "        'accuracy_per_relation': per_relation_acc,\n",
    "        'accuracy_uncalib': acc_uncalib,\n",
    "        'accuracy_pos': acc1,\n",
    "        'accuracy_pos_neg': acc2,\n",
    "        'accuracy_pos_neg_iso': acc3,\n",
    "        'accuracy_pos_iso': acc4,\n",
    "        'accuracy_pos_sc': acc5,\n",
    "        'accuracy_pos_neg_sc': acc6\n",
    "    })\n",
    "        \n",
    "    print(json.dumps(results[-1], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_results = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos [-0.8840532, -3.2565536]\n",
      "pos neg [0.0, 0.0]\n",
      "pos sc -0.9515330038453764 -3.5175033723671834\n",
      "pos neg sc 0.0 0.0\n",
      "{\n",
      "  \"k\": 10,\n",
      "  \"brier_score_scores\": 0.451166679258168,\n",
      "  \"log_loss_scores\": 1.692979506817554,\n",
      "  \"brier_score_probas_pos\": 0.21652967104352755,\n",
      "  \"log_loss_probas_pos\": 0.6212857902857423,\n",
      "  \"brier_score_probas_pos_neg\": 0.25,\n",
      "  \"log_loss_probas_pos_neg\": 0.6931471824645996,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.21380621451564133,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.6171046962616317,\n",
      "  \"brier_score_probas_pos_iso\": 0.21527285481801192,\n",
      "  \"log_loss_probas_pos_iso\": 0.6187579500551534,\n",
      "  \"brier_score_probas_pos_sc\": 0.21710770414936448,\n",
      "  \"log_loss_probas_pos_sc\": 0.6227354870313124,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.25,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.6931471805599453,\n",
      "  \"metrics_mrr\": 0.03978243710736639,\n",
      "  \"metrics_hits@10\": 0.07495363692561302,\n",
      "  \"metrics_mr\": 9773.627601483618,\n",
      "  \"accuracy_per_relation\": 0.6649243885111134,\n",
      "  \"accuracy_uncalib\": 0.5074596569572719,\n",
      "  \"accuracy_pos\": 0.6362529178930275,\n",
      "  \"accuracy_pos_neg\": 0.5074596569572719,\n",
      "  \"accuracy_pos_neg_iso\": 0.6367603775499848,\n",
      "  \"accuracy_pos_iso\": 0.6366588856185933,\n",
      "  \"accuracy_pos_sc\": 0.6355424743732874,\n",
      "  \"accuracy_pos_neg_sc\": 0.5074596569572719\n",
      "}\n",
      "pos [-1.085478, -5.6807094]\n",
      "pos neg [0.0, 0.0]\n",
      "pos sc -1.086553268011478 -5.655060333938201\n",
      "pos neg sc 0.0 0.0\n",
      "{\n",
      "  \"k\": 25,\n",
      "  \"brier_score_scores\": 0.4569732779820942,\n",
      "  \"log_loss_scores\": 2.0480810844832473,\n",
      "  \"brier_score_probas_pos\": 0.14804986721841185,\n",
      "  \"log_loss_probas_pos\": 0.46108149448110375,\n",
      "  \"brier_score_probas_pos_neg\": 0.25,\n",
      "  \"log_loss_probas_pos_neg\": 0.6931471824645996,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.14424572834812183,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.44495363901456386,\n",
      "  \"brier_score_probas_pos_iso\": 0.1441480721679234,\n",
      "  \"log_loss_probas_pos_iso\": 0.44407467056575295,\n",
      "  \"brier_score_probas_pos_sc\": 0.14779629418421186,\n",
      "  \"log_loss_probas_pos_sc\": 0.4611462385347182,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.25,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.6931471805599453,\n",
      "  \"metrics_mrr\": 0.12516933622971993,\n",
      "  \"metrics_hits@10\": 0.21574283948073356,\n",
      "  \"metrics_mr\": 4733.079126313621,\n",
      "  \"accuracy_per_relation\": 0.7957474880746981,\n",
      "  \"accuracy_uncalib\": 0.5074596569572719,\n",
      "  \"accuracy_pos\": 0.786257992489597,\n",
      "  \"accuracy_pos_neg\": 0.5074596569572719,\n",
      "  \"accuracy_pos_neg_iso\": 0.794631076829392,\n",
      "  \"accuracy_pos_iso\": 0.7946818227950878,\n",
      "  \"accuracy_pos_sc\": 0.7879833553232518,\n",
      "  \"accuracy_pos_neg_sc\": 0.5074596569572719\n",
      "}\n",
      "pos [-1.1649492, -6.619066]\n",
      "pos neg [0.0, 0.0]\n",
      "pos sc -1.217564568921278 -6.885488434642508\n",
      "pos neg sc 0.0 0.0\n",
      "{\n",
      "  \"k\": 50,\n",
      "  \"brier_score_scores\": 0.4523723816884954,\n",
      "  \"log_loss_scores\": 2.0327484569620835,\n",
      "  \"brier_score_probas_pos\": 0.11095248321809192,\n",
      "  \"log_loss_probas_pos\": 0.3630816104293552,\n",
      "  \"brier_score_probas_pos_neg\": 0.25,\n",
      "  \"log_loss_probas_pos_neg\": 0.6931471824645996,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.1073997136525896,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.35113564467210984,\n",
      "  \"brier_score_probas_pos_iso\": 0.10749717187390895,\n",
      "  \"log_loss_probas_pos_iso\": 0.3512071699558239,\n",
      "  \"brier_score_probas_pos_sc\": 0.11022062859678554,\n",
      "  \"log_loss_probas_pos_sc\": 0.36165809913388286,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.25,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.6931471805599453,\n",
      "  \"metrics_mrr\": 0.15337982604234432,\n",
      "  \"metrics_hits@10\": 0.29342674634246857,\n",
      "  \"metrics_mr\": 3097.3568411291985,\n",
      "  \"accuracy_per_relation\": 0.8490307520552116,\n",
      "  \"accuracy_uncalib\": 0.5074596569572719,\n",
      "  \"accuracy_pos\": 0.8551710139043947,\n",
      "  \"accuracy_pos_neg\": 0.5074596569572719,\n",
      "  \"accuracy_pos_neg_iso\": 0.8570993606008322,\n",
      "  \"accuracy_pos_iso\": 0.8570993606008322,\n",
      "  \"accuracy_pos_sc\": 0.8562366791840049,\n",
      "  \"accuracy_pos_neg_sc\": 0.5074596569572719\n",
      "}\n",
      "pos [-1.1889946, -6.8933015]\n",
      "pos neg [0.0, 0.0]\n",
      "pos sc -1.3026561825152607 -7.54607280298162\n",
      "pos neg sc 0.0 0.0\n",
      "{\n",
      "  \"k\": 100,\n",
      "  \"brier_score_scores\": 0.4464819982541429,\n",
      "  \"log_loss_scores\": 1.9815199098574756,\n",
      "  \"brier_score_probas_pos\": 0.0960570207576578,\n",
      "  \"log_loss_probas_pos\": 0.3229481111146624,\n",
      "  \"brier_score_probas_pos_neg\": 0.25,\n",
      "  \"log_loss_probas_pos_neg\": 0.6931471824645996,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.09170357713587803,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.30614600018324784,\n",
      "  \"brier_score_probas_pos_iso\": 0.09197719868464173,\n",
      "  \"log_loss_probas_pos_iso\": 0.3076601696429421,\n",
      "  \"brier_score_probas_pos_sc\": 0.0947180531396277,\n",
      "  \"log_loss_probas_pos_sc\": 0.3190037360753413,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.25,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.6931471805599453,\n",
      "  \"metrics_mrr\": 0.1557464157740601,\n",
      "  \"metrics_hits@10\": 0.30512054399340616,\n",
      "  \"metrics_mr\": 2520.0503296929733,\n",
      "  \"accuracy_per_relation\": 0.8754186542169897,\n",
      "  \"accuracy_uncalib\": 0.5074596569572719,\n",
      "  \"accuracy_pos\": 0.8828275652085659,\n",
      "  \"accuracy_pos_neg\": 0.5074596569572719,\n",
      "  \"accuracy_pos_neg_iso\": 0.8826753273114787,\n",
      "  \"accuracy_pos_iso\": 0.8818633918603471,\n",
      "  \"accuracy_pos_sc\": 0.8828783111742616,\n",
      "  \"accuracy_pos_neg_sc\": 0.5074596569572719\n",
      "}\n",
      "pos [-1.1984215, -7.0024867]\n",
      "pos neg [0.0, 0.0]\n",
      "pos sc -1.3334939534074521 -7.8147627240639395\n",
      "pos neg sc 0.0 0.0\n",
      "{\n",
      "  \"k\": 200,\n",
      "  \"brier_score_scores\": 0.44341764684811075,\n",
      "  \"log_loss_scores\": 1.947405572480758,\n",
      "  \"brier_score_probas_pos\": 0.08920557593180586,\n",
      "  \"log_loss_probas_pos\": 0.30253728913323946,\n",
      "  \"brier_score_probas_pos_neg\": 0.25,\n",
      "  \"log_loss_probas_pos_neg\": 0.6931471824645996,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.08574962492877412,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.28997443909226056,\n",
      "  \"brier_score_probas_pos_iso\": 0.0858767111196822,\n",
      "  \"log_loss_probas_pos_iso\": 0.28998958762720173,\n",
      "  \"brier_score_probas_pos_sc\": 0.08775078803281051,\n",
      "  \"log_loss_probas_pos_sc\": 0.29731537493590515,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.25,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.6931471805599453,\n",
      "  \"metrics_mrr\": 0.1551005340060953,\n",
      "  \"metrics_hits@10\": 0.3079538429837214,\n",
      "  \"metrics_mr\": 2186.6361013805895,\n",
      "  \"accuracy_per_relation\": 0.882624581345783,\n",
      "  \"accuracy_uncalib\": 0.5074596569572719,\n",
      "  \"accuracy_pos\": 0.8891200649548361,\n",
      "  \"accuracy_pos_neg\": 0.5074596569572719,\n",
      "  \"accuracy_pos_neg_iso\": 0.8896275246117934,\n",
      "  \"accuracy_pos_iso\": 0.8900334923373592,\n",
      "  \"accuracy_pos_sc\": 0.889323048817619,\n",
      "  \"accuracy_pos_neg_sc\": 0.5074596569572719\n",
      "}\n",
      "pos [-1.1951044, -6.9945583]\n",
      "pos neg [0.0, 0.0]\n",
      "pos sc -1.3299526059182643 -7.804962310617148\n",
      "pos neg sc 0.0 0.0\n",
      "{\n",
      "  \"k\": 500,\n",
      "  \"brier_score_scores\": 0.4409431580983502,\n",
      "  \"log_loss_scores\": 1.9236668853495507,\n",
      "  \"brier_score_probas_pos\": 0.08759233450713359,\n",
      "  \"log_loss_probas_pos\": 0.2976679438330456,\n",
      "  \"brier_score_probas_pos_neg\": 0.25,\n",
      "  \"log_loss_probas_pos_neg\": 0.6931471824645996,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.08414439989824461,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.2856467995790693,\n",
      "  \"brier_score_probas_pos_iso\": 0.0841083228558499,\n",
      "  \"log_loss_probas_pos_iso\": 0.28501091856584226,\n",
      "  \"brier_score_probas_pos_sc\": 0.0862166991486074,\n",
      "  \"log_loss_probas_pos_sc\": 0.292697435883765,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.25,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.6931471805599453,\n",
      "  \"metrics_mrr\": 0.15442569179659227,\n",
      "  \"metrics_hits@10\": 0.30877807541726765,\n",
      "  \"metrics_mr\": 2113.512157428395,\n",
      "  \"accuracy_per_relation\": 0.8841977062823505,\n",
      "  \"accuracy_uncalib\": 0.5074596569572719,\n",
      "  \"accuracy_pos\": 0.8925200446564499,\n",
      "  \"accuracy_pos_neg\": 0.5074596569572719,\n",
      "  \"accuracy_pos_neg_iso\": 0.8932812341418858,\n",
      "  \"accuracy_pos_iso\": 0.8920633309651883,\n",
      "  \"accuracy_pos_sc\": 0.8927230285192327,\n",
      "  \"accuracy_pos_neg_sc\": 0.5074596569572719\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for k in [10, 25, 50, 100, 200, 500]:\n",
    "    model = TransE(batches_count=64, seed=0, epochs=500, k=k, eta=20,\n",
    "                   optimizer='adam', optimizer_params={'lr':0.0001},\n",
    "                   loss='self_adversarial', verbose=False)\n",
    "\n",
    "    model.fit(X['train'])\n",
    "    \n",
    "    scores = model.predict(X['test'])\n",
    "\n",
    "    model.calibrate(X_valid_pos, batches_count=10, epochs=1000, positive_base_rate=0.5)\n",
    "    print(\"pos\", model.calibration_parameters)\n",
    "    probas1 = model.predict_proba(X['test'])\n",
    "\n",
    "    model.calibrate(X_valid_pos, X_valid_neg)\n",
    "    print(\"pos neg\", model.calibration_parameters)\n",
    "    probas2 = model.predict_proba(X['test'])\n",
    "    \n",
    "    val_scores = model.predict(X['valid'])\n",
    "    ir = IsotonicRegression(out_of_bounds='clip')\n",
    "    ir.fit(np.squeeze(val_scores).astype(float), (X['valid_labels']).astype(float))\n",
    "    probas3 = ir.predict(np.squeeze(scores).astype(float))\n",
    "    \n",
    "    model.generate_corruptions = types.MethodType(generate_corruptions, model)\n",
    "    corruptions = model.generate_corruptions(X_valid_pos, batches_count=10, epochs=1000)\n",
    "    val_pos_scores = np.squeeze(model.predict(X_valid_pos))\n",
    "    iso_pos = pos_iso(IsotonicRegression(out_of_bounds='clip'), val_pos_scores, corruptions, positive_base_rate=0.5)\n",
    "    probas4 = iso_pos.predict(np.squeeze(scores).astype(float))\n",
    "\n",
    "    sc_pos = pos_iso(_SigmoidCalibration(), val_pos_scores, corruptions, positive_base_rate=0.5)\n",
    "    print(\"pos sc\", sc_pos.a_, sc_pos.b_)\n",
    "    probas5 = sc_pos.predict(np.squeeze(scores).astype(float))\n",
    "    \n",
    "    val_neg_scores = np.squeeze(model.predict(X_valid_neg))\n",
    "    sc_pos_neg = pos_iso(_SigmoidCalibration(), val_pos_scores, val_neg_scores, positive_base_rate=0.5)\n",
    "    print(\"pos neg sc\", sc_pos_neg.a_, sc_pos_neg.b_)\n",
    "    probas6 = sc_pos_neg.predict(np.squeeze(scores).astype(float))\n",
    "    \n",
    "    thresholds = {r: np.median(np.sort(val_scores[X['valid'][:, 1] == r])) for r in np.unique(X['valid'][:, 1])}\n",
    "    thresholds_test = np.vectorize(thresholds.get)(X['test'][:, 1])\n",
    "    per_relation_acc = accuracy_score(X['test_labels'], scores > thresholds_test)\n",
    "\n",
    "    acc_uncalib = accuracy_score(X['test_labels'], expit(scores) > 0.5)\n",
    "    \n",
    "    acc1 = accuracy_score(X['test_labels'], probas1 > 0.5)\n",
    "    acc2 = accuracy_score(X['test_labels'], probas2 > 0.5)\n",
    "    acc3 = accuracy_score(X['test_labels'], probas3 > 0.5)\n",
    "    acc4 = accuracy_score(X['test_labels'], probas4 > 0.5)\n",
    "    acc5 = accuracy_score(X['test_labels'], probas5 > 0.5)\n",
    "    acc6 = accuracy_score(X['test_labels'], probas6 > 0.5)\n",
    "    \n",
    "    filter_triples = np.concatenate((X['train'], X_valid_pos, X_test_pos))\n",
    "    ranks = evaluate_performance(X_test_pos, \n",
    "                                 model=model, \n",
    "                                 filter_triples=filter_triples,\n",
    "                                 use_default_protocol=True, \n",
    "                                 verbose=False)\n",
    "\n",
    "    results.append({\n",
    "        'k': k,\n",
    "        'brier_score_scores': brier_score_loss(X['test_labels'], expit(scores)),\n",
    "        'log_loss_scores': log_loss(X['test_labels'], expit(scores), eps=1e-7),\n",
    "        'brier_score_probas_pos': brier_score_loss(X['test_labels'], probas1),\n",
    "        'log_loss_probas_pos': log_loss(X['test_labels'], probas1, eps=1e-7),\n",
    "        'brier_score_probas_pos_neg': brier_score_loss(X['test_labels'], probas2),\n",
    "        'log_loss_probas_pos_neg': log_loss(X['test_labels'], probas2, eps=1e-7),\n",
    "        'brier_score_probas_pos_neg_iso': brier_score_loss(X['test_labels'], probas3),\n",
    "        'log_loss_probas_pos_neg_iso': log_loss(X['test_labels'], probas3, eps=1e-7),\n",
    "        'brier_score_probas_pos_iso': brier_score_loss(X['test_labels'], probas4),\n",
    "        'log_loss_probas_pos_iso': log_loss(X['test_labels'], probas4, eps=1e-7),\n",
    "        'brier_score_probas_pos_sc': brier_score_loss(X['test_labels'], probas5),\n",
    "        'log_loss_probas_pos_sc': log_loss(X['test_labels'], probas5, eps=1e-7),\n",
    "        'brier_score_probas_pos_neg_sc': brier_score_loss(X['test_labels'], probas6),\n",
    "        'log_loss_probas_pos_neg_sc': log_loss(X['test_labels'], probas6, eps=1e-7),\n",
    "        'metrics_mrr': mrr_score(ranks), \n",
    "        'metrics_hits@10': hits_at_n_score(ranks, n=10),\n",
    "        'metrics_mr': mr_score(ranks),\n",
    "        'accuracy_per_relation': per_relation_acc,\n",
    "        'accuracy_uncalib': acc_uncalib,\n",
    "        'accuracy_pos': acc1,\n",
    "        'accuracy_pos_neg': acc2,\n",
    "        'accuracy_pos_neg_iso': acc3,\n",
    "        'accuracy_pos_iso': acc4,\n",
    "        'accuracy_pos_sc': acc5,\n",
    "        'accuracy_pos_neg_sc': acc6\n",
    "    })\n",
    "        \n",
    "    print(json.dumps(results[-1], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_results = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
