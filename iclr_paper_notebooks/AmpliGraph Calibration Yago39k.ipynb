{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.calibration import calibration_curve, _SigmoidCalibration\n",
    "from ampligraph.evaluation import evaluate_performance, mr_score, mrr_score, hits_at_n_score, generate_corruptions_for_eval\n",
    "from sklearn.metrics import brier_score_loss, log_loss, accuracy_score\n",
    "from scipy.special import expit\n",
    "\n",
    "from ampligraph.datasets import load_wordnet11\n",
    "from ampligraph.latent_features.models import TransE, ComplEx, DistMult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (pd.read_csv(\"TransC/data/YAGO39K/Train/triple2id.txt\", sep=' ', skiprows=1, names=['s', 'o', 'p'])\n",
    "           [['s', 'p', 'o']]\n",
    "           .reindex()\n",
    "           .values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent = np.unique(np.concatenate((X_train[:, 0], X_train[:, 2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_pos = (pd.read_csv(\"TransC/data/YAGO39K/Valid/triple2id_positive.txt\", sep=' ', skiprows=1, names=['s', 'o', 'p'])\n",
    "               [['s', 'p', 'o']]\n",
    "               .reindex()\n",
    "               .query(\"s in @ent and o in @ent\")\n",
    "               .values)\n",
    "\n",
    "X_valid_neg = (pd.read_csv(\"TransC/data/YAGO39K/Valid/triple2id_negative.txt\", sep=' ', skiprows=1, names=['s', 'o', 'p'])\n",
    "               [['s', 'p', 'o']]\n",
    "               .reindex()\n",
    "               .query(\"s in @ent and o in @ent\")\n",
    "               .values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pos = (pd.read_csv(\"TransC/data/YAGO39K/Valid/triple2id_positive.txt\", sep=' ', skiprows=1, names=['s', 'o', 'p'])\n",
    "              [['s', 'p', 'o']]\n",
    "              .reindex()\n",
    "              .query(\"s in @ent and o in @ent\")\n",
    "              .values)\n",
    "\n",
    "X_test_neg = (pd.read_csv(\"TransC/data/YAGO39K/Valid/triple2id_negative.txt\", sep=' ', skiprows=1, names=['s', 'o', 'p'])\n",
    "              [['s', 'p', 'o']]\n",
    "              .query(\"s in @ent and o in @ent\")\n",
    "              .reindex()\n",
    "              .values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {\n",
    "    'train': X_train,\n",
    "    'valid': np.concatenate((X_valid_pos, X_valid_neg)),\n",
    "    'test': np.concatenate((X_test_pos, X_test_neg)),\n",
    "    'valid_labels': np.concatenate((np.full(len(X_valid_pos), '1'), np.full(len(X_valid_neg), '-1'))),\n",
    "    'test_labels': np.concatenate((np.full(len(X_test_pos), '1'), np.full(len(X_test_neg), '-1')))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "from functools import partial\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import check_random_state\n",
    "from tqdm import tqdm\n",
    "from ampligraph.datasets import AmpligraphDatasetAdapter, NumpyDatasetAdapter\n",
    "from ampligraph.evaluation import generate_corruptions_for_fit, to_idx, generate_corruptions_for_eval, \\\n",
    "    hits_at_n_score, mrr_score\n",
    "\n",
    "\n",
    "def generate_corruptions(self, X_pos, batches_count, epochs):\n",
    "    try:\n",
    "        tf.reset_default_graph()\n",
    "        self.rnd = check_random_state(self.seed)\n",
    "        tf.random.set_random_seed(self.seed)\n",
    "\n",
    "        self._load_model_from_trained_params()\n",
    "\n",
    "        dataset_handle = NumpyDatasetAdapter()\n",
    "        dataset_handle.use_mappings(self.rel_to_idx, self.ent_to_idx)\n",
    "\n",
    "        dataset_handle.set_data(X_pos, \"pos\")\n",
    "\n",
    "        batch_size_pos = int(np.ceil(dataset_handle.get_size(\"pos\") / batches_count))\n",
    "\n",
    "        gen_fn = partial(dataset_handle.get_next_train_batch, batch_size=batch_size_pos, dataset_type=\"pos\")\n",
    "        dataset = tf.data.Dataset.from_generator(gen_fn,\n",
    "                                                 output_types=tf.int32,\n",
    "                                                 output_shapes=(None, 3))\n",
    "        dataset = dataset.repeat().prefetch(1)\n",
    "        dataset_iter = tf.data.make_one_shot_iterator(dataset)\n",
    "\n",
    "        x_pos_tf = dataset_iter.get_next()\n",
    "\n",
    "        e_s, e_p, e_o = self._lookup_embeddings(x_pos_tf)\n",
    "        scores_pos = self._fn(e_s, e_p, e_o)\n",
    "\n",
    "        x_neg_tf = generate_corruptions_for_fit(x_pos_tf,\n",
    "                                                entities_list=None,\n",
    "                                                eta=1,\n",
    "                                                corrupt_side='s+o',\n",
    "                                                entities_size=0,\n",
    "                                                rnd=self.seed)\n",
    "\n",
    "        e_s_neg, e_p_neg, e_o_neg = self._lookup_embeddings(x_neg_tf)\n",
    "        scores = self._fn(e_s_neg, e_p_neg, e_o_neg)\n",
    "\n",
    "        epoch_iterator_with_progress = tqdm(range(1, epochs + 1), disable=(not self.verbose), unit='epoch')\n",
    "\n",
    "        scores_list = []\n",
    "        with tf.Session(config=self.tf_config) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for _ in epoch_iterator_with_progress:\n",
    "                losses = []\n",
    "                for batch in range(batches_count):\n",
    "                    scores_list.append(sess.run(scores))\n",
    "\n",
    "        dataset_handle.cleanup()\n",
    "        return np.concatenate(scores_list)\n",
    "    \n",
    "    except Exception as e:\n",
    "        dataset_handle.cleanup()\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_iso(cal_model, pos_scores, neg_scores, positive_base_rate):\n",
    "    weigths_pos = len(neg_scores) / len(pos_scores)\n",
    "    weights_neg = (1.0 - positive_base_rate) / positive_base_rate\n",
    "    weights = np.concatenate((np.full(pos_scores.shape, weigths_pos),\n",
    "                              np.full(neg_scores.shape, weights_neg))).astype(float)\n",
    "    target =  np.concatenate((np.ones(pos_scores.shape), np.zeros(neg_scores.shape))).astype(float)\n",
    "    x = np.concatenate((pos_scores, neg_scores)).astype(float)\n",
    "    \n",
    "    cal_model.fit(x, target, sample_weight=weights)\n",
    "    return cal_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING - From /home/ptabacof/.conda/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING - From /home/ptabacof/.conda/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "WARNING - From /home/ptabacof/.conda/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING - From /home/ptabacof/AmpliGraph-Lab/ampligraph/evaluation/protocol.py:348: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.random.categorical instead.\n",
      "WARNING - From /home/ptabacof/.conda/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "pos [-1.9906234, -7.067369]\n",
      "pos neg [-1.8516353, -5.5848007]\n",
      "pos sc -2.3224234379544813 -8.26226106292651\n",
      "pos neg sc -1.8523836160560438 -5.596022656508945\n",
      "{\n",
      "  \"model\": \"TransE\",\n",
      "  \"loss\": \"self_adversarial\",\n",
      "  \"brier_score_scores\": 0.3630828071709412,\n",
      "  \"log_loss_scores\": 1.0624504733201046,\n",
      "  \"brier_score_probas_pos\": 0.1055928046437762,\n",
      "  \"log_loss_probas_pos\": 0.3703692744122064,\n",
      "  \"brier_score_probas_pos_neg\": 0.09492535273753563,\n",
      "  \"log_loss_probas_pos_neg\": 0.3187292545466741,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.09270761420085519,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.30851389991917033,\n",
      "  \"brier_score_probas_pos_iso\": 0.10961991848664586,\n",
      "  \"log_loss_probas_pos_iso\": 0.37618111483367217,\n",
      "  \"brier_score_probas_pos_sc\": 0.10636214588180168,\n",
      "  \"log_loss_probas_pos_sc\": 0.38832045645817687,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.09488161608033316,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.31873287960069446,\n",
      "  \"metrics_mrr\": 0.16851154582226918,\n",
      "  \"metrics_hits@10\": 0.3190409331461281,\n",
      "  \"metrics_mr\": 244.60449292580194,\n",
      "  \"accuracy_per_relation\": 0.8875806451612903,\n",
      "  \"accuracy_uncalib\": 0.5022043010752688,\n",
      "  \"accuracy_pos\": 0.8655913978494624,\n",
      "  \"accuracy_pos_neg\": 0.8713440860215054,\n",
      "  \"accuracy_pos_neg_iso\": 0.8777956989247312,\n",
      "  \"accuracy_pos_iso\": 0.8491397849462365,\n",
      "  \"accuracy_pos_sc\": 0.8648924731182795,\n",
      "  \"accuracy_pos_neg_sc\": 0.871505376344086\n",
      "}\n",
      "pos [-0.7855571, -8.769924]\n",
      "pos neg [-1.3645936, -14.62411]\n",
      "pos sc -1.549845361735762 -17.2985716043915\n",
      "pos neg sc -1.3632390866146413 -14.617933328268094\n",
      "{\n",
      "  \"model\": \"TransE\",\n",
      "  \"loss\": \"pairwise\",\n",
      "  \"brier_score_scores\": 0.49772074388347165,\n",
      "  \"log_loss_scores\": 4.921945735433863,\n",
      "  \"brier_score_probas_pos\": 0.15242787077337475,\n",
      "  \"log_loss_probas_pos\": 0.4865037013158723,\n",
      "  \"brier_score_probas_pos_neg\": 0.123208328346179,\n",
      "  \"log_loss_probas_pos_neg\": 0.44454980222833146,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.10320889810531554,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.3517519332316571,\n",
      "  \"brier_score_probas_pos_iso\": 0.11293827956899179,\n",
      "  \"log_loss_probas_pos_iso\": 0.39293455449606485,\n",
      "  \"brier_score_probas_pos_sc\": 0.13953547628203666,\n",
      "  \"log_loss_probas_pos_sc\": 0.4784827552125384,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.12332184709502418,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.4445549083746815,\n",
      "  \"metrics_mrr\": 0.3714327374868514,\n",
      "  \"metrics_hits@10\": 0.6486661626525543,\n",
      "  \"metrics_mr\": 500.2052597472729,\n",
      "  \"accuracy_per_relation\": 0.8982258064516129,\n",
      "  \"accuracy_uncalib\": 0.5022043010752688,\n",
      "  \"accuracy_pos\": 0.8227956989247311,\n",
      "  \"accuracy_pos_neg\": 0.8627956989247312,\n",
      "  \"accuracy_pos_neg_iso\": 0.8713978494623655,\n",
      "  \"accuracy_pos_iso\": 0.8659677419354839,\n",
      "  \"accuracy_pos_sc\": 0.8232258064516129,\n",
      "  \"accuracy_pos_neg_sc\": 0.8626881720430107\n",
      "}\n",
      "pos [-2.379424, -1.7462682]\n",
      "pos neg [-2.6718714, -0.7846663]\n",
      "pos sc -2.3968727131636895 -1.7438828298495106\n",
      "pos neg sc -2.6686390681920433 -0.792429039050779\n",
      "{\n",
      "  \"model\": \"TransE\",\n",
      "  \"loss\": \"nll\",\n",
      "  \"brier_score_scores\": 0.21783368702718622,\n",
      "  \"log_loss_scores\": 0.6262823069746787,\n",
      "  \"brier_score_probas_pos\": 0.2357412229723462,\n",
      "  \"log_loss_probas_pos\": 0.6807377877356809,\n",
      "  \"brier_score_probas_pos_neg\": 0.18752995656610696,\n",
      "  \"log_loss_probas_pos_neg\": 0.5773331834854144,\n",
      "  \"brier_score_probas_pos_neg_iso\": 0.17023151100412076,\n",
      "  \"log_loss_probas_pos_neg_iso\": 0.5183467052240054,\n",
      "  \"brier_score_probas_pos_iso\": 0.20013915424951936,\n",
      "  \"log_loss_probas_pos_iso\": 0.6217215728914681,\n",
      "  \"brier_score_probas_pos_sc\": 0.23499894240715533,\n",
      "  \"log_loss_probas_pos_sc\": 0.6791981867589585,\n",
      "  \"brier_score_probas_pos_neg_sc\": 0.1875901703931119,\n",
      "  \"log_loss_probas_pos_neg_sc\": 0.5773289017686701,\n",
      "  \"metrics_mrr\": 0.06387513996475526,\n",
      "  \"metrics_hits@10\": 0.11264715412031537,\n",
      "  \"metrics_mr\": 1014.7097418727724,\n",
      "  \"accuracy_per_relation\": 0.7796236559139785,\n",
      "  \"accuracy_uncalib\": 0.5022043010752688,\n",
      "  \"accuracy_pos\": 0.6655376344086021,\n",
      "  \"accuracy_pos_neg\": 0.7144086021505376,\n",
      "  \"accuracy_pos_neg_iso\": 0.7596236559139785,\n",
      "  \"accuracy_pos_iso\": 0.7493010752688172,\n",
      "  \"accuracy_pos_sc\": 0.6686021505376344,\n",
      "  \"accuracy_pos_neg_sc\": 0.7133333333333334\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "losses =  ['self_adversarial', 'pairwise', 'nll', 'multiclass_nll']\n",
    "models = [TransE, DistMult, ComplEx]\n",
    "\n",
    "results = []\n",
    "\n",
    "for m, l in itertools.product(models, losses):\n",
    "    model = m(batches_count=64, seed=0, epochs=1000, k=100, eta=20,\n",
    "                   optimizer='adam', optimizer_params={'lr':0.0001},\n",
    "                   loss=l, verbose=False)\n",
    "\n",
    "    model.fit(X['train'])\n",
    "    \n",
    "    scores = model.predict(X['test'])\n",
    "\n",
    "    model.calibrate(X_valid_pos, batches_count=10, epochs=1000, positive_base_rate=0.5)\n",
    "    print(\"pos\", model.calibration_parameters)\n",
    "    probas1 = model.predict_proba(X['test'])\n",
    "\n",
    "    model.calibrate(X_valid_pos, X_valid_neg)\n",
    "    print(\"pos neg\", model.calibration_parameters)\n",
    "    probas2 = model.predict_proba(X['test'])\n",
    "    \n",
    "    val_scores = model.predict(X['valid'])\n",
    "    ir = IsotonicRegression(out_of_bounds='clip')\n",
    "    ir.fit(np.squeeze(val_scores).astype(float), (X['valid_labels'] == \"1\").astype(float))\n",
    "    probas3 = ir.predict(np.squeeze(scores).astype(float))\n",
    "    \n",
    "    model.generate_corruptions = types.MethodType(generate_corruptions, model)\n",
    "    corruptions = model.generate_corruptions(X_valid_pos, batches_count=10, epochs=1000)\n",
    "    val_pos_scores = np.squeeze(model.predict(X_valid_pos))\n",
    "    iso_pos = pos_iso(IsotonicRegression(out_of_bounds='clip'), val_pos_scores, corruptions, positive_base_rate=0.5)\n",
    "    probas4 = iso_pos.predict(np.squeeze(scores).astype(float))\n",
    "\n",
    "    sc_pos = pos_iso(_SigmoidCalibration(), val_pos_scores, corruptions, positive_base_rate=0.5)\n",
    "    print(\"pos sc\", sc_pos.a_, sc_pos.b_)\n",
    "    probas5 = sc_pos.predict(np.squeeze(scores).astype(float))\n",
    "    \n",
    "    val_neg_scores = np.squeeze(model.predict(X_valid_neg))\n",
    "    sc_pos_neg = pos_iso(_SigmoidCalibration(), val_pos_scores, val_neg_scores, positive_base_rate=0.5)\n",
    "    print(\"pos neg sc\", sc_pos_neg.a_, sc_pos_neg.b_)\n",
    "    probas6 = sc_pos_neg.predict(np.squeeze(scores).astype(float))\n",
    "    \n",
    "    thresholds = {r: np.median(np.sort(val_scores[X['valid'][:, 1] == r])) for r in np.unique(X['valid'][:, 1])}\n",
    "    thresholds_test = np.vectorize(thresholds.get)(X['test'][:, 1])\n",
    "    per_relation_acc = accuracy_score(X['test_labels'] == \"1\", scores > thresholds_test)\n",
    "\n",
    "    acc_uncalib = accuracy_score(X['test_labels'] == \"1\", expit(scores) > 0.5)\n",
    "\n",
    "    acc1 = accuracy_score(X['test_labels'] == \"1\", probas1 > 0.5)\n",
    "    acc2 = accuracy_score(X['test_labels'] == \"1\", probas2 > 0.5)\n",
    "    acc3 = accuracy_score(X['test_labels'] == \"1\", probas3 > 0.5)\n",
    "    acc4 = accuracy_score(X['test_labels'] == \"1\", probas4 > 0.5)\n",
    "    acc5 = accuracy_score(X['test_labels'] == \"1\", probas5 > 0.5)\n",
    "    acc6 = accuracy_score(X['test_labels'] == \"1\", probas6 > 0.5)\n",
    "    \n",
    "    filter_triples = np.concatenate((X['train'], X_valid_pos, X_test_pos))\n",
    "    ranks = evaluate_performance(X_test_pos, \n",
    "                                 model=model, \n",
    "                                 filter_triples=filter_triples,\n",
    "                                 use_default_protocol=True, \n",
    "                                 verbose=False)\n",
    "\n",
    "    results.append({\n",
    "        'model': m.__name__,\n",
    "        'loss': l,\n",
    "        'brier_score_scores': brier_score_loss(X['test_labels'] == \"1\", expit(scores)),\n",
    "        'log_loss_scores': log_loss(X['test_labels'] == \"1\", expit(scores), eps=1e-7),\n",
    "        'brier_score_probas_pos': brier_score_loss(X['test_labels'] == \"1\", probas1),\n",
    "        'log_loss_probas_pos': log_loss(X['test_labels'] == \"1\", probas1, eps=1e-7),\n",
    "        'brier_score_probas_pos_neg': brier_score_loss(X['test_labels'] == \"1\", probas2),\n",
    "        'log_loss_probas_pos_neg': log_loss(X['test_labels'] == \"1\", probas2, eps=1e-7),\n",
    "        'brier_score_probas_pos_neg_iso': brier_score_loss(X['test_labels'] == \"1\", probas3),\n",
    "        'log_loss_probas_pos_neg_iso': log_loss(X['test_labels'] == \"1\", probas3, eps=1e-7),\n",
    "        'brier_score_probas_pos_iso': brier_score_loss(X['test_labels'] == \"1\", probas4),\n",
    "        'log_loss_probas_pos_iso': log_loss(X['test_labels'] == \"1\", probas4, eps=1e-7),\n",
    "        'brier_score_probas_pos_sc': brier_score_loss(X['test_labels'] == \"1\", probas5),\n",
    "        'log_loss_probas_pos_sc': log_loss(X['test_labels'] == \"1\", probas5, eps=1e-7),\n",
    "        'brier_score_probas_pos_neg_sc': brier_score_loss(X['test_labels'] == \"1\", probas6),\n",
    "        'log_loss_probas_pos_neg_sc': log_loss(X['test_labels'] == \"1\", probas6, eps=1e-7),\n",
    "        'metrics_mrr': mrr_score(ranks), \n",
    "        'metrics_hits@10': hits_at_n_score(ranks, n=10),\n",
    "        'metrics_mr': mr_score(ranks),\n",
    "        'accuracy_per_relation': per_relation_acc,\n",
    "        'accuracy_uncalib': acc_uncalib,\n",
    "        'accuracy_pos': acc1,\n",
    "        'accuracy_pos_neg': acc2,\n",
    "        'accuracy_pos_neg_iso': acc3,\n",
    "        'accuracy_pos_iso': acc4,\n",
    "        'accuracy_pos_sc': acc5,\n",
    "        'accuracy_pos_neg_sc': acc6\n",
    "    })\n",
    "        \n",
    "    print(json.dumps(results[-1], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_min(s):\n",
    "    is_min = s == s.min()\n",
    "    return ['font-weight: bold' if v else '' for v in is_min]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results).set_index(['model', 'loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow0_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow1_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow2_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow3_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow4_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow5_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow6_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow7_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow8_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow9_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow10_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow11_col3 {\n",
       "            font-weight:  bold;\n",
       "        }</style><table id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ec\" ><thead>    <tr>        <th class=\"blank\" ></th>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >probas_pos</th>        <th class=\"col_heading level0 col1\" >probas_pos_iso</th>        <th class=\"col_heading level0 col2\" >probas_pos_neg</th>        <th class=\"col_heading level0 col3\" >probas_pos_neg_iso</th>        <th class=\"col_heading level0 col4\" >probas_pos_neg_sc</th>        <th class=\"col_heading level0 col5\" >probas_pos_sc</th>        <th class=\"col_heading level0 col6\" >scores</th>    </tr>    <tr>        <th class=\"index_name level0\" >model</th>        <th class=\"index_name level1\" >loss</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8eclevel0_row0\" class=\"row_heading level0 row0\" rowspan=4>TransE</th>\n",
       "                        <th id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8eclevel1_row0\" class=\"row_heading level1 row0\" >self_adversarial</th>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow0_col0\" class=\"data row0 col0\" >0.105593</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow0_col1\" class=\"data row0 col1\" >0.10962</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow0_col2\" class=\"data row0 col2\" >0.0949254</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow0_col3\" class=\"data row0 col3\" >0.0927076</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow0_col4\" class=\"data row0 col4\" >0.0948816</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow0_col5\" class=\"data row0 col5\" >0.106362</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow0_col6\" class=\"data row0 col6\" >0.363083</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8eclevel1_row1\" class=\"row_heading level1 row1\" >pairwise</th>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow1_col0\" class=\"data row1 col0\" >0.152428</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow1_col1\" class=\"data row1 col1\" >0.112938</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow1_col2\" class=\"data row1 col2\" >0.123208</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow1_col3\" class=\"data row1 col3\" >0.103209</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow1_col4\" class=\"data row1 col4\" >0.123322</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow1_col5\" class=\"data row1 col5\" >0.139535</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow1_col6\" class=\"data row1 col6\" >0.497721</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8eclevel1_row2\" class=\"row_heading level1 row2\" >nll</th>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow2_col0\" class=\"data row2 col0\" >0.235741</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow2_col1\" class=\"data row2 col1\" >0.200139</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow2_col2\" class=\"data row2 col2\" >0.18753</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow2_col3\" class=\"data row2 col3\" >0.170232</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow2_col4\" class=\"data row2 col4\" >0.18759</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow2_col5\" class=\"data row2 col5\" >0.234999</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow2_col6\" class=\"data row2 col6\" >0.217834</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8eclevel1_row3\" class=\"row_heading level1 row3\" >multiclass_nll</th>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow3_col0\" class=\"data row3 col0\" >0.126562</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow3_col1\" class=\"data row3 col1\" >0.116082</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow3_col2\" class=\"data row3 col2\" >0.111302</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow3_col3\" class=\"data row3 col3\" >0.103911</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow3_col4\" class=\"data row3 col4\" >0.111273</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow3_col5\" class=\"data row3 col5\" >0.122762</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow3_col6\" class=\"data row3 col6\" >0.497795</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8eclevel0_row4\" class=\"row_heading level0 row4\" rowspan=4>DistMult</th>\n",
       "                        <th id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8eclevel1_row4\" class=\"row_heading level1 row4\" >self_adversarial</th>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow4_col0\" class=\"data row4 col0\" >0.0928978</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow4_col1\" class=\"data row4 col1\" >0.0886699</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow4_col2\" class=\"data row4 col2\" >0.0813233</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow4_col3\" class=\"data row4 col3\" >0.0785058</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow4_col4\" class=\"data row4 col4\" >0.0813693</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow4_col5\" class=\"data row4 col5\" >0.0929009</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow4_col6\" class=\"data row4 col6\" >0.284488</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8eclevel1_row5\" class=\"row_heading level1 row5\" >pairwise</th>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow5_col0\" class=\"data row5 col0\" >0.149369</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow5_col1\" class=\"data row5 col1\" >0.133468</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow5_col2\" class=\"data row5 col2\" >0.129219</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow5_col3\" class=\"data row5 col3\" >0.115388</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow5_col4\" class=\"data row5 col4\" >0.129325</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow5_col5\" class=\"data row5 col5\" >0.148927</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow5_col6\" class=\"data row5 col6\" >0.371667</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8eclevel1_row6\" class=\"row_heading level1 row6\" >nll</th>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow6_col0\" class=\"data row6 col0\" >0.0768235</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow6_col1\" class=\"data row6 col1\" >0.0761126</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow6_col2\" class=\"data row6 col2\" >0.0717517</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow6_col3\" class=\"data row6 col3\" >0.0690451</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow6_col4\" class=\"data row6 col4\" >0.071781</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow6_col5\" class=\"data row6 col5\" >0.0768545</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow6_col6\" class=\"data row6 col6\" >0.104989</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8eclevel1_row7\" class=\"row_heading level1 row7\" >multiclass_nll</th>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow7_col0\" class=\"data row7 col0\" >0.150234</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow7_col1\" class=\"data row7 col1\" >0.134586</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow7_col2\" class=\"data row7 col2\" >0.126563</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow7_col3\" class=\"data row7 col3\" >0.112589</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow7_col4\" class=\"data row7 col4\" >0.126658</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow7_col5\" class=\"data row7 col5\" >0.14929</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow7_col6\" class=\"data row7 col6\" >0.456301</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8eclevel0_row8\" class=\"row_heading level0 row8\" rowspan=4>ComplEx</th>\n",
       "                        <th id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8eclevel1_row8\" class=\"row_heading level1 row8\" >self_adversarial</th>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow8_col0\" class=\"data row8 col0\" >0.0972693</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow8_col1\" class=\"data row8 col1\" >0.0948809</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow8_col2\" class=\"data row8 col2\" >0.0893608</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow8_col3\" class=\"data row8 col3\" >0.0843688</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow8_col4\" class=\"data row8 col4\" >0.0894297</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow8_col5\" class=\"data row8 col5\" >0.097268</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow8_col6\" class=\"data row8 col6\" >0.264185</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8eclevel1_row9\" class=\"row_heading level1 row9\" >pairwise</th>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow9_col0\" class=\"data row9 col0\" >0.130981</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow9_col1\" class=\"data row9 col1\" >0.12295</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow9_col2\" class=\"data row9 col2\" >0.114808</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow9_col3\" class=\"data row9 col3\" >0.106525</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow9_col4\" class=\"data row9 col4\" >0.114892</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow9_col5\" class=\"data row9 col5\" >0.131137</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow9_col6\" class=\"data row9 col6\" >0.321774</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8eclevel1_row10\" class=\"row_heading level1 row10\" >nll</th>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow10_col0\" class=\"data row10 col0\" >0.0726619</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow10_col1\" class=\"data row10 col1\" >0.0728427</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow10_col2\" class=\"data row10 col2\" >0.0691204</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow10_col3\" class=\"data row10 col3\" >0.0668039</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow10_col4\" class=\"data row10 col4\" >0.0691529</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow10_col5\" class=\"data row10 col5\" >0.0726807</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow10_col6\" class=\"data row10 col6\" >0.116176</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8eclevel1_row11\" class=\"row_heading level1 row11\" >multiclass_nll</th>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow11_col0\" class=\"data row11 col0\" >0.129535</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow11_col1\" class=\"data row11 col1\" >0.123032</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow11_col2\" class=\"data row11 col2\" >0.107907</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow11_col3\" class=\"data row11 col3\" >0.101173</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow11_col4\" class=\"data row11 col4\" >0.107994</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow11_col5\" class=\"data row11 col5\" >0.129032</td>\n",
       "                        <td id=\"T_b58ba622_df6c_11e9_ae70_3f6d31a8f8ecrow11_col6\" class=\"data row11 col6\" >0.428827</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f3aae947e10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = df[(c for c in df.columns if c.startswith('brier'))]\n",
    "bs.columns = [c[len(\"brier_score_\"):] for c in bs.columns]\n",
    "bs.style.apply(highlight_min, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow0_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow1_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow2_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow3_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow4_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow5_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow6_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow7_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow8_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow9_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow10_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow11_col3 {\n",
       "            font-weight:  bold;\n",
       "        }</style><table id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ec\" ><thead>    <tr>        <th class=\"blank\" ></th>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >probas_pos</th>        <th class=\"col_heading level0 col1\" >probas_pos_iso</th>        <th class=\"col_heading level0 col2\" >probas_pos_neg</th>        <th class=\"col_heading level0 col3\" >probas_pos_neg_iso</th>        <th class=\"col_heading level0 col4\" >probas_pos_neg_sc</th>        <th class=\"col_heading level0 col5\" >probas_pos_sc</th>        <th class=\"col_heading level0 col6\" >scores</th>    </tr>    <tr>        <th class=\"index_name level0\" >model</th>        <th class=\"index_name level1\" >loss</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8eclevel0_row0\" class=\"row_heading level0 row0\" rowspan=4>TransE</th>\n",
       "                        <th id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8eclevel1_row0\" class=\"row_heading level1 row0\" >self_adversarial</th>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow0_col0\" class=\"data row0 col0\" >0.370369</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow0_col1\" class=\"data row0 col1\" >0.376181</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow0_col2\" class=\"data row0 col2\" >0.318729</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow0_col3\" class=\"data row0 col3\" >0.308514</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow0_col4\" class=\"data row0 col4\" >0.318733</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow0_col5\" class=\"data row0 col5\" >0.38832</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow0_col6\" class=\"data row0 col6\" >1.06245</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8eclevel1_row1\" class=\"row_heading level1 row1\" >pairwise</th>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow1_col0\" class=\"data row1 col0\" >0.486504</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow1_col1\" class=\"data row1 col1\" >0.392935</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow1_col2\" class=\"data row1 col2\" >0.44455</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow1_col3\" class=\"data row1 col3\" >0.351752</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow1_col4\" class=\"data row1 col4\" >0.444555</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow1_col5\" class=\"data row1 col5\" >0.478483</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow1_col6\" class=\"data row1 col6\" >4.92195</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8eclevel1_row2\" class=\"row_heading level1 row2\" >nll</th>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow2_col0\" class=\"data row2 col0\" >0.680738</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow2_col1\" class=\"data row2 col1\" >0.621722</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow2_col2\" class=\"data row2 col2\" >0.577333</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow2_col3\" class=\"data row2 col3\" >0.518347</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow2_col4\" class=\"data row2 col4\" >0.577329</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow2_col5\" class=\"data row2 col5\" >0.679198</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow2_col6\" class=\"data row2 col6\" >0.626282</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8eclevel1_row3\" class=\"row_heading level1 row3\" >multiclass_nll</th>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow3_col0\" class=\"data row3 col0\" >0.427793</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow3_col1\" class=\"data row3 col1\" >0.440544</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow3_col2\" class=\"data row3 col2\" >0.392977</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow3_col3\" class=\"data row3 col3\" >0.350676</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow3_col4\" class=\"data row3 col4\" >0.392981</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow3_col5\" class=\"data row3 col5\" >0.474568</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow3_col6\" class=\"data row3 col6\" >7.85788</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8eclevel0_row4\" class=\"row_heading level0 row4\" rowspan=4>DistMult</th>\n",
       "                        <th id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8eclevel1_row4\" class=\"row_heading level1 row4\" >self_adversarial</th>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow4_col0\" class=\"data row4 col0\" >0.310696</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow4_col1\" class=\"data row4 col1\" >0.307953</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow4_col2\" class=\"data row4 col2\" >0.279444</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow4_col3\" class=\"data row4 col3\" >0.265872</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow4_col4\" class=\"data row4 col4\" >0.279448</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow4_col5\" class=\"data row4 col5\" >0.310797</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow4_col6\" class=\"data row4 col6\" >1.04257</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8eclevel1_row5\" class=\"row_heading level1 row5\" >pairwise</th>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow5_col0\" class=\"data row5 col0\" >0.451408</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow5_col1\" class=\"data row5 col1\" >0.398292</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow5_col2\" class=\"data row5 col2\" >0.415302</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow5_col3\" class=\"data row5 col3\" >0.356361</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow5_col4\" class=\"data row5 col4\" >0.415307</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow5_col5\" class=\"data row5 col5\" >0.450355</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow5_col6\" class=\"data row5 col6\" >1.46674</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8eclevel1_row6\" class=\"row_heading level1 row6\" >nll</th>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow6_col0\" class=\"data row6 col0\" >0.263119</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow6_col1\" class=\"data row6 col1\" >0.261522</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow6_col2\" class=\"data row6 col2\" >0.247208</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow6_col3\" class=\"data row6 col3\" >0.231766</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow6_col4\" class=\"data row6 col4\" >0.247211</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow6_col5\" class=\"data row6 col5\" >0.263137</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow6_col6\" class=\"data row6 col6\" >0.71899</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8eclevel1_row7\" class=\"row_heading level1 row7\" >multiclass_nll</th>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow7_col0\" class=\"data row7 col0\" >0.453266</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow7_col1\" class=\"data row7 col1\" >0.405863</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow7_col2\" class=\"data row7 col2\" >0.407079</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow7_col3\" class=\"data row7 col3\" >0.351802</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow7_col4\" class=\"data row7 col4\" >0.407085</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow7_col5\" class=\"data row7 col5\" >0.450874</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow7_col6\" class=\"data row7 col6\" >4.22456</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8eclevel0_row8\" class=\"row_heading level0 row8\" rowspan=4>ComplEx</th>\n",
       "                        <th id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8eclevel1_row8\" class=\"row_heading level1 row8\" >self_adversarial</th>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow8_col0\" class=\"data row8 col0\" >0.322934</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow8_col1\" class=\"data row8 col1\" >0.312896</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow8_col2\" class=\"data row8 col2\" >0.305282</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow8_col3\" class=\"data row8 col3\" >0.277734</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow8_col4\" class=\"data row8 col4\" >0.305286</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow8_col5\" class=\"data row8 col5\" >0.322939</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow8_col6\" class=\"data row8 col6\" >1.19863</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8eclevel1_row9\" class=\"row_heading level1 row9\" >pairwise</th>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow9_col0\" class=\"data row9 col0\" >0.404138</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow9_col1\" class=\"data row9 col1\" >0.368594</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow9_col2\" class=\"data row9 col2\" >0.373314</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow9_col3\" class=\"data row9 col3\" >0.329283</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow9_col4\" class=\"data row9 col4\" >0.373318</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow9_col5\" class=\"data row9 col5\" >0.404576</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow9_col6\" class=\"data row9 col6\" >1.06695</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8eclevel1_row10\" class=\"row_heading level1 row10\" >nll</th>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow10_col0\" class=\"data row10 col0\" >0.240049</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow10_col1\" class=\"data row10 col1\" >0.24166</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow10_col2\" class=\"data row10 col2\" >0.230555</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow10_col3\" class=\"data row10 col3\" >0.216739</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow10_col4\" class=\"data row10 col4\" >0.230558</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow10_col5\" class=\"data row10 col5\" >0.239992</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow10_col6\" class=\"data row10 col6\" >0.847344</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8eclevel1_row11\" class=\"row_heading level1 row11\" >multiclass_nll</th>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow11_col0\" class=\"data row11 col0\" >0.397692</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow11_col1\" class=\"data row11 col1\" >0.371894</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow11_col2\" class=\"data row11 col2\" >0.353528</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow11_col3\" class=\"data row11 col3\" >0.316719</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow11_col4\" class=\"data row11 col4\" >0.353532</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow11_col5\" class=\"data row11 col5\" >0.396375</td>\n",
       "                        <td id=\"T_b5a429d6_df6c_11e9_ae70_3f6d31a8f8ecrow11_col6\" class=\"data row11 col6\" >3.33273</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f367a643710>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll = df[(c for c in df.columns if c.startswith('log_loss'))]\n",
    "ll.columns = [c[len(\"log_loss_\"):] for c in ll.columns]\n",
    "ll.style.apply(highlight_min, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrr}\n",
      "\\toprule\n",
      "{} &     model &  scores &  probas\\_pos\\_neg &  probas\\_pos\\_neg\\_iso &  probas\\_pos &  probas\\_pos\\_iso \\\\\n",
      "\\midrule\n",
      "0 &    TransE &   0.363 &           0.095 &               0.093 &       0.106 &           0.110 \\\\\n",
      "1 &  DistMult &   0.284 &           0.081 &               0.079 &       0.093 &           0.089 \\\\\n",
      "2 &   ComplEx &   0.264 &           0.089 &               0.084 &       0.097 &           0.095 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print((bs.reset_index()\n",
    " .query(\"loss == 'self_adversarial' \")\n",
    " [['model', 'scores', 'probas_pos_neg', 'probas_pos_neg_iso', 'probas_pos', 'probas_pos_iso']]\n",
    " .reset_index(drop=True)\n",
    " .round(3)\n",
    " .to_latex()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrr}\n",
      "\\toprule\n",
      "{} &     model &  scores &  probas\\_pos\\_neg &  probas\\_pos\\_neg\\_iso &  probas\\_pos &  probas\\_pos\\_iso \\\\\n",
      "\\midrule\n",
      "0 &    TransE &   1.062 &           0.319 &               0.309 &       0.370 &           0.376 \\\\\n",
      "1 &  DistMult &   1.043 &           0.279 &               0.266 &       0.311 &           0.308 \\\\\n",
      "2 &   ComplEx &   1.199 &           0.305 &               0.278 &       0.323 &           0.313 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ll.reset_index()\n",
    " .query(\"loss == 'self_adversarial' \")\n",
    " [['model', 'scores', 'probas_pos_neg', 'probas_pos_neg_iso', 'probas_pos', 'probas_pos_iso']]\n",
    " .reset_index(drop=True)\n",
    "  .round(3)\n",
    " .to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrr}\n",
      "\\toprule\n",
      "{} &     model &  pos\\_neg &  pos\\_neg\\_iso &   pos &  pos\\_iso &  uncalib &  per\\_relation \\\\\n",
      "\\midrule\n",
      "0 &    TransE &     87.1 &         87.8 &  86.6 &     84.9 &     50.2 &          88.8 \\\\\n",
      "1 &  DistMult &     88.9 &         89.3 &  87.7 &     88.5 &     56.7 &          90.2 \\\\\n",
      "2 &   ComplEx &     87.3 &         88.2 &  86.6 &     87.2 &     61.1 &          89.4 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print((acc*100).reset_index()\n",
    " .query(\"loss == 'self_adversarial' \")\n",
    " [['model', 'pos_neg', 'pos_neg_iso', 'pos', 'pos_iso',  'uncalib', 'per_relation']]\n",
    " .reset_index(drop=True)\n",
    "  .round(1)\n",
    " .to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>hits@10</th>\n",
       "      <th>mr</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>loss</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">TransE</th>\n",
       "      <th>self_adversarial</th>\n",
       "      <td>0.319041</td>\n",
       "      <td>244.604493</td>\n",
       "      <td>0.168512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairwise</th>\n",
       "      <td>0.648666</td>\n",
       "      <td>500.205260</td>\n",
       "      <td>0.371433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nll</th>\n",
       "      <td>0.112647</td>\n",
       "      <td>1014.709742</td>\n",
       "      <td>0.063875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiclass_nll</th>\n",
       "      <td>0.588346</td>\n",
       "      <td>216.314559</td>\n",
       "      <td>0.323279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">DistMult</th>\n",
       "      <th>self_adversarial</th>\n",
       "      <td>0.619883</td>\n",
       "      <td>635.099201</td>\n",
       "      <td>0.305570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairwise</th>\n",
       "      <td>0.631116</td>\n",
       "      <td>648.168485</td>\n",
       "      <td>0.337314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nll</th>\n",
       "      <td>0.647262</td>\n",
       "      <td>744.198240</td>\n",
       "      <td>0.330295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiclass_nll</th>\n",
       "      <td>0.585268</td>\n",
       "      <td>397.900475</td>\n",
       "      <td>0.308723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">ComplEx</th>\n",
       "      <th>self_adversarial</th>\n",
       "      <td>0.752673</td>\n",
       "      <td>1074.095853</td>\n",
       "      <td>0.530927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairwise</th>\n",
       "      <td>0.729776</td>\n",
       "      <td>586.873528</td>\n",
       "      <td>0.476573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nll</th>\n",
       "      <td>0.731882</td>\n",
       "      <td>855.117021</td>\n",
       "      <td>0.493711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiclass_nll</th>\n",
       "      <td>0.747165</td>\n",
       "      <td>326.583702</td>\n",
       "      <td>0.475104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            hits@10           mr       mrr\n",
       "model    loss                                             \n",
       "TransE   self_adversarial  0.319041   244.604493  0.168512\n",
       "         pairwise          0.648666   500.205260  0.371433\n",
       "         nll               0.112647  1014.709742  0.063875\n",
       "         multiclass_nll    0.588346   216.314559  0.323279\n",
       "DistMult self_adversarial  0.619883   635.099201  0.305570\n",
       "         pairwise          0.631116   648.168485  0.337314\n",
       "         nll               0.647262   744.198240  0.330295\n",
       "         multiclass_nll    0.585268   397.900475  0.308723\n",
       "ComplEx  self_adversarial  0.752673  1074.095853  0.530927\n",
       "         pairwise          0.729776   586.873528  0.476573\n",
       "         nll               0.731882   855.117021  0.493711\n",
       "         multiclass_nll    0.747165   326.583702  0.475104"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = df[(c for c in df.columns if c.startswith('metrics'))]\n",
    "metrics.columns = [c[len(\"metrics_\"):] for c in metrics.columns]\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow0_col0 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow1_col0 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow2_col0 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow3_col0 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow4_col0 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow5_col0 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow6_col0 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow7_col0 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow8_col0 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow9_col0 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow10_col0 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow11_col0 {\n",
       "            font-weight:  bold;\n",
       "        }</style><table id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ec\" ><thead>    <tr>        <th class=\"blank\" ></th>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >per_relation</th>        <th class=\"col_heading level0 col1\" >pos</th>        <th class=\"col_heading level0 col2\" >pos_iso</th>        <th class=\"col_heading level0 col3\" >pos_neg</th>        <th class=\"col_heading level0 col4\" >pos_neg_iso</th>        <th class=\"col_heading level0 col5\" >pos_neg_sc</th>        <th class=\"col_heading level0 col6\" >pos_sc</th>        <th class=\"col_heading level0 col7\" >uncalib</th>    </tr>    <tr>        <th class=\"index_name level0\" >model</th>        <th class=\"index_name level1\" >loss</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8eclevel0_row0\" class=\"row_heading level0 row0\" rowspan=4>TransE</th>\n",
       "                        <th id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8eclevel1_row0\" class=\"row_heading level1 row0\" >self_adversarial</th>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow0_col0\" class=\"data row0 col0\" >0.887581</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow0_col1\" class=\"data row0 col1\" >0.865591</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow0_col2\" class=\"data row0 col2\" >0.84914</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow0_col3\" class=\"data row0 col3\" >0.871344</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow0_col4\" class=\"data row0 col4\" >0.877796</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow0_col5\" class=\"data row0 col5\" >0.871505</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow0_col6\" class=\"data row0 col6\" >0.864892</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow0_col7\" class=\"data row0 col7\" >0.502204</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8eclevel1_row1\" class=\"row_heading level1 row1\" >pairwise</th>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow1_col0\" class=\"data row1 col0\" >0.898226</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow1_col1\" class=\"data row1 col1\" >0.822796</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow1_col2\" class=\"data row1 col2\" >0.865968</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow1_col3\" class=\"data row1 col3\" >0.862796</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow1_col4\" class=\"data row1 col4\" >0.871398</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow1_col5\" class=\"data row1 col5\" >0.862688</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow1_col6\" class=\"data row1 col6\" >0.823226</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow1_col7\" class=\"data row1 col7\" >0.502204</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8eclevel1_row2\" class=\"row_heading level1 row2\" >nll</th>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow2_col0\" class=\"data row2 col0\" >0.779624</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow2_col1\" class=\"data row2 col1\" >0.665538</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow2_col2\" class=\"data row2 col2\" >0.749301</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow2_col3\" class=\"data row2 col3\" >0.714409</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow2_col4\" class=\"data row2 col4\" >0.759624</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow2_col5\" class=\"data row2 col5\" >0.713333</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow2_col6\" class=\"data row2 col6\" >0.668602</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow2_col7\" class=\"data row2 col7\" >0.502204</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8eclevel1_row3\" class=\"row_heading level1 row3\" >multiclass_nll</th>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow3_col0\" class=\"data row3 col0\" >0.909731</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow3_col1\" class=\"data row3 col1\" >0.843441</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow3_col2\" class=\"data row3 col2\" >0.857742</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow3_col3\" class=\"data row3 col3\" >0.866505</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow3_col4\" class=\"data row3 col4\" >0.86957</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow3_col5\" class=\"data row3 col5\" >0.866505</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow3_col6\" class=\"data row3 col6\" >0.842688</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow3_col7\" class=\"data row3 col7\" >0.502204</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8eclevel0_row4\" class=\"row_heading level0 row4\" rowspan=4>DistMult</th>\n",
       "                        <th id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8eclevel1_row4\" class=\"row_heading level1 row4\" >self_adversarial</th>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow4_col0\" class=\"data row4 col0\" >0.901882</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow4_col1\" class=\"data row4 col1\" >0.877204</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow4_col2\" class=\"data row4 col2\" >0.885376</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow4_col3\" class=\"data row4 col3\" >0.889194</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow4_col4\" class=\"data row4 col4\" >0.893118</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow4_col5\" class=\"data row4 col5\" >0.889032</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow4_col6\" class=\"data row4 col6\" >0.877151</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow4_col7\" class=\"data row4 col7\" >0.567151</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8eclevel1_row5\" class=\"row_heading level1 row5\" >pairwise</th>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow5_col0\" class=\"data row5 col0\" >0.901774</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow5_col1\" class=\"data row5 col1\" >0.782258</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow5_col2\" class=\"data row5 col2\" >0.766022</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow5_col3\" class=\"data row5 col3\" >0.818226</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow5_col4\" class=\"data row5 col4\" >0.842097</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow5_col5\" class=\"data row5 col5\" >0.817742</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow5_col6\" class=\"data row5 col6\" >0.782634</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow5_col7\" class=\"data row5 col7\" >0.540806</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8eclevel1_row6\" class=\"row_heading level1 row6\" >nll</th>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow6_col0\" class=\"data row6 col0\" >0.915269</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow6_col1\" class=\"data row6 col1\" >0.897151</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow6_col2\" class=\"data row6 col2\" >0.901882</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow6_col3\" class=\"data row6 col3\" >0.903817</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow6_col4\" class=\"data row6 col4\" >0.904462</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow6_col5\" class=\"data row6 col5\" >0.904032</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow6_col6\" class=\"data row6 col6\" >0.897043</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow6_col7\" class=\"data row6 col7\" >0.883763</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8eclevel1_row7\" class=\"row_heading level1 row7\" >multiclass_nll</th>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow7_col0\" class=\"data row7 col0\" >0.909247</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow7_col1\" class=\"data row7 col1\" >0.78172</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow7_col2\" class=\"data row7 col2\" >0.786882</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow7_col3\" class=\"data row7 col3\" >0.817312</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow7_col4\" class=\"data row7 col4\" >0.843925</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow7_col5\" class=\"data row7 col5\" >0.817419</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow7_col6\" class=\"data row7 col6\" >0.78328</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow7_col7\" class=\"data row7 col7\" >0.522688</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8eclevel0_row8\" class=\"row_heading level0 row8\" rowspan=4>ComplEx</th>\n",
       "                        <th id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8eclevel1_row8\" class=\"row_heading level1 row8\" >self_adversarial</th>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow8_col0\" class=\"data row8 col0\" >0.893817</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow8_col1\" class=\"data row8 col1\" >0.866452</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow8_col2\" class=\"data row8 col2\" >0.871559</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow8_col3\" class=\"data row8 col3\" >0.872903</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow8_col4\" class=\"data row8 col4\" >0.881828</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow8_col5\" class=\"data row8 col5\" >0.872849</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow8_col6\" class=\"data row8 col6\" >0.866452</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow8_col7\" class=\"data row8 col7\" >0.610806</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8eclevel1_row9\" class=\"row_heading level1 row9\" >pairwise</th>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow9_col0\" class=\"data row9 col0\" >0.902527</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow9_col1\" class=\"data row9 col1\" >0.816774</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow9_col2\" class=\"data row9 col2\" >0.803387</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow9_col3\" class=\"data row9 col3\" >0.843495</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow9_col4\" class=\"data row9 col4\" >0.852796</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow9_col5\" class=\"data row9 col5\" >0.843441</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow9_col6\" class=\"data row9 col6\" >0.81672</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow9_col7\" class=\"data row9 col7\" >0.560645</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8eclevel1_row10\" class=\"row_heading level1 row10\" >nll</th>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow10_col0\" class=\"data row10 col0\" >0.914462</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow10_col1\" class=\"data row10 col1\" >0.900269</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow10_col2\" class=\"data row10 col2\" >0.903656</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow10_col3\" class=\"data row10 col3\" >0.903387</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow10_col4\" class=\"data row10 col4\" >0.905968</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow10_col5\" class=\"data row10 col5\" >0.903333</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow10_col6\" class=\"data row10 col6\" >0.900323</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow10_col7\" class=\"data row10 col7\" >0.873978</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8eclevel1_row11\" class=\"row_heading level1 row11\" >multiclass_nll</th>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow11_col0\" class=\"data row11 col0\" >0.913602</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow11_col1\" class=\"data row11 col1\" >0.818226</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow11_col2\" class=\"data row11 col2\" >0.822688</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow11_col3\" class=\"data row11 col3\" >0.853602</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow11_col4\" class=\"data row11 col4\" >0.857204</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow11_col5\" class=\"data row11 col5\" >0.853172</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow11_col6\" class=\"data row11 col6\" >0.818548</td>\n",
       "                        <td id=\"T_b6f5161a_df6c_11e9_ae70_3f6d31a8f8ecrow11_col7\" class=\"data row11 col7\" >0.541075</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f3a9d0beb38>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def highlight_max(s):\n",
    "    is_min = s == s.max()\n",
    "    return ['font-weight: bold' if v else '' for v in is_min]\n",
    "\n",
    "acc = df[(c for c in df.columns if c.startswith('accuracy'))]\n",
    "acc.columns = [c[len(\"accuracy_\"):] for c in acc.columns]\n",
    "acc.style.apply(highlight_max, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_per_relation</th>\n",
       "      <th>accuracy_pos</th>\n",
       "      <th>accuracy_pos_iso</th>\n",
       "      <th>accuracy_pos_neg</th>\n",
       "      <th>accuracy_pos_neg_iso</th>\n",
       "      <th>accuracy_pos_neg_sc</th>\n",
       "      <th>accuracy_pos_sc</th>\n",
       "      <th>accuracy_uncalib</th>\n",
       "      <th>brier_score_probas_pos</th>\n",
       "      <th>brier_score_probas_pos_iso</th>\n",
       "      <th>...</th>\n",
       "      <th>log_loss_probas_pos</th>\n",
       "      <th>log_loss_probas_pos_iso</th>\n",
       "      <th>log_loss_probas_pos_neg</th>\n",
       "      <th>log_loss_probas_pos_neg_iso</th>\n",
       "      <th>log_loss_probas_pos_neg_sc</th>\n",
       "      <th>log_loss_probas_pos_sc</th>\n",
       "      <th>log_loss_scores</th>\n",
       "      <th>metrics_hits@10</th>\n",
       "      <th>metrics_mr</th>\n",
       "      <th>metrics_mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy_per_relation</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.398601</td>\n",
       "      <td>0.447552</td>\n",
       "      <td>0.405594</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.405594</td>\n",
       "      <td>0.419580</td>\n",
       "      <td>0.555248</td>\n",
       "      <td>-0.496503</td>\n",
       "      <td>-0.342657</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.489510</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>-0.510490</td>\n",
       "      <td>-0.475524</td>\n",
       "      <td>-0.510490</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.370629</td>\n",
       "      <td>-0.160839</td>\n",
       "      <td>0.342657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_pos</th>\n",
       "      <td>0.398601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>0.986014</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>0.619315</td>\n",
       "      <td>-0.930070</td>\n",
       "      <td>-0.986014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.895105</td>\n",
       "      <td>-0.818182</td>\n",
       "      <td>-0.888112</td>\n",
       "      <td>-0.937063</td>\n",
       "      <td>-0.888112</td>\n",
       "      <td>-0.832168</td>\n",
       "      <td>-0.293706</td>\n",
       "      <td>0.391608</td>\n",
       "      <td>0.174825</td>\n",
       "      <td>0.300699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_pos_iso</th>\n",
       "      <td>0.447552</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.612197</td>\n",
       "      <td>-0.839161</td>\n",
       "      <td>-0.965035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.804196</td>\n",
       "      <td>-0.797203</td>\n",
       "      <td>-0.811189</td>\n",
       "      <td>-0.888112</td>\n",
       "      <td>-0.811189</td>\n",
       "      <td>-0.741259</td>\n",
       "      <td>-0.195804</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.188811</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_pos_neg</th>\n",
       "      <td>0.405594</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986014</td>\n",
       "      <td>0.626434</td>\n",
       "      <td>-0.923077</td>\n",
       "      <td>-0.979021</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.888112</td>\n",
       "      <td>-0.811189</td>\n",
       "      <td>-0.881119</td>\n",
       "      <td>-0.930070</td>\n",
       "      <td>-0.881119</td>\n",
       "      <td>-0.825175</td>\n",
       "      <td>-0.300699</td>\n",
       "      <td>0.370629</td>\n",
       "      <td>0.167832</td>\n",
       "      <td>0.265734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_pos_neg_iso</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.986014</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>0.612197</td>\n",
       "      <td>-0.888112</td>\n",
       "      <td>-0.986014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.867133</td>\n",
       "      <td>-0.832168</td>\n",
       "      <td>-0.874126</td>\n",
       "      <td>-0.937063</td>\n",
       "      <td>-0.874126</td>\n",
       "      <td>-0.818182</td>\n",
       "      <td>-0.286713</td>\n",
       "      <td>0.398601</td>\n",
       "      <td>0.174825</td>\n",
       "      <td>0.300699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_pos_neg_sc</th>\n",
       "      <td>0.405594</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986014</td>\n",
       "      <td>0.626434</td>\n",
       "      <td>-0.923077</td>\n",
       "      <td>-0.979021</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.888112</td>\n",
       "      <td>-0.811189</td>\n",
       "      <td>-0.881119</td>\n",
       "      <td>-0.930070</td>\n",
       "      <td>-0.881119</td>\n",
       "      <td>-0.825175</td>\n",
       "      <td>-0.300699</td>\n",
       "      <td>0.370629</td>\n",
       "      <td>0.167832</td>\n",
       "      <td>0.265734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_pos_sc</th>\n",
       "      <td>0.419580</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.986014</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>0.986014</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612197</td>\n",
       "      <td>-0.923077</td>\n",
       "      <td>-0.979021</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.888112</td>\n",
       "      <td>-0.811189</td>\n",
       "      <td>-0.895105</td>\n",
       "      <td>-0.944056</td>\n",
       "      <td>-0.895105</td>\n",
       "      <td>-0.825175</td>\n",
       "      <td>-0.279720</td>\n",
       "      <td>0.370629</td>\n",
       "      <td>0.146853</td>\n",
       "      <td>0.279720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_uncalib</th>\n",
       "      <td>0.555248</td>\n",
       "      <td>0.619315</td>\n",
       "      <td>0.612197</td>\n",
       "      <td>0.626434</td>\n",
       "      <td>0.612197</td>\n",
       "      <td>0.626434</td>\n",
       "      <td>0.612197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.733212</td>\n",
       "      <td>-0.626434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.804398</td>\n",
       "      <td>-0.882702</td>\n",
       "      <td>-0.797279</td>\n",
       "      <td>-0.754568</td>\n",
       "      <td>-0.797279</td>\n",
       "      <td>-0.847109</td>\n",
       "      <td>-0.444910</td>\n",
       "      <td>0.637112</td>\n",
       "      <td>0.558807</td>\n",
       "      <td>0.555248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brier_score_probas_pos</th>\n",
       "      <td>-0.496503</td>\n",
       "      <td>-0.930070</td>\n",
       "      <td>-0.839161</td>\n",
       "      <td>-0.923077</td>\n",
       "      <td>-0.888112</td>\n",
       "      <td>-0.923077</td>\n",
       "      <td>-0.923077</td>\n",
       "      <td>-0.733212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.930070</td>\n",
       "      <td>0.370629</td>\n",
       "      <td>-0.370629</td>\n",
       "      <td>-0.181818</td>\n",
       "      <td>-0.286713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brier_score_probas_pos_iso</th>\n",
       "      <td>-0.342657</td>\n",
       "      <td>-0.986014</td>\n",
       "      <td>-0.965035</td>\n",
       "      <td>-0.979021</td>\n",
       "      <td>-0.986014</td>\n",
       "      <td>-0.979021</td>\n",
       "      <td>-0.979021</td>\n",
       "      <td>-0.626434</td>\n",
       "      <td>0.888112</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867133</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.860140</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.860140</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.321678</td>\n",
       "      <td>-0.405594</td>\n",
       "      <td>-0.223776</td>\n",
       "      <td>-0.328671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brier_score_probas_pos_neg</th>\n",
       "      <td>-0.489510</td>\n",
       "      <td>-0.958042</td>\n",
       "      <td>-0.909091</td>\n",
       "      <td>-0.951049</td>\n",
       "      <td>-0.951049</td>\n",
       "      <td>-0.951049</td>\n",
       "      <td>-0.965035</td>\n",
       "      <td>-0.715416</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.930070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.881119</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.916084</td>\n",
       "      <td>0.349650</td>\n",
       "      <td>-0.447552</td>\n",
       "      <td>-0.153846</td>\n",
       "      <td>-0.328671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brier_score_probas_pos_neg_iso</th>\n",
       "      <td>-0.433566</td>\n",
       "      <td>-0.965035</td>\n",
       "      <td>-0.944056</td>\n",
       "      <td>-0.958042</td>\n",
       "      <td>-0.979021</td>\n",
       "      <td>-0.958042</td>\n",
       "      <td>-0.972028</td>\n",
       "      <td>-0.676264</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916084</td>\n",
       "      <td>0.881119</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.881119</td>\n",
       "      <td>0.321678</td>\n",
       "      <td>-0.468531</td>\n",
       "      <td>-0.174825</td>\n",
       "      <td>-0.335664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brier_score_probas_pos_neg_sc</th>\n",
       "      <td>-0.489510</td>\n",
       "      <td>-0.958042</td>\n",
       "      <td>-0.909091</td>\n",
       "      <td>-0.951049</td>\n",
       "      <td>-0.951049</td>\n",
       "      <td>-0.951049</td>\n",
       "      <td>-0.965035</td>\n",
       "      <td>-0.715416</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.930070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.881119</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.916084</td>\n",
       "      <td>0.349650</td>\n",
       "      <td>-0.447552</td>\n",
       "      <td>-0.153846</td>\n",
       "      <td>-0.328671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brier_score_probas_pos_sc</th>\n",
       "      <td>-0.461538</td>\n",
       "      <td>-0.979021</td>\n",
       "      <td>-0.916084</td>\n",
       "      <td>-0.972028</td>\n",
       "      <td>-0.951049</td>\n",
       "      <td>-0.972028</td>\n",
       "      <td>-0.972028</td>\n",
       "      <td>-0.690501</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.853147</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.895105</td>\n",
       "      <td>0.342657</td>\n",
       "      <td>-0.419580</td>\n",
       "      <td>-0.167832</td>\n",
       "      <td>-0.321678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brier_score_scores</th>\n",
       "      <td>-0.069930</td>\n",
       "      <td>-0.447552</td>\n",
       "      <td>-0.377622</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>-0.440559</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>-0.433566</td>\n",
       "      <td>-0.686941</td>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.475524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.622378</td>\n",
       "      <td>0.573427</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.573427</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.930070</td>\n",
       "      <td>-0.160839</td>\n",
       "      <td>-0.797203</td>\n",
       "      <td>-0.097902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_loss_probas_pos</th>\n",
       "      <td>-0.489510</td>\n",
       "      <td>-0.895105</td>\n",
       "      <td>-0.804196</td>\n",
       "      <td>-0.888112</td>\n",
       "      <td>-0.867133</td>\n",
       "      <td>-0.888112</td>\n",
       "      <td>-0.888112</td>\n",
       "      <td>-0.804398</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.867133</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.433566</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>-0.230769</td>\n",
       "      <td>-0.349650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_loss_probas_pos_iso</th>\n",
       "      <td>-0.454545</td>\n",
       "      <td>-0.818182</td>\n",
       "      <td>-0.797203</td>\n",
       "      <td>-0.811189</td>\n",
       "      <td>-0.832168</td>\n",
       "      <td>-0.811189</td>\n",
       "      <td>-0.811189</td>\n",
       "      <td>-0.882702</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.902098</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.902098</td>\n",
       "      <td>0.930070</td>\n",
       "      <td>0.440559</td>\n",
       "      <td>-0.636364</td>\n",
       "      <td>-0.370629</td>\n",
       "      <td>-0.524476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_loss_probas_pos_neg</th>\n",
       "      <td>-0.510490</td>\n",
       "      <td>-0.888112</td>\n",
       "      <td>-0.811189</td>\n",
       "      <td>-0.881119</td>\n",
       "      <td>-0.874126</td>\n",
       "      <td>-0.881119</td>\n",
       "      <td>-0.895105</td>\n",
       "      <td>-0.797279</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.860140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>0.902098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.419580</td>\n",
       "      <td>-0.433566</td>\n",
       "      <td>-0.202797</td>\n",
       "      <td>-0.328671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_loss_probas_pos_neg_iso</th>\n",
       "      <td>-0.475524</td>\n",
       "      <td>-0.937063</td>\n",
       "      <td>-0.888112</td>\n",
       "      <td>-0.930070</td>\n",
       "      <td>-0.937063</td>\n",
       "      <td>-0.930070</td>\n",
       "      <td>-0.944056</td>\n",
       "      <td>-0.754568</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.391608</td>\n",
       "      <td>-0.482517</td>\n",
       "      <td>-0.188811</td>\n",
       "      <td>-0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_loss_probas_pos_neg_sc</th>\n",
       "      <td>-0.510490</td>\n",
       "      <td>-0.888112</td>\n",
       "      <td>-0.811189</td>\n",
       "      <td>-0.881119</td>\n",
       "      <td>-0.874126</td>\n",
       "      <td>-0.881119</td>\n",
       "      <td>-0.895105</td>\n",
       "      <td>-0.797279</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.860140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>0.902098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.419580</td>\n",
       "      <td>-0.433566</td>\n",
       "      <td>-0.202797</td>\n",
       "      <td>-0.328671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_loss_probas_pos_sc</th>\n",
       "      <td>-0.454545</td>\n",
       "      <td>-0.832168</td>\n",
       "      <td>-0.741259</td>\n",
       "      <td>-0.825175</td>\n",
       "      <td>-0.818182</td>\n",
       "      <td>-0.825175</td>\n",
       "      <td>-0.825175</td>\n",
       "      <td>-0.847109</td>\n",
       "      <td>0.930070</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.930070</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.475524</td>\n",
       "      <td>-0.461538</td>\n",
       "      <td>-0.300699</td>\n",
       "      <td>-0.356643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_loss_scores</th>\n",
       "      <td>0.069930</td>\n",
       "      <td>-0.293706</td>\n",
       "      <td>-0.195804</td>\n",
       "      <td>-0.300699</td>\n",
       "      <td>-0.286713</td>\n",
       "      <td>-0.300699</td>\n",
       "      <td>-0.279720</td>\n",
       "      <td>-0.444910</td>\n",
       "      <td>0.370629</td>\n",
       "      <td>0.321678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.433566</td>\n",
       "      <td>0.440559</td>\n",
       "      <td>0.419580</td>\n",
       "      <td>0.391608</td>\n",
       "      <td>0.419580</td>\n",
       "      <td>0.475524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.132867</td>\n",
       "      <td>-0.643357</td>\n",
       "      <td>0.209790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metrics_hits@10</th>\n",
       "      <td>0.370629</td>\n",
       "      <td>0.391608</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.370629</td>\n",
       "      <td>0.398601</td>\n",
       "      <td>0.370629</td>\n",
       "      <td>0.370629</td>\n",
       "      <td>0.637112</td>\n",
       "      <td>-0.370629</td>\n",
       "      <td>-0.405594</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>-0.636364</td>\n",
       "      <td>-0.433566</td>\n",
       "      <td>-0.482517</td>\n",
       "      <td>-0.433566</td>\n",
       "      <td>-0.461538</td>\n",
       "      <td>0.132867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.286713</td>\n",
       "      <td>0.951049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metrics_mr</th>\n",
       "      <td>-0.160839</td>\n",
       "      <td>0.174825</td>\n",
       "      <td>0.188811</td>\n",
       "      <td>0.167832</td>\n",
       "      <td>0.174825</td>\n",
       "      <td>0.167832</td>\n",
       "      <td>0.146853</td>\n",
       "      <td>0.558807</td>\n",
       "      <td>-0.181818</td>\n",
       "      <td>-0.223776</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230769</td>\n",
       "      <td>-0.370629</td>\n",
       "      <td>-0.202797</td>\n",
       "      <td>-0.188811</td>\n",
       "      <td>-0.202797</td>\n",
       "      <td>-0.300699</td>\n",
       "      <td>-0.643357</td>\n",
       "      <td>0.286713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.286713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metrics_mrr</th>\n",
       "      <td>0.342657</td>\n",
       "      <td>0.300699</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.265734</td>\n",
       "      <td>0.300699</td>\n",
       "      <td>0.265734</td>\n",
       "      <td>0.279720</td>\n",
       "      <td>0.555248</td>\n",
       "      <td>-0.286713</td>\n",
       "      <td>-0.328671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.349650</td>\n",
       "      <td>-0.524476</td>\n",
       "      <td>-0.328671</td>\n",
       "      <td>-0.363636</td>\n",
       "      <td>-0.328671</td>\n",
       "      <td>-0.356643</td>\n",
       "      <td>0.209790</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.286713</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                accuracy_per_relation  accuracy_pos  \\\n",
       "accuracy_per_relation                        1.000000      0.398601   \n",
       "accuracy_pos                                 0.398601      1.000000   \n",
       "accuracy_pos_iso                             0.447552      0.965035   \n",
       "accuracy_pos_neg                             0.405594      0.993007   \n",
       "accuracy_pos_neg_iso                         0.384615      0.986014   \n",
       "accuracy_pos_neg_sc                          0.405594      0.993007   \n",
       "accuracy_pos_sc                              0.419580      0.993007   \n",
       "accuracy_uncalib                             0.555248      0.619315   \n",
       "brier_score_probas_pos                      -0.496503     -0.930070   \n",
       "brier_score_probas_pos_iso                  -0.342657     -0.986014   \n",
       "brier_score_probas_pos_neg                  -0.489510     -0.958042   \n",
       "brier_score_probas_pos_neg_iso              -0.433566     -0.965035   \n",
       "brier_score_probas_pos_neg_sc               -0.489510     -0.958042   \n",
       "brier_score_probas_pos_sc                   -0.461538     -0.979021   \n",
       "brier_score_scores                          -0.069930     -0.447552   \n",
       "log_loss_probas_pos                         -0.489510     -0.895105   \n",
       "log_loss_probas_pos_iso                     -0.454545     -0.818182   \n",
       "log_loss_probas_pos_neg                     -0.510490     -0.888112   \n",
       "log_loss_probas_pos_neg_iso                 -0.475524     -0.937063   \n",
       "log_loss_probas_pos_neg_sc                  -0.510490     -0.888112   \n",
       "log_loss_probas_pos_sc                      -0.454545     -0.832168   \n",
       "log_loss_scores                              0.069930     -0.293706   \n",
       "metrics_hits@10                              0.370629      0.391608   \n",
       "metrics_mr                                  -0.160839      0.174825   \n",
       "metrics_mrr                                  0.342657      0.300699   \n",
       "\n",
       "                                accuracy_pos_iso  accuracy_pos_neg  \\\n",
       "accuracy_per_relation                   0.447552          0.405594   \n",
       "accuracy_pos                            0.965035          0.993007   \n",
       "accuracy_pos_iso                        1.000000          0.958042   \n",
       "accuracy_pos_neg                        0.958042          1.000000   \n",
       "accuracy_pos_neg_iso                    0.979021          0.979021   \n",
       "accuracy_pos_neg_sc                     0.958042          1.000000   \n",
       "accuracy_pos_sc                         0.972028          0.986014   \n",
       "accuracy_uncalib                        0.612197          0.626434   \n",
       "brier_score_probas_pos                 -0.839161         -0.923077   \n",
       "brier_score_probas_pos_iso             -0.965035         -0.979021   \n",
       "brier_score_probas_pos_neg             -0.909091         -0.951049   \n",
       "brier_score_probas_pos_neg_iso         -0.944056         -0.958042   \n",
       "brier_score_probas_pos_neg_sc          -0.909091         -0.951049   \n",
       "brier_score_probas_pos_sc              -0.916084         -0.972028   \n",
       "brier_score_scores                     -0.377622         -0.454545   \n",
       "log_loss_probas_pos                    -0.804196         -0.888112   \n",
       "log_loss_probas_pos_iso                -0.797203         -0.811189   \n",
       "log_loss_probas_pos_neg                -0.811189         -0.881119   \n",
       "log_loss_probas_pos_neg_iso            -0.888112         -0.930070   \n",
       "log_loss_probas_pos_neg_sc             -0.811189         -0.881119   \n",
       "log_loss_probas_pos_sc                 -0.741259         -0.825175   \n",
       "log_loss_scores                        -0.195804         -0.300699   \n",
       "metrics_hits@10                         0.454545          0.370629   \n",
       "metrics_mr                              0.188811          0.167832   \n",
       "metrics_mrr                             0.363636          0.265734   \n",
       "\n",
       "                                accuracy_pos_neg_iso  accuracy_pos_neg_sc  \\\n",
       "accuracy_per_relation                       0.384615             0.405594   \n",
       "accuracy_pos                                0.986014             0.993007   \n",
       "accuracy_pos_iso                            0.979021             0.958042   \n",
       "accuracy_pos_neg                            0.979021             1.000000   \n",
       "accuracy_pos_neg_iso                        1.000000             0.979021   \n",
       "accuracy_pos_neg_sc                         0.979021             1.000000   \n",
       "accuracy_pos_sc                             0.993007             0.986014   \n",
       "accuracy_uncalib                            0.612197             0.626434   \n",
       "brier_score_probas_pos                     -0.888112            -0.923077   \n",
       "brier_score_probas_pos_iso                 -0.986014            -0.979021   \n",
       "brier_score_probas_pos_neg                 -0.951049            -0.951049   \n",
       "brier_score_probas_pos_neg_iso             -0.979021            -0.958042   \n",
       "brier_score_probas_pos_neg_sc              -0.951049            -0.951049   \n",
       "brier_score_probas_pos_sc                  -0.951049            -0.972028   \n",
       "brier_score_scores                         -0.440559            -0.454545   \n",
       "log_loss_probas_pos                        -0.867133            -0.888112   \n",
       "log_loss_probas_pos_iso                    -0.832168            -0.811189   \n",
       "log_loss_probas_pos_neg                    -0.874126            -0.881119   \n",
       "log_loss_probas_pos_neg_iso                -0.937063            -0.930070   \n",
       "log_loss_probas_pos_neg_sc                 -0.874126            -0.881119   \n",
       "log_loss_probas_pos_sc                     -0.818182            -0.825175   \n",
       "log_loss_scores                            -0.286713            -0.300699   \n",
       "metrics_hits@10                             0.398601             0.370629   \n",
       "metrics_mr                                  0.174825             0.167832   \n",
       "metrics_mrr                                 0.300699             0.265734   \n",
       "\n",
       "                                accuracy_pos_sc  accuracy_uncalib  \\\n",
       "accuracy_per_relation                  0.419580          0.555248   \n",
       "accuracy_pos                           0.993007          0.619315   \n",
       "accuracy_pos_iso                       0.972028          0.612197   \n",
       "accuracy_pos_neg                       0.986014          0.626434   \n",
       "accuracy_pos_neg_iso                   0.993007          0.612197   \n",
       "accuracy_pos_neg_sc                    0.986014          0.626434   \n",
       "accuracy_pos_sc                        1.000000          0.612197   \n",
       "accuracy_uncalib                       0.612197          1.000000   \n",
       "brier_score_probas_pos                -0.923077         -0.733212   \n",
       "brier_score_probas_pos_iso            -0.979021         -0.626434   \n",
       "brier_score_probas_pos_neg            -0.965035         -0.715416   \n",
       "brier_score_probas_pos_neg_iso        -0.972028         -0.676264   \n",
       "brier_score_probas_pos_neg_sc         -0.965035         -0.715416   \n",
       "brier_score_probas_pos_sc             -0.972028         -0.690501   \n",
       "brier_score_scores                    -0.433566         -0.686941   \n",
       "log_loss_probas_pos                   -0.888112         -0.804398   \n",
       "log_loss_probas_pos_iso               -0.811189         -0.882702   \n",
       "log_loss_probas_pos_neg               -0.895105         -0.797279   \n",
       "log_loss_probas_pos_neg_iso           -0.944056         -0.754568   \n",
       "log_loss_probas_pos_neg_sc            -0.895105         -0.797279   \n",
       "log_loss_probas_pos_sc                -0.825175         -0.847109   \n",
       "log_loss_scores                       -0.279720         -0.444910   \n",
       "metrics_hits@10                        0.370629          0.637112   \n",
       "metrics_mr                             0.146853          0.558807   \n",
       "metrics_mrr                            0.279720          0.555248   \n",
       "\n",
       "                                brier_score_probas_pos  \\\n",
       "accuracy_per_relation                        -0.496503   \n",
       "accuracy_pos                                 -0.930070   \n",
       "accuracy_pos_iso                             -0.839161   \n",
       "accuracy_pos_neg                             -0.923077   \n",
       "accuracy_pos_neg_iso                         -0.888112   \n",
       "accuracy_pos_neg_sc                          -0.923077   \n",
       "accuracy_pos_sc                              -0.923077   \n",
       "accuracy_uncalib                             -0.733212   \n",
       "brier_score_probas_pos                        1.000000   \n",
       "brier_score_probas_pos_iso                    0.888112   \n",
       "brier_score_probas_pos_neg                    0.965035   \n",
       "brier_score_probas_pos_neg_iso                0.909091   \n",
       "brier_score_probas_pos_neg_sc                 0.965035   \n",
       "brier_score_probas_pos_sc                     0.979021   \n",
       "brier_score_scores                            0.524476   \n",
       "log_loss_probas_pos                           0.979021   \n",
       "log_loss_probas_pos_iso                       0.832168   \n",
       "log_loss_probas_pos_neg                       0.972028   \n",
       "log_loss_probas_pos_neg_iso                   0.951049   \n",
       "log_loss_probas_pos_neg_sc                    0.972028   \n",
       "log_loss_probas_pos_sc                        0.930070   \n",
       "log_loss_scores                               0.370629   \n",
       "metrics_hits@10                              -0.370629   \n",
       "metrics_mr                                   -0.181818   \n",
       "metrics_mrr                                  -0.286713   \n",
       "\n",
       "                                brier_score_probas_pos_iso  ...  \\\n",
       "accuracy_per_relation                            -0.342657  ...   \n",
       "accuracy_pos                                     -0.986014  ...   \n",
       "accuracy_pos_iso                                 -0.965035  ...   \n",
       "accuracy_pos_neg                                 -0.979021  ...   \n",
       "accuracy_pos_neg_iso                             -0.986014  ...   \n",
       "accuracy_pos_neg_sc                              -0.979021  ...   \n",
       "accuracy_pos_sc                                  -0.979021  ...   \n",
       "accuracy_uncalib                                 -0.626434  ...   \n",
       "brier_score_probas_pos                            0.888112  ...   \n",
       "brier_score_probas_pos_iso                        1.000000  ...   \n",
       "brier_score_probas_pos_neg                        0.930070  ...   \n",
       "brier_score_probas_pos_neg_iso                    0.951049  ...   \n",
       "brier_score_probas_pos_neg_sc                     0.930070  ...   \n",
       "brier_score_probas_pos_sc                         0.951049  ...   \n",
       "brier_score_scores                                0.475524  ...   \n",
       "log_loss_probas_pos                               0.867133  ...   \n",
       "log_loss_probas_pos_iso                           0.846154  ...   \n",
       "log_loss_probas_pos_neg                           0.860140  ...   \n",
       "log_loss_probas_pos_neg_iso                       0.923077  ...   \n",
       "log_loss_probas_pos_neg_sc                        0.860140  ...   \n",
       "log_loss_probas_pos_sc                            0.818182  ...   \n",
       "log_loss_scores                                   0.321678  ...   \n",
       "metrics_hits@10                                  -0.405594  ...   \n",
       "metrics_mr                                       -0.223776  ...   \n",
       "metrics_mrr                                      -0.328671  ...   \n",
       "\n",
       "                                log_loss_probas_pos  log_loss_probas_pos_iso  \\\n",
       "accuracy_per_relation                     -0.489510                -0.454545   \n",
       "accuracy_pos                              -0.895105                -0.818182   \n",
       "accuracy_pos_iso                          -0.804196                -0.797203   \n",
       "accuracy_pos_neg                          -0.888112                -0.811189   \n",
       "accuracy_pos_neg_iso                      -0.867133                -0.832168   \n",
       "accuracy_pos_neg_sc                       -0.888112                -0.811189   \n",
       "accuracy_pos_sc                           -0.888112                -0.811189   \n",
       "accuracy_uncalib                          -0.804398                -0.882702   \n",
       "brier_score_probas_pos                     0.979021                 0.832168   \n",
       "brier_score_probas_pos_iso                 0.867133                 0.846154   \n",
       "brier_score_probas_pos_neg                 0.965035                 0.881119   \n",
       "brier_score_probas_pos_neg_iso             0.916084                 0.881119   \n",
       "brier_score_probas_pos_neg_sc              0.965035                 0.881119   \n",
       "brier_score_probas_pos_sc                  0.958042                 0.853147   \n",
       "brier_score_scores                         0.587413                 0.622378   \n",
       "log_loss_probas_pos                        1.000000                 0.909091   \n",
       "log_loss_probas_pos_iso                    0.909091                 1.000000   \n",
       "log_loss_probas_pos_neg                    0.993007                 0.902098   \n",
       "log_loss_probas_pos_neg_iso                0.972028                 0.923077   \n",
       "log_loss_probas_pos_neg_sc                 0.993007                 0.902098   \n",
       "log_loss_probas_pos_sc                     0.979021                 0.930070   \n",
       "log_loss_scores                            0.433566                 0.440559   \n",
       "metrics_hits@10                           -0.454545                -0.636364   \n",
       "metrics_mr                                -0.230769                -0.370629   \n",
       "metrics_mrr                               -0.349650                -0.524476   \n",
       "\n",
       "                                log_loss_probas_pos_neg  \\\n",
       "accuracy_per_relation                         -0.510490   \n",
       "accuracy_pos                                  -0.888112   \n",
       "accuracy_pos_iso                              -0.811189   \n",
       "accuracy_pos_neg                              -0.881119   \n",
       "accuracy_pos_neg_iso                          -0.874126   \n",
       "accuracy_pos_neg_sc                           -0.881119   \n",
       "accuracy_pos_sc                               -0.895105   \n",
       "accuracy_uncalib                              -0.797279   \n",
       "brier_score_probas_pos                         0.972028   \n",
       "brier_score_probas_pos_iso                     0.860140   \n",
       "brier_score_probas_pos_neg                     0.972028   \n",
       "brier_score_probas_pos_neg_iso                 0.923077   \n",
       "brier_score_probas_pos_neg_sc                  0.972028   \n",
       "brier_score_probas_pos_sc                      0.951049   \n",
       "brier_score_scores                             0.573427   \n",
       "log_loss_probas_pos                            0.993007   \n",
       "log_loss_probas_pos_iso                        0.902098   \n",
       "log_loss_probas_pos_neg                        1.000000   \n",
       "log_loss_probas_pos_neg_iso                    0.979021   \n",
       "log_loss_probas_pos_neg_sc                     1.000000   \n",
       "log_loss_probas_pos_sc                         0.972028   \n",
       "log_loss_scores                                0.419580   \n",
       "metrics_hits@10                               -0.433566   \n",
       "metrics_mr                                    -0.202797   \n",
       "metrics_mrr                                   -0.328671   \n",
       "\n",
       "                                log_loss_probas_pos_neg_iso  \\\n",
       "accuracy_per_relation                             -0.475524   \n",
       "accuracy_pos                                      -0.937063   \n",
       "accuracy_pos_iso                                  -0.888112   \n",
       "accuracy_pos_neg                                  -0.930070   \n",
       "accuracy_pos_neg_iso                              -0.937063   \n",
       "accuracy_pos_neg_sc                               -0.930070   \n",
       "accuracy_pos_sc                                   -0.944056   \n",
       "accuracy_uncalib                                  -0.754568   \n",
       "brier_score_probas_pos                             0.951049   \n",
       "brier_score_probas_pos_iso                         0.923077   \n",
       "brier_score_probas_pos_neg                         0.993007   \n",
       "brier_score_probas_pos_neg_iso                     0.972028   \n",
       "brier_score_probas_pos_neg_sc                      0.993007   \n",
       "brier_score_probas_pos_sc                          0.972028   \n",
       "brier_score_scores                                 0.545455   \n",
       "log_loss_probas_pos                                0.972028   \n",
       "log_loss_probas_pos_iso                            0.923077   \n",
       "log_loss_probas_pos_neg                            0.979021   \n",
       "log_loss_probas_pos_neg_iso                        1.000000   \n",
       "log_loss_probas_pos_neg_sc                         0.979021   \n",
       "log_loss_probas_pos_sc                             0.937063   \n",
       "log_loss_scores                                    0.391608   \n",
       "metrics_hits@10                                   -0.482517   \n",
       "metrics_mr                                        -0.188811   \n",
       "metrics_mrr                                       -0.363636   \n",
       "\n",
       "                                log_loss_probas_pos_neg_sc  \\\n",
       "accuracy_per_relation                            -0.510490   \n",
       "accuracy_pos                                     -0.888112   \n",
       "accuracy_pos_iso                                 -0.811189   \n",
       "accuracy_pos_neg                                 -0.881119   \n",
       "accuracy_pos_neg_iso                             -0.874126   \n",
       "accuracy_pos_neg_sc                              -0.881119   \n",
       "accuracy_pos_sc                                  -0.895105   \n",
       "accuracy_uncalib                                 -0.797279   \n",
       "brier_score_probas_pos                            0.972028   \n",
       "brier_score_probas_pos_iso                        0.860140   \n",
       "brier_score_probas_pos_neg                        0.972028   \n",
       "brier_score_probas_pos_neg_iso                    0.923077   \n",
       "brier_score_probas_pos_neg_sc                     0.972028   \n",
       "brier_score_probas_pos_sc                         0.951049   \n",
       "brier_score_scores                                0.573427   \n",
       "log_loss_probas_pos                               0.993007   \n",
       "log_loss_probas_pos_iso                           0.902098   \n",
       "log_loss_probas_pos_neg                           1.000000   \n",
       "log_loss_probas_pos_neg_iso                       0.979021   \n",
       "log_loss_probas_pos_neg_sc                        1.000000   \n",
       "log_loss_probas_pos_sc                            0.972028   \n",
       "log_loss_scores                                   0.419580   \n",
       "metrics_hits@10                                  -0.433566   \n",
       "metrics_mr                                       -0.202797   \n",
       "metrics_mrr                                      -0.328671   \n",
       "\n",
       "                                log_loss_probas_pos_sc  log_loss_scores  \\\n",
       "accuracy_per_relation                        -0.454545         0.069930   \n",
       "accuracy_pos                                 -0.832168        -0.293706   \n",
       "accuracy_pos_iso                             -0.741259        -0.195804   \n",
       "accuracy_pos_neg                             -0.825175        -0.300699   \n",
       "accuracy_pos_neg_iso                         -0.818182        -0.286713   \n",
       "accuracy_pos_neg_sc                          -0.825175        -0.300699   \n",
       "accuracy_pos_sc                              -0.825175        -0.279720   \n",
       "accuracy_uncalib                             -0.847109        -0.444910   \n",
       "brier_score_probas_pos                        0.930070         0.370629   \n",
       "brier_score_probas_pos_iso                    0.818182         0.321678   \n",
       "brier_score_probas_pos_neg                    0.916084         0.349650   \n",
       "brier_score_probas_pos_neg_iso                0.881119         0.321678   \n",
       "brier_score_probas_pos_neg_sc                 0.916084         0.349650   \n",
       "brier_score_probas_pos_sc                     0.895105         0.342657   \n",
       "brier_score_scores                            0.629371         0.930070   \n",
       "log_loss_probas_pos                           0.979021         0.433566   \n",
       "log_loss_probas_pos_iso                       0.930070         0.440559   \n",
       "log_loss_probas_pos_neg                       0.972028         0.419580   \n",
       "log_loss_probas_pos_neg_iso                   0.937063         0.391608   \n",
       "log_loss_probas_pos_neg_sc                    0.972028         0.419580   \n",
       "log_loss_probas_pos_sc                        1.000000         0.475524   \n",
       "log_loss_scores                               0.475524         1.000000   \n",
       "metrics_hits@10                              -0.461538         0.132867   \n",
       "metrics_mr                                   -0.300699        -0.643357   \n",
       "metrics_mrr                                  -0.356643         0.209790   \n",
       "\n",
       "                                metrics_hits@10  metrics_mr  metrics_mrr  \n",
       "accuracy_per_relation                  0.370629   -0.160839     0.342657  \n",
       "accuracy_pos                           0.391608    0.174825     0.300699  \n",
       "accuracy_pos_iso                       0.454545    0.188811     0.363636  \n",
       "accuracy_pos_neg                       0.370629    0.167832     0.265734  \n",
       "accuracy_pos_neg_iso                   0.398601    0.174825     0.300699  \n",
       "accuracy_pos_neg_sc                    0.370629    0.167832     0.265734  \n",
       "accuracy_pos_sc                        0.370629    0.146853     0.279720  \n",
       "accuracy_uncalib                       0.637112    0.558807     0.555248  \n",
       "brier_score_probas_pos                -0.370629   -0.181818    -0.286713  \n",
       "brier_score_probas_pos_iso            -0.405594   -0.223776    -0.328671  \n",
       "brier_score_probas_pos_neg            -0.447552   -0.153846    -0.328671  \n",
       "brier_score_probas_pos_neg_iso        -0.468531   -0.174825    -0.335664  \n",
       "brier_score_probas_pos_neg_sc         -0.447552   -0.153846    -0.328671  \n",
       "brier_score_probas_pos_sc             -0.419580   -0.167832    -0.321678  \n",
       "brier_score_scores                    -0.160839   -0.797203    -0.097902  \n",
       "log_loss_probas_pos                   -0.454545   -0.230769    -0.349650  \n",
       "log_loss_probas_pos_iso               -0.636364   -0.370629    -0.524476  \n",
       "log_loss_probas_pos_neg               -0.433566   -0.202797    -0.328671  \n",
       "log_loss_probas_pos_neg_iso           -0.482517   -0.188811    -0.363636  \n",
       "log_loss_probas_pos_neg_sc            -0.433566   -0.202797    -0.328671  \n",
       "log_loss_probas_pos_sc                -0.461538   -0.300699    -0.356643  \n",
       "log_loss_scores                        0.132867   -0.643357     0.209790  \n",
       "metrics_hits@10                        1.000000    0.286713     0.951049  \n",
       "metrics_mr                             0.286713    1.000000     0.286713  \n",
       "metrics_mrr                            0.951049    0.286713     1.000000  \n",
       "\n",
       "[25 rows x 25 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(X['valid'][:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
