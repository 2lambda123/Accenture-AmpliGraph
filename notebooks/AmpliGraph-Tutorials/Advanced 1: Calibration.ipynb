{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7d979c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dafa4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ampligraph\n",
    "# Benchmark datasets are under ampligraph.datasets module\n",
    "from ampligraph.datasets import load_fb15k_237\n",
    "# load fb15k-237 dataset\n",
    "dataset = load_fb15k_237()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e03ab8",
   "metadata": {},
   "source": [
    "## Train and predict scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ed1243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29/29 [==============================] - 3s 107ms/step - loss: 6736.2163\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 1s 33ms/step - loss: 6734.2759\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 1s 32ms/step - loss: 6722.5811\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 1s 32ms/step - loss: 6670.1821\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 1s 31ms/step - loss: 6525.2368\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 1s 32ms/step - loss: 6255.4956\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 1s 31ms/step - loss: 5888.8159\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 1s 32ms/step - loss: 5486.6587\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 1s 32ms/step - loss: 5098.1455\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 1s 32ms/step - loss: 4743.7100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6d700838e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the KGE model\n",
    "from ampligraph.latent_features import ScoringBasedEmbeddingModel\n",
    "\n",
    "# create the model with transe scoring function\n",
    "model = ScoringBasedEmbeddingModel(eta=1, \n",
    "                                     k=100,\n",
    "                                     scoring_type='ComplEx')\n",
    "\n",
    "\n",
    "# compile the model with loss and optimizer\n",
    "model.compile(optimizer='adam', loss='multiclass_nll')\n",
    "\n",
    "\n",
    "dataset = load_fb15k_237()\n",
    "\n",
    "model.fit(dataset['train'],\n",
    "             batch_size=10000,\n",
    "             epochs=10)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24cb1627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.555357  -1.4917737 -1.3967279 ...  6.119666   6.14651    6.2213273]\n",
      "[ 3834 18634  4569 ... 10495  9727 15757]\n"
     ]
    }
   ],
   "source": [
    "# The predicted scores are unbounded. \n",
    "# So it is hard to say just by looking at a single score if it is a good or bad score\n",
    "pred_out = model.predict(dataset['test'], batch_size=10000)\n",
    "\n",
    "# print the sorted score\n",
    "print(np.sort(pred_out))\n",
    "# rank the triples based on scores\n",
    "print(np.argsort(pred_out))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f22b45e",
   "metadata": {},
   "source": [
    "## Model calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd478620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate on the test set\n",
    "model.calibrate(dataset['test'],        # Dataset to calibrate on\n",
    "                batch_size=500,         # Batch size to be used for calibration\n",
    "                positive_base_rate=0.8, # prior which indicates what percentage of the dataset might be correct\n",
    "                epochs=100,             # Number of epochs\n",
    "                verbose=True)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f625f2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00847833 0.04739374 0.05502658 ... 0.9999324  0.9999354  0.9999429 ]\n",
      "[ 3834 18634  4569 ... 10495  9727 15757]\n"
     ]
    }
   ],
   "source": [
    "# use predict_proba to predict the calibrated scores\n",
    "# You will observe that the predicted scores are now bounded and between [0-1]\n",
    "out = model.predict_proba(dataset['test'], batch_size=10000)\n",
    "\n",
    "# if we now look at the sorted scores and ranks, it doesnt change from earlier\n",
    "print(np.sort(out))\n",
    "print(np.argsort(out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badb504e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d55c73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.8",
   "language": "python",
   "name": "tf2.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
