{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7d979c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dafa4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ampligraph\n",
    "# Benchmark datasets are under ampligraph.datasets module\n",
    "from ampligraph.datasets import load_fb15k_237\n",
    "# load fb15k-237 dataset\n",
    "dataset = load_fb15k_237()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3993fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ed1243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the KGE model\n",
    "from ampligraph.latent_features import ScoringBasedEmbeddingModel\n",
    "from ampligraph.datasets import SQLiteAdapter\n",
    "from ampligraph.datasets import GraphDataLoader\n",
    "from ampligraph.datasets.graph_partitioner import PARTITION_ALGO_REGISTRY\n",
    "\n",
    "# Graph loader - loads the data from the file, numpy array, etc and generates batchs for iterating\n",
    "dataset_loader = GraphDataLoader('/home/spai/code/ampligraph_projects/dataset/fb15k-237/train.txt', \n",
    "                                  backend=SQLiteAdapter, # type of backend to use\n",
    "                                  batch_size=1000,       # batch size to use while iterating over this dataset\n",
    "                                  dataset_type='train',  # dataset type\n",
    "                                  use_filter=False,      # Whether to use filter or not\n",
    "                                  use_indexer=True)      # indicates that the data needs to be mapped to index\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24cb1627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_split: memory before: 864.0Bytes, after: 12.825MB, consumed: 12.824MB; exec time: 19.579s\n"
     ]
    }
   ],
   "source": [
    "# Choose the partitioner - in this case we choose RandomEdges partitioner\n",
    "partitioner = PARTITION_ALGO_REGISTRY.get('RandomEdges')(dataset_loader, k=3)\n",
    "\n",
    "# the above code will create a partitioner by passing the graph dataloader object\n",
    "# the partitioner will partition the data and will internally create multiple graph \n",
    "# data loaders for each partition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "badb504e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1095.1127\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 25s 90ms/step - loss: 1090.9618\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 25s 91ms/step - loss: 1080.2867\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 25s 91ms/step - loss: 1052.5120\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 25s 90ms/step - loss: 1004.9535\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 25s 90ms/step - loss: 945.0866\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 25s 90ms/step - loss: 880.6620\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 25s 91ms/step - loss: 817.8426\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 25s 90ms/step - loss: 759.7908\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 25s 90ms/step - loss: 707.4431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc1df77faf0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and compile a model as usual\n",
    "partitioned_model = ScoringBasedEmbeddingModel(eta=2, \n",
    "                                     k=50, \n",
    "                                     scoring_type='DistMult')\n",
    "\n",
    "partitioned_model.compile(optimizer='adam', loss='multiclass_nll')\n",
    "\n",
    "partitioned_model.fit(partitioner,            # pass the partitioner object as input to the fit function\n",
    "                                              # this will generate data for the model during training\n",
    "                      use_partitioning=True,  # Specify that partitioning needs to be used           \n",
    "                      epochs=10)              # number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8d55c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "28 triples containing invalid keys skipped!\n"
     ]
    }
   ],
   "source": [
    "dataset_loader_test = GraphDataLoader('/home/spai/code/ampligraph_projects/dataset/fb15k-237/test.txt', \n",
    "            backend=SQLiteAdapter,     # type of backend to use\n",
    "            batch_size=400,            # batch size to use while iterating over this dataset\n",
    "            dataset_type='test',       # dataset type\n",
    "            use_indexer=partitioned_model.data_handler.get_mapper())    # get the mapper from the trained model \n",
    "                                                                        # and map the concepts to same indices \n",
    "                                                                        # as used during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10f32d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 213s 4s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1171.3521381739897, 0.07391564404652512, 0.0, 0.20427634797925434, 20438)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks = partitioned_model.evaluate(dataset_loader_test, # pass the dataloader object as input to the \n",
    "                                                        # evaluate function. this will generate data\n",
    "                                                        # for the model during training\n",
    "                                   batch_size=400)\n",
    "from ampligraph.evaluation.metrics import mrr_score, hits_at_n_score, mr_score\n",
    "mr_score(ranks), mrr_score(ranks), hits_at_n_score(ranks, 1), hits_at_n_score(ranks, 10), len(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77a8342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21abb55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.8",
   "language": "python",
   "name": "tf2.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
