{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67304fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main difference in the api's is how you import the models and evaluate performance\n",
    "# These api's can be found under ampligraph.compat APIs\n",
    "# from ampligraph.compat import TransE, DistMult, ComplEx, HolE, evaluate_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ed1ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "815c51e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ampligraph\n",
    "# load the dataset\n",
    "from ampligraph.datasets import load_fb15k_237\n",
    "X = load_fb15k_237()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c8fb84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea220fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import the models from ampligraph.compat\n",
    "# we support only TransE, DistMult, ComplEx, HolE\n",
    "from ampligraph.compat import ComplEx\n",
    "\n",
    "model = ComplEx(batches_count=10, seed=0, epochs=2000, k=350, eta=10,\n",
    "                    # Use adam optimizer with learning rate 1e-3\n",
    "                    optimizer='adam', optimizer_params={'lr':1e-3},\n",
    "                    # Use multiclass_nll loss \n",
    "                    loss='multiclass_nll', loss_params={},\n",
    "                    # Use L3 regularizer with regularizer weight 1e-3\n",
    "                    regularizer='LP', regularizer_params={'p':3, 'lambda':1e-3}, \n",
    "                    # Enable stdout messages (set to false if you don't want to display)\n",
    "                    verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dd122b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the filter\n",
    "filter = np.concatenate((X['train'], X['valid'], X['test']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49ad1810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "11/11 [==============================] - 2s 224ms/step - loss: 65250.1641\n",
      "Epoch 2/2000\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 65240.8359\n",
      "Epoch 3/2000\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 65222.4375\n",
      "Epoch 4/2000\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 65179.2812\n",
      "Epoch 5/2000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 65083.1094\n",
      "Epoch 6/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 64889.0352\n",
      "Epoch 7/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 64534.9219\n",
      "Epoch 8/2000\n",
      "11/11 [==============================] - 1s 84ms/step - loss: 63944.8438\n",
      "Epoch 9/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 63039.1602\n",
      "Epoch 10/2000\n",
      "11/11 [==============================] - 1s 84ms/step - loss: 61753.2969\n",
      "Epoch 11/2000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 60068.1680\n",
      "Epoch 12/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 58037.3711\n",
      "Epoch 13/2000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 55781.2266\n",
      "Epoch 14/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 53442.3789\n",
      "Epoch 15/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 51134.9219\n",
      "Epoch 16/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 48932.1719\n",
      "Epoch 17/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 46864.1641\n",
      "Epoch 18/2000\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 44941.6641\n",
      "Epoch 19/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 43158.6797\n",
      "Epoch 20/2000\n",
      "19/19 [==============================] - 6s 308ms/step\n",
      "11/11 [==============================] - 16s 1s/step - loss: 41508.4062 - val_mrr: 0.2805 - val_mr: 313.7222 - val_hits@1: 0.2037 - val_hits@10: 0.4310 - val_hits@100: 0.6634\n",
      "Epoch 21/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 39977.9648\n",
      "Epoch 22/2000\n",
      "11/11 [==============================] - 1s 89ms/step - loss: 38559.2188\n",
      "Epoch 23/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 37239.6016\n",
      "Epoch 24/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 36012.7578\n",
      "Epoch 25/2000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 34867.1211\n",
      "Epoch 26/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 33796.3516\n",
      "Epoch 27/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 32794.1797\n",
      "Epoch 28/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 31852.8242\n",
      "Epoch 29/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 30967.8164\n",
      "Epoch 30/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 30133.0801\n",
      "Epoch 31/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 29346.0898\n",
      "Epoch 32/2000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 28602.3438\n",
      "Epoch 33/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 27898.4336\n",
      "Epoch 34/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 27231.4492\n",
      "Epoch 35/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 26597.7090\n",
      "Epoch 36/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 25995.6133\n",
      "Epoch 37/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 25421.6641\n",
      "Epoch 38/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 24874.6348\n",
      "Epoch 39/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 24353.5000\n",
      "Epoch 40/2000\n",
      "19/19 [==============================] - 5s 266ms/step\n",
      "11/11 [==============================] - 15s 1s/step - loss: 23855.9980 - val_mrr: 0.3004 - val_mr: 233.5573 - val_hits@1: 0.2136 - val_hits@10: 0.4709 - val_hits@100: 0.7239\n",
      "Epoch 41/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 23380.0176\n",
      "Epoch 42/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 22924.3457\n",
      "Epoch 43/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 22488.3516\n",
      "Epoch 44/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 22069.7324\n",
      "Epoch 45/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 21668.3320\n",
      "Epoch 46/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 21282.6152\n",
      "Epoch 47/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 20911.9258\n",
      "Epoch 48/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 20555.3398\n",
      "Epoch 49/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 20212.0781\n",
      "Epoch 50/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 19881.0918\n",
      "Epoch 51/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 19561.8125\n",
      "Epoch 52/2000\n",
      "11/11 [==============================] - 1s 88ms/step - loss: 19254.0195\n",
      "Epoch 53/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 18956.9375\n",
      "Epoch 54/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 18670.3047\n",
      "Epoch 55/2000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 18393.3867\n",
      "Epoch 56/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 18125.4062\n",
      "Epoch 57/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 17866.3809\n",
      "Epoch 58/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 17615.4922\n",
      "Epoch 59/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 17372.5957\n",
      "Epoch 60/2000\n",
      "19/19 [==============================] - 5s 265ms/step\n",
      "11/11 [==============================] - 15s 1s/step - loss: 17136.9707 - val_mrr: 0.3035 - val_mr: 219.0376 - val_hits@1: 0.2156 - val_hits@10: 0.4755 - val_hits@100: 0.7370\n",
      "Epoch 61/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 16908.7227\n",
      "Epoch 62/2000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 16686.7930\n",
      "Epoch 63/2000\n",
      "11/11 [==============================] - 1s 86ms/step - loss: 16471.8594\n",
      "Epoch 64/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 16263.1855\n",
      "Epoch 65/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 16060.1650\n",
      "Epoch 66/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 15862.9805\n",
      "Epoch 67/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 15671.5283\n",
      "Epoch 68/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 15484.9766\n",
      "Epoch 69/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 15303.6699\n",
      "Epoch 70/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 15127.6240\n",
      "Epoch 71/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 14956.2002\n",
      "Epoch 72/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 14788.9053\n",
      "Epoch 73/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 14625.8447\n",
      "Epoch 74/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 14467.0186\n",
      "Epoch 75/2000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 14312.3281\n",
      "Epoch 76/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 14161.0234\n",
      "Epoch 77/2000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 14013.6934\n",
      "Epoch 78/2000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 13869.8145\n",
      "Epoch 79/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 13729.3857\n",
      "Epoch 80/2000\n",
      "19/19 [==============================] - 5s 261ms/step\n",
      "11/11 [==============================] - 15s 1s/step - loss: 13592.6201 - val_mrr: 0.2996 - val_mr: 213.1945 - val_hits@1: 0.2068 - val_hits@10: 0.4792 - val_hits@100: 0.7450\n",
      "Epoch 81/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 13458.6152\n",
      "Epoch 82/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 13327.9990\n",
      "Epoch 83/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 13200.2891\n",
      "Epoch 84/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 13075.4844\n",
      "Epoch 85/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 12953.1689\n",
      "Epoch 86/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 12833.6533\n",
      "Epoch 87/2000\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 12716.7422\n",
      "Epoch 88/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 78ms/step - loss: 12602.2197\n",
      "Epoch 89/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 12490.2334\n",
      "Epoch 90/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 12380.6807\n",
      "Epoch 91/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 12273.6699\n",
      "Epoch 92/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 12168.8193\n",
      "Epoch 93/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 12065.9434\n",
      "Epoch 94/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 11965.1338\n",
      "Epoch 95/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 11866.1641\n",
      "Epoch 96/2000\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 11769.2451\n",
      "Epoch 97/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 11674.4580\n",
      "Epoch 98/2000\n",
      "11/11 [==============================] - 1s 88ms/step - loss: 11581.3438\n",
      "Epoch 99/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 11490.0049\n",
      "Epoch 100/2000\n",
      "19/19 [==============================] - 5s 268ms/step\n",
      "11/11 [==============================] - 15s 1s/step - loss: 11400.4863 - val_mrr: 0.2945 - val_mr: 213.7362 - val_hits@1: 0.2025 - val_hits@10: 0.4809 - val_hits@100: 0.7510\n",
      "Epoch 101/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 11312.5146\n",
      "Epoch 102/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 11226.1533\n",
      "Epoch 103/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 11141.3838\n",
      "Epoch 104/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 11058.4678\n",
      "Epoch 105/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 10976.8408\n",
      "Epoch 106/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 10896.7012\n",
      "Epoch 107/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 10818.1504\n",
      "Epoch 108/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 10740.7422\n",
      "Epoch 109/2000\n",
      "11/11 [==============================] - 1s 85ms/step - loss: 10664.6299\n",
      "Epoch 110/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 10590.0752\n",
      "Epoch 111/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 10517.0264\n",
      "Epoch 112/2000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 10445.0342\n",
      "Epoch 113/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 10374.2676\n",
      "Epoch 114/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 10304.6113\n",
      "Epoch 115/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 10236.1836\n",
      "Epoch 116/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 10168.7979\n",
      "Epoch 117/2000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 10102.6719\n",
      "Epoch 118/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 10037.3809\n",
      "Epoch 119/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 9973.3701\n",
      "Epoch 120/2000\n",
      "19/19 [==============================] - 5s 264ms/step\n",
      "11/11 [==============================] - 15s 1s/step - loss: 9910.3789 - val_mrr: 0.2963 - val_mr: 215.1412 - val_hits@1: 0.2037 - val_hits@10: 0.4832 - val_hits@100: 0.7530\n",
      "Epoch 121/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 9848.2529\n",
      "Epoch 122/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 9787.2930\n",
      "Epoch 123/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 9726.9941\n",
      "Epoch 124/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 9667.6514\n",
      "Epoch 125/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 9609.2803\n",
      "Epoch 126/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 9551.8027\n",
      "Epoch 127/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 9495.3750\n",
      "Epoch 128/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 9439.6523\n",
      "Epoch 129/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 9384.6338\n",
      "Epoch 130/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 9330.5166\n",
      "Epoch 131/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 9277.0537\n",
      "Epoch 132/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 9224.5488\n",
      "Epoch 133/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 9172.7627\n",
      "Epoch 134/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 9121.7705\n",
      "Epoch 135/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 9071.5479\n",
      "Epoch 136/2000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 9021.8457\n",
      "Epoch 137/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 8972.8994\n",
      "Epoch 138/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 8924.6484\n",
      "Epoch 139/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 8877.0449\n",
      "Epoch 140/2000\n",
      "19/19 [==============================] - 5s 262ms/step\n",
      "11/11 [==============================] - 15s 1s/step - loss: 8830.2393 - val_mrr: 0.2956 - val_mr: 214.8060 - val_hits@1: 0.2011 - val_hits@10: 0.4866 - val_hits@100: 0.7556\n",
      "Epoch 141/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 8783.9121\n",
      "Epoch 142/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 8738.2227\n",
      "Epoch 143/2000\n",
      "11/11 [==============================] - 1s 96ms/step - loss: 8693.2158\n",
      "Epoch 144/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 8648.7344\n",
      "Epoch 145/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 8604.7451\n",
      "Epoch 146/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 8561.4277\n",
      "Epoch 147/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 8518.7373\n",
      "Epoch 148/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 8476.5332\n",
      "Epoch 149/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 8435.0430\n",
      "Epoch 150/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 8394.0176\n",
      "Epoch 151/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 8353.4688\n",
      "Epoch 152/2000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 8313.3770\n",
      "Epoch 153/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 8273.8770\n",
      "Epoch 154/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 8234.8193\n",
      "Epoch 155/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 8196.2061\n",
      "Epoch 156/2000\n",
      "11/11 [==============================] - 1s 84ms/step - loss: 8158.0674\n",
      "Epoch 157/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 8120.3828\n",
      "Epoch 158/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 8083.1436\n",
      "Epoch 159/2000\n",
      "11/11 [==============================] - 1s 84ms/step - loss: 8046.5190\n",
      "Epoch 160/2000\n",
      "19/19 [==============================] - 6s 303ms/step\n",
      "11/11 [==============================] - 16s 1s/step - loss: 8010.2695 - val_mrr: 0.2870 - val_mr: 219.4218 - val_hits@1: 0.1920 - val_hits@10: 0.4806 - val_hits@100: 0.7513\n",
      "Epoch 161/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 7974.5137\n",
      "Epoch 162/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 7939.2026\n",
      "Epoch 163/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 7904.2031\n",
      "Epoch 164/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 7869.6191\n",
      "Epoch 165/2000\n",
      "11/11 [==============================] - 1s 86ms/step - loss: 7835.6431\n",
      "Epoch 166/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 7801.8945\n",
      "Epoch 167/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 7768.5166\n",
      "Epoch 168/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 7735.5825\n",
      "Epoch 169/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 7702.9116\n",
      "Epoch 170/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 7670.6714\n",
      "Epoch 171/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 7638.7329\n",
      "Epoch 172/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 7607.3896\n",
      "Epoch 173/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 7576.2227\n",
      "Epoch 174/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 82ms/step - loss: 7545.4492\n",
      "Epoch 175/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 7514.9331\n",
      "Epoch 176/2000\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 7484.8115\n",
      "Epoch 177/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 7454.9971\n",
      "Epoch 178/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 7425.5674\n",
      "Epoch 179/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 7396.4575\n",
      "Epoch 180/2000\n",
      "19/19 [==============================] - 5s 289ms/step\n",
      "11/11 [==============================] - 16s 1s/step - loss: 7367.6929 - val_mrr: 0.2868 - val_mr: 218.7188 - val_hits@1: 0.1925 - val_hits@10: 0.4783 - val_hits@100: 0.7567\n",
      "Epoch 181/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 7339.1338\n",
      "Epoch 182/2000\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 7310.8516\n",
      "Epoch 183/2000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 7282.8994\n",
      "Epoch 184/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 7255.2017\n",
      "Epoch 185/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 7227.8506\n",
      "Epoch 186/2000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 7200.8877\n",
      "Epoch 187/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 7174.0947\n",
      "Epoch 188/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 7147.6064\n",
      "Epoch 189/2000\n",
      "11/11 [==============================] - 1s 97ms/step - loss: 7121.3242\n",
      "Epoch 190/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 7095.4819\n",
      "Epoch 191/2000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 7069.7363\n",
      "Epoch 192/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 7044.3550\n",
      "Epoch 193/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 7019.1675\n",
      "Epoch 194/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 6994.2466\n",
      "Epoch 195/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 6969.5186\n",
      "Epoch 196/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 6945.0239\n",
      "Epoch 197/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 6920.7788\n",
      "Epoch 198/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 6896.8037\n",
      "Epoch 199/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 6873.2178\n",
      "Epoch 200/2000\n",
      "19/19 [==============================] - 5s 288ms/step\n",
      "11/11 [==============================] - 16s 1s/step - loss: 6849.7866 - val_mrr: 0.2845 - val_mr: 219.8354 - val_hits@1: 0.1908 - val_hits@10: 0.4766 - val_hits@100: 0.7558\n",
      "Epoch 201/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 6826.5718\n",
      "Epoch 202/2000\n",
      "11/11 [==============================] - 1s 87ms/step - loss: 6803.5156\n",
      "Epoch 203/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 6780.6104\n",
      "Epoch 204/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 6758.0703\n",
      "Epoch 205/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 6735.6587\n",
      "Epoch 206/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 6713.4307\n",
      "Epoch 207/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 6691.4751\n",
      "Epoch 208/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 6669.7998\n",
      "Epoch 209/2000\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 6648.3096\n",
      "Epoch 210/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 6627.0078\n",
      "Epoch 211/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 6605.8711\n",
      "Epoch 212/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 6584.8940\n",
      "Epoch 213/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 6564.1499\n",
      "Epoch 214/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 6543.5693\n",
      "Epoch 215/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 6523.2109\n",
      "Epoch 216/2000\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 6503.0298\n",
      "Epoch 217/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 6482.9668\n",
      "Epoch 218/2000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 6463.1182\n",
      "Epoch 219/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 6443.4556\n",
      "Epoch 220/2000\n",
      "19/19 [==============================] - 6s 307ms/step\n",
      "11/11 [==============================] - 16s 1s/step - loss: 6423.8535 - val_mrr: 0.2817 - val_mr: 219.8725 - val_hits@1: 0.1854 - val_hits@10: 0.4766 - val_hits@100: 0.7524\n",
      "Epoch 221/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 6404.4639\n",
      "Epoch 222/2000\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 6385.3501\n",
      "Epoch 223/2000\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 6366.3125\n",
      "Epoch 224/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 6347.4712\n",
      "Epoch 225/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 6328.7378\n",
      "Epoch 226/2000\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 6310.1992\n",
      "Epoch 227/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 6291.8325\n",
      "Epoch 228/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 6273.5107\n",
      "Epoch 229/2000\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 6255.5112\n",
      "Epoch 230/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 6237.6074\n",
      "Epoch 231/2000\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 6219.8594\n",
      "Epoch 232/2000\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 6202.2539\n",
      "Epoch 233/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 6184.7383\n",
      "Epoch 234/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 6167.4937\n",
      "Epoch 235/2000\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 6150.3491\n",
      "Epoch 236/2000\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 6133.2871\n",
      "Epoch 237/2000\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 6116.4116\n",
      "Epoch 238/2000\n",
      "11/11 [==============================] - 1s 96ms/step - loss: 6099.6606\n",
      "Epoch 239/2000\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 6083.0723\n",
      "Epoch 240/2000\n",
      "19/19 [==============================] - 5s 286ms/step\n",
      "11/11 [==============================] - 16s 1s/step - loss: 6066.6304 - val_mrr: 0.2825 - val_mr: 222.1631 - val_hits@1: 0.1880 - val_hits@10: 0.4755 - val_hits@100: 0.7493\n",
      "Restoring model weights from the end of the best epoch: 140.\n",
      "Epoch 240: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on training and validation set\n",
    "model.fit(X['train'], \n",
    "          early_stopping = True,\n",
    "          early_stopping_params = \\\n",
    "                  {\n",
    "                      'x_valid': X['valid'][::10],       # validation set\n",
    "                      'criteria':'hits@10',         # Uses hits10 criteria for early stopping\n",
    "                      'burn_in': 20,              # early stopping kicks in after 100 epochs\n",
    "                      'check_interval':20,         # validates every 20th epoch\n",
    "                      'stop_interval':5,           # stops if 5 successive validation checks are bad.\n",
    "                      'x_filter': filter,          # Use filter for filtering out positives \n",
    "                      'corruption_entities':'all', # corrupt using all entities\n",
    "                      'corrupt_side':'s+o'         # corrupt subject and object (but not at once)\n",
    "                  }\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0da6a76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['/m/08966',\n",
       "        '/travel/travel_destination/climate./travel/travel_destination_monthly_climate/month',\n",
       "        '/m/05lf_'],\n",
       "       ['/m/01hww_',\n",
       "        '/music/performance_role/regular_performances./music/group_membership/group',\n",
       "        '/m/01q99h']], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X['test']\n",
    "X_test[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38786d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.322721,  7.204272], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on new triples\n",
    "model.predict(X_test[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39ec7559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.26887387,  0.27902964, -0.20528151, ...,  0.15810564,\n",
       "        -0.23209587,  0.33689767],\n",
       "       [ 0.17871626, -0.19304618, -0.24542606, ...,  0.20739488,\n",
       "        -0.2235089 , -0.22911648]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get embedding of entities\n",
    "model.get_embeddings(['/m/08966','/m/05lf_'], embedding_type='entity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "729d6de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14505, 237)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the entity and relation mappings to emb matrix\n",
    "ent_to_idx, rel_to_idx = model.get_hyperparameter_dict()\n",
    "len(ent_to_idx), len(rel_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3be4857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "305beebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 51s 248ms/step\n",
      "MR: 208.67266855856738\n",
      "MRR: 0.289697242341989\n",
      "hits@1: 0.1933897641647911\n",
      "hits@10: 0.48177414619825815\n"
     ]
    }
   ],
   "source": [
    "# import the evaluate_performance API from compat module\n",
    "from ampligraph.compat import evaluate_performance\n",
    "ranks = evaluate_performance(X_test, model, filter_triples=filter, corrupt_side='s,o', verbose=True)\n",
    "\n",
    "# import the evaluation metrics\n",
    "from ampligraph.evaluation.metrics import mrr_score, hits_at_n_score, mr_score\n",
    "\n",
    "print('MR:', mr_score(ranks))\n",
    "print('MRR:', mrr_score(ranks))\n",
    "print('hits@1:', hits_at_n_score(ranks, 1))\n",
    "print('hits@10:', hits_at_n_score(ranks, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b67466c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path backward_model already exists. This save operation will overwrite the model                 at the specified path.\n",
      "WARNING - Found untraced functions such as _get_ranks while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "from ampligraph.utils import save_model\n",
    "# save the model\n",
    "save_model(model, 'backward_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f78f15cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.utils import restore_model\n",
    "\n",
    "# restore saved models or checkpoints\n",
    "res_model = restore_model('backward_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f0f553b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 50s 244ms/step\n",
      "MR: 208.67266855856738\n",
      "MRR: 0.289697242341989\n",
      "hits@1: 0.1933897641647911\n",
      "hits@10: 0.48177414619825815\n"
     ]
    }
   ],
   "source": [
    "# import the evaluate_performance API from compat module\n",
    "from ampligraph.compat import evaluate_performance\n",
    "ranks = evaluate_performance(X_test, res_model, filter_triples=filter, corrupt_side='s,o', verbose=True)\n",
    "\n",
    "# import the evaluation metrics\n",
    "from ampligraph.evaluation.metrics import mrr_score, hits_at_n_score, mr_score\n",
    "\n",
    "print('MR:', mr_score(ranks))\n",
    "print('MRR:', mrr_score(ranks))\n",
    "print('hits@1:', hits_at_n_score(ranks, 1))\n",
    "print('hits@10:', hits_at_n_score(ranks, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fea2d0d",
   "metadata": {},
   "source": [
    "# Discovery "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a24648d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([['/m/06w99h3', '/location/country/form_of_government', '/m/09nqf'],\n",
       "        ['/m/0fvf9q', '/location/country/form_of_government',\n",
       "         '/m/05b4l5x']], dtype=object),\n",
       " array([27.5, 47.5]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for discovery, import the required apis from the corresponding modules\n",
    "# They are designed to be backward compatible\n",
    "from ampligraph.discovery import discover_facts\n",
    "\n",
    "discover_facts(X['train'][:100], \n",
    "               res_model, \n",
    "               top_n=100, \n",
    "               strategy='entity_frequency', \n",
    "               max_candidates=100, \n",
    "               target_rel='/location/country/form_of_government', \n",
    "               seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caa7289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c751f2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.8",
   "language": "python",
   "name": "tf2.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
