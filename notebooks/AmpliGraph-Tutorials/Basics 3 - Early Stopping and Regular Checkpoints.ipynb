{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7d979c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dafa4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ampligraph\n",
    "# Benchmark datasets are under ampligraph.datasets module\n",
    "from ampligraph.datasets import load_fb15k_237\n",
    "# load fb15k-237 dataset\n",
    "dataset = load_fb15k_237()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ed1243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 2s 76ms/step - loss: 6698.2188\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 1s 351ms/steposs: 6743.884\n",
      "29/29 [==============================] - 2s 70ms/step - loss: 6648.8862 - val_mrr: 0.0672 - val_mr: 2604.4943 - val_hits@1: 0.0000e+00 - val_hits@10: 0.1847\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 1s 33ms/step - loss: 6590.2842\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 89ms/steploss: 6564.021\n",
      "29/29 [==============================] - 1s 43ms/step - loss: 6517.4517 - val_mrr: 0.0918 - val_mr: 1316.6307 - val_hits@1: 0.0000e+00 - val_hits@10: 0.2528\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 1s 32ms/step - loss: 6431.8696\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 89ms/steploss: 6369.422\n",
      "29/29 [==============================] - 1s 43ms/step - loss: 6338.9854 - val_mrr: 0.0873 - val_mr: 935.4460 - val_hits@1: 0.0000e+00 - val_hits@10: 0.2443\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 1s 32ms/step - loss: 6243.9902\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 1s 350ms/steposs: 6170.871\n",
      "29/29 [==============================] - 2s 69ms/step - loss: 6148.5376 - val_mrr: 0.0843 - val_mr: 857.0710 - val_hits@1: 0.0000e+00 - val_hits@10: 0.2159\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 1s 32ms/step - loss: 6054.7817\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 94ms/steploss: 5980.499\n",
      "29/29 [==============================] - 1s 43ms/step - loss: 5963.0801 - val_mrr: 0.0778 - val_mr: 814.8324 - val_hits@1: 0.0000e+00 - val_hits@10: 0.1790\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Epoch 10: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6084419b20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the KGE model\n",
    "from ampligraph.latent_features import ScoringBasedEmbeddingModel\n",
    "\n",
    "# create the model with transe scoring function\n",
    "model = ScoringBasedEmbeddingModel(eta=1, \n",
    "                                     k=10,\n",
    "                                     scoring_type='TransE')\n",
    "\n",
    "\n",
    "# compile the model with loss and optimizer\n",
    "model.compile(optimizer='adam', loss='multiclass_nll')\n",
    "\n",
    "# Use this for checkpoints at regular intervals\n",
    "#checkpoint = tf.keras.callbacks.ModelCheckpoint('./chkpt_transe', monitor='val_mrr', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# Use this for early stopping\n",
    "checkpoint = tf.keras.callbacks.EarlyStopping(monitor=\"val_mrr\", # which metrics to monitor\n",
    "                                              patience=3,        # If the monitored metric doesnt improve \n",
    "                                                                 # for these many checks the model early stops\n",
    "                                              verbose=1,         # verbosity\n",
    "                                              mode=\"max\",        # how to compare the monitored metrics. \n",
    "                                                                 # max - means higher is better\n",
    "                                              restore_best_weights=True) # restore the weights with best value\n",
    "\n",
    "dataset = load_fb15k_237()\n",
    "\n",
    "model.fit(dataset['train'],\n",
    "             batch_size=10000,\n",
    "             epochs=100,\n",
    "             validation_freq=2,\n",
    "             validation_batch_size=100,\n",
    "             validation_data = dataset['valid'][::100],\n",
    "         callbacks=[checkpoint])     # Pass the callback to the fit function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5b4dc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 85s 413ms/step\n",
      "MR: 1181.2051325961445\n",
      "MRR: 0.18521472801873523\n",
      "hits@1: 0.1281191897445934\n",
      "hits@10: 0.29547900968783636\n"
     ]
    }
   ],
   "source": [
    "# evaluate on the test set\n",
    "ranks = model.evaluate(dataset['test'], # test set\n",
    "                       batch_size=100, # evaluation batch size\n",
    "                       corrupt_side='s,o', \n",
    "                       use_filter={'train':dataset['train'], # Filter to be used for evaluation\n",
    "                                   'valid':dataset['valid'],\n",
    "                                   'test':dataset['test']}\n",
    "                       )\n",
    "\n",
    "# import the evaluation metrics\n",
    "from ampligraph.evaluation.metrics import mrr_score, hits_at_n_score, mr_score\n",
    "\n",
    "print('MR:', mr_score(ranks))\n",
    "print('MRR:', mrr_score(ranks))\n",
    "print('hits@1:', hits_at_n_score(ranks, 1))\n",
    "print('hits@10:', hits_at_n_score(ranks, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee12a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using ModelCheckpoint then we can restore the checkpoints using restore model\n",
    "# from ampligraph.utils import restore_model\n",
    "# model = restore_model('chkpt_transe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc72ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115f311e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f625f2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.8",
   "language": "python",
   "name": "tf2.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
